%% LyX 2.3.0 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[ngerman]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{geometry}
\geometry{verbose,tmargin=1.5cm,bmargin=1.5cm,lmargin=1.5cm,rmargin=1.5cm}
\setlength{\parindent}{0bp}
\usepackage{babel}
\usepackage{array}
\usepackage{varioref}
\usepackage{booktabs}
\usepackage{fancybox}
\usepackage{calc}
\usepackage{textcomp}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{cancel}
\usepackage{stmaryrd}
\usepackage{graphicx}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}[section]
\theoremstyle{definition}
\newtheorem{defn}[thm]{\protect\definitionname}
\theoremstyle{definition}
\newtheorem*{defn*}{\protect\definitionname}
\newenvironment{lyxlist}[1]
	{\begin{list}{}
		{\settowidth{\labelwidth}{#1}
		 \setlength{\leftmargin}{\labelwidth}
		 \addtolength{\leftmargin}{\labelsep}
		 \renewcommand{\makelabel}[1]{##1\hfil}}}
	{\end{list}}
\theoremstyle{plain}
\newtheorem{lem}[thm]{\protect\lemmaname}
\theoremstyle{plain}
\newtheorem{prop}[thm]{\protect\propositionname}
\theoremstyle{plain}
\newtheorem{cor}[thm]{\protect\corollaryname}
\theoremstyle{plain}
\newtheorem*{prop*}{\protect\propositionname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage{pstricks}
\usepackage{hyperref}
\renewcommand{\labelenumi}{(\arabic{enumi})}
\renewcommand{\labelenumii}{(\arabic{enumi}.\arabic{enumii})}
\renewcommand{\labelenumiii}{(\arabic{enumi}.\arabic{enumii}.\arabic{enumiii})}
\renewcommand{\labelenumiv}{(\arabic{enumi}.\arabic{enumii}.\arabic{enumiii}.\arabic{enumiv})}

\makeatother

\providecommand{\corollaryname}{Korollar}
\providecommand{\definitionname}{Definition}
\providecommand{\lemmaname}{Lemma}
\providecommand{\propositionname}{Satz}
\providecommand{\theoremname}{Theorem}

\begin{document}

\title{\noindent Effiziente Algorithmen 1 - Zusammenfassung}

\author{\noindent Patrick Dammann}

\date{\noindent 21.05.2017}

\maketitle
{\footnotesize{}}%
\begin{tabular}{clllr}
\toprule 
{\footnotesize{}Zweck} & {\footnotesize{}Name} & {\footnotesize{}Laufzeit} & {\footnotesize{}Kommentar} & {\footnotesize{}Link}\tabularnewline
\midrule
\midrule 
\multirow{2}{*}{{\footnotesize{}Durchsuchen}} & \textbf{\footnotesize{}Breitensuche} & {\footnotesize{}$\mathcal{O}\left(\text{Adj.}\right)\star$} & {\footnotesize{}Laufzeit je nach Adjazenzstruktur} & {\footnotesize{}\vref{BFS}}\tabularnewline
\cmidrule{2-5} 
 & \textbf{\footnotesize{}Tiefensuche} & {\footnotesize{}$\mathcal{O}\left(\text{Adj.}\right)\star$} &  & {\footnotesize{}\vref{DFS}}\tabularnewline
\midrule 
{\footnotesize{}Topologische Sortierung} & \textbf{\footnotesize{}Topsort} & {\footnotesize{}$\mathcal{O}\left(\text{Adj.}\right)\star$} & {\footnotesize{}findet auch Kreise} & {\footnotesize{}\vref{TopSort}}\tabularnewline
\midrule 
{\footnotesize{}Komponenten finden} & \textbf{\footnotesize{}StrongComponents} & {\footnotesize{}$\mathcal{O}\left(\text{Adj.}\right)\star$(?)} &  & {\footnotesize{}\vref{StrongComponents}}\tabularnewline
\midrule 
\multirow{8}{*}{{\footnotesize{}Minimum Spanning Tree}} & \textbf{\footnotesize{}Boruvka} & {\footnotesize{}¯\textbackslash\_($\ddot{\smile}$)\_/¯} & {\footnotesize{}paralleler Ansatz} & {\footnotesize{}\vref{Boruvka}}\tabularnewline
\cmidrule{2-5} 
 & \textbf{\footnotesize{}Kruskal} & {\footnotesize{}$\mathcal{O}\left(E\log V\right)$} & {\footnotesize{}Kanten sortieren} & {\footnotesize{}\vref{Kruskal}}\tabularnewline
\cmidrule{2-5} 
 & \multirow{5}{*}{\textbf{\footnotesize{}Prim}} & {\footnotesize{}$-$} & {\footnotesize{}baut MST von Startknoten} & {\footnotesize{}\vref{Prim}}\tabularnewline
\cmidrule{3-5} 
 &  & {\footnotesize{}$\mathcal{O}\left(VE\right)$} & {\footnotesize{}Implementierung} & {\footnotesize{}\vref{Prim1}}\tabularnewline
\cmidrule{3-5} 
 &  & {\footnotesize{}$\mathcal{O}\left(V^{2}\right)$} & \multirow{3}{*}{{\footnotesize{}Bessere Impl., sucht sinnvoller}} & \multirow{3}{*}{{\footnotesize{}\vref{Prim2}}}\tabularnewline
 &  & {\footnotesize{}$\mathcal{O}\left(E\log V\right)$} &  & \tabularnewline
 &  & {\footnotesize{}$\mathcal{O}\left(E+V\log V\right)$} &  & \tabularnewline
\cmidrule{2-5} 
 & \textbf{\footnotesize{}Round Robin} & {\footnotesize{}$\mathcal{O}\left(E\log\log V\right)$} & {\footnotesize{}baut MST von überall} & {\footnotesize{}\vref{RoundRobin}}\tabularnewline
\midrule 
{\footnotesize{}1-Baum} & \textbf{\footnotesize{}OneTree} & {\footnotesize{}-> MST} & {\footnotesize{}Untere Schranke TSP} & {\footnotesize{}\vref{OneTree}}\tabularnewline
\midrule 
\multirow{2}{*}{{\footnotesize{}Maximales Branching}} & \textbf{\footnotesize{}Branching} & {\footnotesize{}$\mathcal{O}\left(A\log V\right)$} &  & {\footnotesize{}\vref{Branching}}\tabularnewline
 &  & {\footnotesize{}oder $\mathcal{O}\left(V^{2}\right)$} & {\footnotesize{}Schrumpfen:} & {\footnotesize{}\vref{Branching (Schrumpfen)}}\tabularnewline
\midrule 
\multirow{5}{*}{{\footnotesize{}Kürzeste Wege}} & \multirow{3}{*}{\textbf{\footnotesize{}Dijkstra}} & {\footnotesize{}$\mathcal{O}\left(V^{2}\right)$} & \multirow{3}{*}{{\footnotesize{}Keine neg. Kanten}} & \multirow{3}{*}{{\footnotesize{}\vref{Dijkstra}}}\tabularnewline
 &  & {\footnotesize{}$\mathcal{O}\left(A\log V\right)$} &  & \tabularnewline
 &  & {\footnotesize{}$\mathcal{O}\left(A+V\log V\right)$} &  & \tabularnewline
\cmidrule{2-5} 
 & {\footnotesize{}BellmanFord} & {\footnotesize{}$\mathcal{O}\left(VA\right)$} &  & {\footnotesize{}\vref{BellmanFord}}\tabularnewline
\cmidrule{2-5} 
 & \textbf{\footnotesize{}DAGShortestPath} & {\footnotesize{}$\mathcal{O}\left(V+A\right)$} & {\footnotesize{}Nur in DAGs} & {\footnotesize{}\vref{DAGShortestPath}}\tabularnewline
\midrule 
\multirow{2}{*}{{\footnotesize{}Alle kürzesten Wege}} & {\footnotesize{}FloydWarshall} & {\footnotesize{}$\mathcal{O}\left(V^{3}\right)$} & {\footnotesize{}Wege über erste k Knoten} & {\footnotesize{}\vref{FloydWarshall}}\tabularnewline
\cmidrule{2-5} 
 & {\footnotesize{}Johnson} & {\footnotesize{}$\mathcal{O}\left(V\times\text{Dijkstra}\right)$} & {\footnotesize{}1$\times$BF, $\left|V\right|\times$Dijkstra} & {\footnotesize{}\vref{Johnson}}\tabularnewline
\midrule 
{\footnotesize{}Kreise mit bestem KZV} & {\footnotesize{}<kein Name>} & {\footnotesize{}$\mathcal{O}\left(VA\log\left(CVT\right)\right)$} & {\footnotesize{}$\mu$ schätzen} & \tabularnewline
\midrule 
\multirow{2}{*}{{\footnotesize{}Minimales Matching}} & \textbf{\footnotesize{}Ungarische Methode} & {\footnotesize{}$\mathcal{O}\left(n^{3}\right)$} &  & {\footnotesize{}\vref{HungarianMethod}}\tabularnewline
\cmidrule{2-5} 
 & {\footnotesize{}AKP-Algorithmus} & {\footnotesize{}$\mathcal{O}\left(n^{3}\right)$} &  & {\footnotesize{}\vref{AKP}}\tabularnewline
\midrule 
\multirow{6}{*}{{\footnotesize{}Maximaler $\left(s,t\right)$-Fluss}} & \textbf{\footnotesize{}FordFulkerson} & {\footnotesize{}$\mathcal{O}\left(A\left|f^{*}\right|\right)\cancel{\boxast}$} & {\footnotesize{}a.W. im reduzierten Netzwerk} & {\footnotesize{}\vref{FordFulkerson}}\tabularnewline
\cmidrule{2-5} 
 & {\footnotesize{}EdmondsKarp} & {\footnotesize{}$\mathcal{O}\left(VA^{2}\right)$} & {\footnotesize{}FF mit wenig Kanten auf a.W.} & {\footnotesize{}\vref{EdmondsKarp}}\tabularnewline
\cmidrule{2-5} 
 & \multirow{2}{*}{{\footnotesize{}ScalingMaxFlow}} & {\footnotesize{}$\mathcal{O}\left(A^{2}\log C\right)$} & \multirow{2}{*}{{\footnotesize{}nur Kanten mit $c_{f}>K$}} & \multirow{2}{*}{{\footnotesize{}\vref{ScalingMaxFlow}}}\tabularnewline
 &  & {\footnotesize{}$\mathcal{O}\left(VA\log C\right)$} &  & \tabularnewline
\cmidrule{2-5} 
 & {\footnotesize{}Preflow-Push} & {\footnotesize{}$\mathcal{O}\left(V^{2}A\right)$} & {\footnotesize{}Push, Lift} & {\footnotesize{}\vref{PrefowPush}}\tabularnewline
 & {\footnotesize{}(FIFO-Variante)} & {\footnotesize{}$\mathcal{O}\left(V^{3}\right)$} & {\footnotesize{}(Examine)} & {\footnotesize{}\vref{FIFO-PFP}}\tabularnewline
\midrule 
\multirow{3}{*}{{\footnotesize{}Minimaler Schnitt}} & \multirow{2}{*}{\textbf{\footnotesize{}NagamochiIbaraki}} & {\footnotesize{}$\mathcal{O}\left(V^{3}\right)$} & \multirow{2}{*}{{\footnotesize{}legale Ordnung}} & \multirow{2}{*}{{\footnotesize{}\vref{NagamochiIbaraki}}}\tabularnewline
 &  & {\footnotesize{}$\mathcal{O}\left(V^{2}+VE\log V\right)$} &  & \tabularnewline
\cmidrule{2-5} 
 & {\footnotesize{}Karger} & {\footnotesize{}¯\textbackslash\_($\ddot{\smile}$)\_/¯} & {\footnotesize{}MC-Algo, $p=\frac{2}{n\left(n-1\right)}$} & {\footnotesize{}\vref{Karger}}\tabularnewline
\midrule 
\multirow{6}{*}{{\footnotesize{}Netzwerkfluss}} & \textbf{\footnotesize{}SteppingStone} & {\footnotesize{}¯\textbackslash\_($\ddot{\smile}$)\_/¯} &  & \tabularnewline
\cmidrule{2-5} 
 & {\footnotesize{}Neg.-Kreise-Verfahren} & {\footnotesize{}$\mathcal{O}\left(V^{2}AUW\right)\cancel{\boxast}$} & {\footnotesize{}zul. Fluss wird kostenminimiert} & {\footnotesize{}\vref{CycleCanceling}}\tabularnewline
\cmidrule{2-5} 
 & \multirow{2}{*}{{\footnotesize{}Kürz.-Wege-Verfahren}} & {\footnotesize{}$\mathcal{O}\left(BV^{2}\right)\cancel{\boxast}$} & {\footnotesize{}kostenmin. Fluss wird zulässig} & {\footnotesize{}\vref{SuccShortestPath}}\tabularnewline
\cmidrule{4-5} 
 &  & {\footnotesize{}$\mathcal{O}\left(BA\log V\right)\cancel{\boxast}$} & {\footnotesize{}auch ohne dass }\textbf{\footnotesize{}alle}{\footnotesize{}
KW existieren} & {\footnotesize{}\vref{SuccShortestPath2}}\tabularnewline
\cmidrule{2-5} 
 & \multirow{2}{*}{{\footnotesize{}CapacityScaling}} & {\footnotesize{}$\mathcal{O}\left(AV^{2}\log U\right)$} & \multirow{2}{*}{{\footnotesize{}analog zu ScalingMaxFlow}} & \multirow{2}{*}{{\footnotesize{}\vref{CapacityScaling}}}\tabularnewline
 &  & {\footnotesize{}$\mathcal{O}\left(A^{2}\log V\log U\right)$} &  & \tabularnewline
\cmidrule{2-5} 
\end{tabular}{\footnotesize\par}

$\star$$\mathcal{O}\left(V^{2}\right)$ für Matrix, $\mathcal{O}\left(V+E\right)$
für Liste

\pagebreak{}

\section{Probleme und Algorithmen}

\noindent %
\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Lineares kombinatorisches Optimierungsproblem}

\smallskip{}

Gegeben sind eine endliche Menge $E$, ein System von Teilmengen $\mathcal{I}\subseteq2^{E}$
(zulässige Lösungen) und eine Funktion $c:E\rightarrow\mathbb{R}$.
Es ist eine Menge $I^{\ast}\in\mathcal{I}$ zu bestimmen, so dass
${\displaystyle c(I^{\ast})=\sum_{e\in I^{\ast}}c(e)}$ minimal bzw.
maximal ist.%
\end{minipage}}

\medskip{}

\noindent %
\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Euklidisches Traveling-Salesman-Problem}

\smallskip{}

Gegeben sind $n$ Punkte in der Euklidischen Ebene. Zu bestimmen ist
eine geschlossene Tour, die jeden Punkt genau einmal besucht und möglichst
kurz ist.

$E=$ Menge der Kanten

$\mathcal{I}=$ Alle Mengen von Kanten, die eine Tour bilden%
\end{minipage}}

\medskip{}

\noindent %
\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Euklidisches Matching-Problem}

\smallskip{}

Gegeben sind $n$ Punkte in der Euklidischen Ebene ($n$ gerade).
Zu bestimmen sind $\frac{n}{2}$ Linien, so dass jeder Punkt Endpunkt
genau einer Linie ist und die Summe der Linienlängen so klein wie
möglich ist.

$E=$ Menge der Kanten

$\mathcal{I}=$ Alle Mengen von Kanten mit der Eigenschaft, dass jeder
Knoten zu genau einer der Kanten gehört.%
\end{minipage}}
\begin{description}
\item [{Einheitskosten-Modell}] Es werden nur die Schritte des Algorithmus
gezählt, die Zahlengrößen bleiben unberücksichtigt.
\item [{Bit-Modell}] Die Laufzeit für eine arithmetische Operation ist
$M$, wobei $M$ die größte Kodierungslänge einer an dieser Operation
beteiligten Zahl ist.
\end{description}
\begin{defn}
\noindent Die Laufzeitfunktion $f_{A}:\mathbb{N}\rightarrow\mathcal{\mathbb{N}}$
ist in $\mathcal{O}(g)$ für eine Funktion $g:\mathbb{N}\rightarrow\mathcal{\mathbb{N}}$
falls es eine Konstante $c>0$ und $n_{o}\in\mathbb{N}$ gibt, so
dass $f_{A}\leq c\cdot g(n)$ für alle $n\geq n_{o}$.
\end{defn}

\begin{defn}
Ein Algorithmus heißt \textbf{effizient} bzw. \textbf{polynomialer
Algorithmus}, wenn seine Laufzeit in $\mathcal{O}\left(n^{k}\right)$
liegt.

Ein Problem, das mit einem polynomialen Algorithmus gelöst werden
kann, heißt \textbf{polynomiales Problem}.
\end{defn}

\begin{defn*}
Ein \textbf{Graph} $G$ ist ein Tupel $G=(V,E)$\footnote{In der Vorlesung werden primär endliche, einfache, schleifenfreie
Graphen behandelt, die der Einfachheit halber eine Notation ohne Inzendenzfunktion
nutzen können. In diesem Skript wird (sofern nicht anders angegeben)
von solchen Graphen ausgegangen.} bestehend aus einer nicht-leeren Knotenmenge $V$ und einer Kantenmenge
$E$.
\end{defn*}
\begin{itemize}
\item Ein Graph heißt \textbf{endlich}, wenn $V$ und $E$ endlich sind.
\item Wenn $e=\left\{ u,v\right\} \in E$ und $u,v\in V$, dann sind $u$
und $v$ \textbf{Nachbarn} bzw. \textbf{adjazen}t, sind \textbf{Endknoten}
von $e$ und werden von $e$ \textbf{verbunden}.
\item Eine Kante $e=\{u,u\}\in E$ heißt \textbf{Schleife}.
\item Kanten mit $E\ni e=\{u,v\}=f\in E$ heißen \textbf{parallel} oder
\textbf{mehrfach}.
\item Ein Graph ohne Mehrfachkanten heißt \textbf{einfach}.
\item Für $W\subseteq V$ bekommt die Menge aller Knoten in $V\setminus W$
mit Nachbarn in $W$ die Bezeichnung $\Gamma(W)$.
\item Kurzform von $\Gamma\left(\left\{ v\right\} \right)$ ist $\Gamma\left(v\right)$.
\item Die Menge $\delta\left(W\right)$ aller Kanten mit je einem Endknoten
in $W$ und $V\setminus W$ heißt \textbf{Schnitt}.
\item Kurzform von $\delta\left(\left\{ v\right\} \right)$ ist $\delta\left(v\right)$.
\item Der \textbf{Grad} eines Knoten $v$ ist die Anzahl seiner Nachbarn,
bzw. $\left|\delta\left(v\right)\right|$.
\item Ein \textbf{(s,t)-Schnitt} ist ein Schnitt $\delta\left(V\right)$
mit $s\in W$ und $t\in V\setminus W$ und gleichzeitig ein (t,s)-Schnitt.
\item Mit $W\subseteq V$ ist $E\left(W\right)$ die Menge aller Kanten
mit beiden Endknoten in $W$.
\item Mit $F\subseteq E$ ist $V\left(F\right)$ die Menge aller Knoten,
die Endknoten von mind. einer Kante in $F$ sind.
\item Sind $G=\left(V,E\right)$ und $H=\left(W,F\right)$ Graphen und $W\subseteq V$
und $F\subseteq E$, so heißt H \textbf{Untergraph} von G.
\item Mit $W\subseteq V$ ist $G-W$ der Graph $G$ ohne die Knoten in $W$
und ohne alle Kanten an $W$.
\item $G\left[W\right]=G-\left(V\setminus W\right)$ ist der \textbf{von
$W$ induzierte Untergraph}.
\item Mit $F\subseteq E$ ist $G-F=\left(V,E\setminus F\right)$.
\item Kurzform von $G-\left\{ x\right\} $ ist $G-x$ für $x\in E$ oder
$x\in V$.
\item Ein einfacher Graph heißt \textbf{vollständig}, wenn jede mögliche
Kante zwischen seinen Knoten existiert.
\item Der vollstängige Graph mit $n$ Knoten wird mit $K_{n}=\left(V_{n},E_{n}\right)$
bezeichnet.
\item Das \textbf{Komplement} des Graphen $G=\left(V,E\right)$ ist $\bar{G}=(V,E_{n}\setminus E)$.
\item Ein Graph heißt \textbf{bipartit}, wenn er sich in zwei disjunkte
Teilmengen $V_{1},V_{2}$ mit $V_{1}\cup V_{2}=V$ teilen lässt, ohne
dass es Kanten $\left\{ u,v\right\} $ mit $u,v\in V_{1}\vee u,v\in V_{2}$
gibt.
\end{itemize}
\begin{defn*}
Ein \textbf{Digraph} $G$ ist ein Tupel $D=(V,A)$ bestehend aus einer
nicht-leeren Knotenmenge $V$ und einer Kantenmenge $A$.
\end{defn*}
\begin{itemize}
\item Wenn $a=\left(u,v\right)\in A$ und $u,v\in V$, dann ist $u$ \textbf{Anfangsknoten}
und $v$ \textbf{Endknoten }von $a$. Hier heißt $u$ \textbf{Vorgänger}
von $v$ und $v$ \textbf{Nachfolger} von $u$.
\item Die Kanten $\left(u,v\right)$ und $\left(v,u\right)$ heißen \textbf{antiparallel}.
\item Mit $W\subseteq V$ ist $A\left(W\right)$ die Menge aller Kanten
mit Anfangs- und Endknoten in $W$.
\item Mit $B\subseteq A$ ist $V\left(A\right)$ die Menge aller Knoten,
die Anfangs- oder Endknoten von mind. einer Kante in $B$ sind.
\item $G=\left(V,E\right)$ ist der unterliegende Graph von $D=\left(V,A\right)$,
wenn $E$ genau die Kanten $\left\{ u,v\right\} $ enthält, für die
$\left(u,v\right)$ oder $\left(v,u\right)$ in $A$ liegen.
\item Ein einfacher Digraph heißt \textbf{vollständig}, wenn jede mögliche
Kante (in beide Richtungen) zwischen seinen Knoten existiert.
\item Der vollstängige Digraph mit $n$ Knoten wird mit $D_{n}=\left(V_{n},A_{n}\right)$
bezeichnet.
\item Für $W\subseteq V,W\neq V\neq\emptyset$ enthält $\delta^{+}\left(W\right)=\left\{ \left(i,j\right)\in A\,\vert\,i\in W,j\notin W\right\} $
alle Kanten, die $W$ verlassen, $\delta^{-}\left(W\right)=\delta^{+}\left(V\setminus W\right)$
alle Kanten, die in $W$ hinein führen und $\delta\left(W\right)=\delta^{+}\left(W\right)\cup\delta^{-}\left(W\right)$
beide. Diese Mengen heißen \textbf{Schnitt}. Es gelten die Kurzformen
für einzelne Knoten.
\item Für $s\in W$ und $t\notin W$ heißt $\delta^{+}\left(W\right)$ auch
\textbf{$\left(s,t\right)$-Schnitt}.
\item Die Kardinalitäten der Schnitte heißen \textbf{Außengrad} $\left(\left|\delta^{+}\left(v\right)\right|\right)$,
\textbf{Innengrad} $\left(\left|\delta^{-}\left(v\right)\right|\right)$
und \textbf{Grad} $\left(\left|\delta\left(v\right)\right|\right)$.
\item $\delta^{+}\left(W\right)$ heißt \textbf{gerichteter Schnitt}, wenn
$\delta^{-}\left(W\right)=\emptyset$.
\end{itemize}
\begin{defn*}
Eine endliche Folge $W=\left(v_{0},e_{1},v_{1},e_{2},v_{2},\ldots,e_{k},v_{k}\right)$
heißt \textbf{Kette} oder $\left[v_{0},v_{k}\right]$-Kette der Länge
$k$, wenn jede Kante $e_{i}$ die Knoten $v_{i-1}$ und $v_{i}$
in einem (Di-)Graphen indiziert und \textbf{gerichtete Kette} oder
$\left(v_{0},v_{k}\right)$-Kette, wenn alle Kanten in der Form $e_{i}=\left(v_{i-1},v_{i}\right)$
sind. $v_{0}$ und $v_{k}$ heißen \textbf{Anfangs- und Endknoten}.
\end{defn*}
\begin{itemize}
\item Gibt es in einem (Di-)Graphen keine parallelen Kanten, ist eine (gerichtete)
Kette durch ihre Knoten eindeutig identifiziert.
\item Ein \textbf{(gerichteter) Weg} oder \textbf{(gerichteter) Pfad} ist
eine (gerichtete) Kette, in der alle Knoten verschieden sind.
\item Die Notation $u\underset{D}{\rightarrow}v$ bedeutet, dass es einen
$\left(u,v\right)$-Weg in D gibt.
\item Man spricht auch von $\left(u,v\right)$-Wegen bzw. $\left(u,v\right)$-Pfaden.
\item Die Knoten $s$ und $t$ eines Graphen heißen \textbf{zusammenhängend},
wenn ein $\left(s,t\right)$-Weg existiert.
\item Ein \textbf{zusammenhängender Graph} enthält nur Knoten, die paarweise
zusammenhängend sind.
\item Ein Digraph heißt \textbf{stark zusammenhängend}, wenn es zu jedem
Knotenpaar $s,t$ einen $\left(s,t\right)$-Weg und einen $\left(t,s\right)$-Weg
gibt.
\item \textbf{Kompontenten} eines Graphen sind die (bezüglich Kanteninklusion)
maximalen zusammenhängenden Untergraphen.
\item \textbf{Starke Kompontenten} eines Diraphen sind die (bezüglich Kanteninklusion)
maximalen stark zusammenhängenden Unterdigraphen.
\item Ein Graph heißt \textbf{$k$-fach zusammenhängend}, wenn jedes Paar
Knoten $s,t$ durch mindestens $k$ $\left(s,t\right)$-Wege verbunden
ist, die keine inneren Knoten gemeinsam haben.
\item Ein Digraph heißt \textbf{$k$-fach stark zusammenhängend}, wenn jedes
Paar Knoten $s,t$ durch mindestens $k$ $\left(s,t\right)$-Wege
und $\left(t,s\right)$-Wege verbunden ist, die keine inneren Knoten
gemeinsam haben.
\item Eine \textbf{geschlossene Kette} hat mehr als $0$ Kanten und den
gleichen Anfangs- und Endknoten.
\item Ein \textbf{Kreis} ist eine geschlossene Kette mit paarweise verschiedenen
inneren Knoten. Seine \textbf{Länge} ist die Anzahl seiner Kanten.
\item Ein \textbf{Eulerpfad} ist eine Kette, die jede Kante eines (Di-)Graphen
einmal enthält.
\item Eine \textbf{Eulertour} ist ein geschlossener Eulerpfad.
\item Ein \textbf{Eulergraph} ist ein Graph, der eine Eulertour enthält.
\item Ein \textbf{Hamiltonkreis} (oder \textbf{Hamiltontour}) ist ein Kreis
der Länge $\left|V\right|$.
\item Ein \textbf{hamiltonischer} Graph enthält einen Hamiltonkreis.
\item Ein \textbf{Hamiltonweg} ist ein (gerichteter) Weg der Länge $\left|V\right|-1$.
\item Ein \textbf{Wald} ist eine Kantenmenge in einem Graphen, die keinen
Kreis enthält.
\item Ein \textbf{Baum} ist ein zusammenhängender Wald.
\item Ein \textbf{aufspannender} Baum enthält alle Knoten des Graphen.
\item Ein \textbf{azyklischer} Digraph enthält keine gerichteten Kreise.
\item Ein \textbf{Branching} in einem Digraphen ist eine azyklische Kantenmenge,
sodass jeder Knoten maximal eine Eingangskante besitzt.
\item Eine \textbf{Arboreszenz} ist ein zusammenhängendes Branching.
\item Eine \textbf{aufspannende Arboreszenz} enthält alle Knoten ihres Digraphen.
\item \textbf{Gewichte} (auch ``Kosten'', ``Distanzen'', ``Kapazitäten'',
usw.) werden durch Funktionen der Form $c:E\rightarrow\mathbb{R}$
bzw. $c:A\rightarrow\mathbb{R}$ mit Kanten assoziiert.
\end{itemize}

\section{Grundlegende Graphenalgorithmen}

\subsection{Repräsentationen von Graphen}
\begin{description}
\item [{Adjazenzliste}] Jeder Knoten hat eine Liste seiner Nachbarn gespeichert.
Speichersparend für dünne Graphen. Hinzufügen und Entfernen von Knoten
und Kanten sehr einfach. Existenz von Kanten prüfen teuer (einen Knoten
durchlaufen). Speicheraufwand: $\mathfrak{\mathcal{O}}(V+E)$
\item [{Adjazenzmatrix}] $\left|V\right|\times\left|V\right|$-Matrix,
die an der Stelle $(u,v)$ eine $1$ hat, wenn die Kante $\left(u,v\right)$
bzw. $\left\{ u,v\right\} $ existiert. Existenz von Kanten prüfen
in $\mathcal{O}(1)$. Nachbarn durchlaufen unanhängig von ihrer Anzahl
in $\mathcal{O}(V)$. Speicheraufwand: $\mathcal{O}\left(V^{2}\right)$
\item [{Inzidenzmatrix}] $\left|V\right|\times\left|E\right|$-Matrix,
die an der Stelle $(v,e)$ eine $1$ hat, wenn der Knoten $v$ Endknoten
der Kante $e$ ist. Erlaubt Untersuchung des Graphen mit diversen,
algebraischen Methoden. \emph{{[}Kein Beispiel{]}}
\end{description}
\begin{tabular}{>{\centering}m{0.3\textwidth}>{\centering}m{0.3\textwidth}>{\centering}m{0.3\textwidth}}
\includegraphics[scale=0.15]{diagramme/adjazenz} & $\begin{bmatrix}1 & \rightarrow2 & \rightarrow5\\
2 & \rightarrow1 & \rightarrow3 & \rightarrow4 & \rightarrow5\\
3 & \rightarrow2 & \rightarrow4\\
4 & \rightarrow2 & \rightarrow3 & \rightarrow5\\
5 & \rightarrow1 & \rightarrow2 & \rightarrow4
\end{bmatrix}$ & $\left[\begin{array}{c|ccccc}
 & 1 & 2 & 3 & 4 & 5\\
\hline 1 & 0 & 1 & 0 & 0 & 1\\
2 & 1 & 0 & 1 & 1 & 1\\
3 & 0 & 1 & 0 & 1 & 0\\
4 & 0 & 1 & 1 & 0 & 1\\
5 & 1 & 1 & 0 & 1 & 0
\end{array}\right]$\tabularnewline
 &  & \tabularnewline
\includegraphics[scale=0.15]{diagramme/adjazenz_dir} & $\begin{bmatrix}1 & \rightarrow2 & \rightarrow5\\
2 & \rightarrow4\\
3 & \rightarrow4\\
4\\
5 & \rightarrow2 & \rightarrow4
\end{bmatrix}$ & $\left[\begin{array}{c|ccccc}
\nearrow & 1 & 2 & 3 & 4 & 5\\
\hline 1 & 0 & 1 & 0 & 0 & 1\\
2 & 0 & 0 & 0 & 1 & 0\\
3 & 0 & 0 & 0 & 1 & 0\\
4 & 0 & 0 & 0 & 0 & 0\\
5 & 0 & 1 & 0 & 1 & 0
\end{array}\right]$\tabularnewline
\end{tabular}

\subsection{Durchsuchen von Graphen}

Das ``färben'' von Knoten ist eine Kurzschreibweise für folgende
Sachverhalte:
\begin{lyxlist}{00.00.0000}
\item [{weiß}] Der Knoten ist noch nicht erreicht. (Im Normalfall Grundzustand)
\item [{grau}] Der Knoten wurde erreicht, seine Nachbarn jedoch noch nicht
abgearbeitet.
\item [{schwarz}] Der Knoten wurde komplett bearbeitet.
\end{lyxlist}

\subsubsection{Breitensuche (BFS)}

Start bei Knoten $s$. $\pi\left[u\right]=v$ heißt $v$ ist direkter
Vorgänger von $u$. $Q$ ist eine Queue.

\label{BFS}%
\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{BFS}$\left(G,s\right)$:
\begin{enumerate}
\item Färbe $s$ grau, setze $d\left[s\right]=0$, $\pi\left[s\right]=\textrm{\ensuremath{\bot}}$
und initialisiere $Q$ mit $s$.
\item Färbe alle Knoten $v\in V\setminus\left\{ s\right\} $ weiß und setze
$d\left[v\right]=+\infty$ und $\pi\left[v\right]=\bot$.
\item Falls $Q$ leer, \emph{Stop}(``BFS beendet''), sonst sei $u$ erster
Knoten in $Q$.
\item Für alle $v$ aus Adjazenzliste von $u$:
\begin{enumerate}
\item Falls $v$ weiß ist, färbe $v$ grau, setze $d\left[v\right]=d\left[u\right]+1$,
$\pi\left[v\right]=u$ und füge $v$ ans Ende von $Q$ ein.
\end{enumerate}
\item Entferne $u$ aus $Q$, färbe $u$ schwarz und gehe zu $\left(3\right)$.
\end{enumerate}
%
\end{minipage}}

Laufzeit: linear in Bezug auf Adjazenzstruktur. Das heißt $\mathcal{O}\left(V+E\right)$
bei Adjazenzlisten und $\mathcal{O}\left(V^{2}\right)$ bei Adjazenzmatrizen.
\begin{defn*}
Für $v\in V$ sei $\delta\left(s,u\right)$ die Zahl der Kanten des
kürzesten $\left(s,u\right)$-Weges, bzw. $\infty$ wenn kein solcher
existiert.
\end{defn*}
\begin{lem}
Sei $G=\left(V,E\right)$ ein Graph und $s\in V$.
\begin{itemize}
\item Für jede Kante $uv\in E$ gilt: $\delta\left(s,v\right)\leq\delta\left(s,u\right)+1$.
\item Nach Terminierung von BFS$\left(G,s\right)$ gilt: $\forall v\in V:d\left[v\right]\geq\delta\left(s,v\right)$
\item Enthält $Q$ während BFS$\left(G,s\right)$ $v_{1},v_{2},\ldots,v_{r}$
gilt: $d\left[v_{r}\right]\leq d\left[v_{1}\right]+1$ und $d\left[v_{i}\right]\leq d\left[v_{i+1}\right],1\leq i<r$
\end{itemize}
\end{lem}

\begin{prop}
Sei $G=\left(V,E\right)$, $s\in V$ und BFS$\left(G,s\right)$ ausgeführt.
Dann ist jeder Knoten, der von $s$ aus erreichbar ist, schwarz gefärbt
und es gilt $d\left[v\right]=\delta\left(s,v\right)$.
\end{prop}


\subsubsection{Tiefensuche (DFS)}

Kein spezieller Startknoten. Die Zeit der Grau-Färbung wird in $d\left[v\right]$
gespeichtert, die Zeit der Schwarz-Färbung (Terminierungszeit) in
$t\left[v\right].$

\label{DFS}%
\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{DFS}$\left(D\right)$:
\begin{enumerate}
\item Färbe alle Knoten $u\in V$ weiß und setze $\pi\left[u\right]=\bot$.
\item Setze globale Zeit $t=0$.
\item Für jeden Knoten $u\in V$:
\begin{enumerate}
\item Falls $u$ weiß gefärbt ist, dann DFSVisit$\left(u\right)$.
\end{enumerate}
\end{enumerate}
\rule[1ex]{1\columnwidth}{1pt}

\textbf{DFSVisit}$\left(u\right)$:
\begin{enumerate}
\item Färbe $u$ grau, setze $t=t+1$ und $d[u]=t.$
\item Für alle $v$ aus Adjazenzliste von $u$:
\begin{enumerate}
\item Falls $v$ weiß ist, dann setze $\pi\left[v\right]=u$ und vollziehe
DFSVisit$\left(v\right)$.
\end{enumerate}
\item Färbe $u$ schwarz, setze $t=t+1$ und $f\left[u\right]=t$.
\end{enumerate}
%
\end{minipage}}

Laufzeit: linear in Bezug auf Adjazenzstruktur. Das heißt $\mathcal{O}\left(V+A\right)$
bei Adjazenzlisten und $\mathcal{O}\left(V^{2}\right)$ bei Adjazenzmatrizen.
\begin{defn*}
Der \textbf{DFS-Wald} des (Di-)Graphen $G=\left(V,E\right)$ ist ein
Digraph der Form $\left(V,\left\{ \left\{ \pi\left[v\right],v\right\} |v\in V,\pi\left[v\right]\neq\bot\right\} \right)$.
Er symbolisiert also den Weg durch den Graphen während einer DFS.

Alle Kanten $\left\{ u,v\right\} $ aus $E$, die nicht zum Wald gehören
sind:
\begin{description}
\item [{Vorwärtskanten}] Es gibt einen $\left(u,v\right)$-Weg im DFS-Wald
\item [{Rückwärtskanten}] Es gibt einen $(v,u)$-Weg im DFS-Wald
\item [{Kreuzungskanten}] Es gibt keinen der Wege im DFS-Wald
\end{description}
Für ungerichtete Graphen gibt es nur Rückwärtskanten.
\end{defn*}
\begin{prop}
Ein Knoten $v$ ist Nachfolger eines Knotens $u$ im DFS-Wald genau
dann, wenn gilt: Zu dem Zeitpunkt, zu dem $u$ grau gefärbt wird,
ist $v$ von $u$ aus auf einem Weg erreichbar, der nur aus weißen
Knoten besteht.
\end{prop}


\subsection{Topologisches Sortieren}

Die topologische Sortierung eines Digraphen ist eine Knotenreihenfolge,
in der alle Kanten nur zu später auftretenden Knoten führen.

\label{TopSort}%
\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Topsort}$\left(D\right)$:
\begin{enumerate}
\item Initialisiere leere Liste $L=\emptyset$.
\item Führe DFS$\left(D\right)$ aus, mit Zusatz: Wenn ein Knoten $v$ schwarz
gefärbt wird, füge ihn am Anfang der Liste $L$ ein.
\item $L$ liefert topologische Sortierung.
\end{enumerate}
%
\end{minipage}}

Laufzeit: siehe DFS$\left(D\right)$
\begin{lem}
Ein Digraph $D$ ist genau dann kreisfrei, wenn DFS$\left(D\right)$
keine Ruckwärtskanten liefert.
\end{lem}

\begin{prop}
Ein azyklischer Digraph $D$ wird durch Topsort$\left(D\right)$ topologisch
sortiert.
\end{prop}


\subsection{Starke Zusammenhangskomponenten}

\label{StrongComponents}%
\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{StrongComponents}$\left(D\right)$:
\begin{enumerate}
\item Führe DFS$\left(D\right)$ aus, merke Terminierungszeiten $f\left[u\right]$
für alle $u\in V$.
\item Generiere $D^{\top}$.
\item Führe DFS$\left(D^{\top}\right)$ aus, wobei im Schritt $\left(3\right)$
die Knoten nach absteigenden Werten von $f\left[u\right]$ sortiert
werden.
\item Die Knoten jedes Baumes im DFS-Wald von $D^{\top}$ bestimmen eine
starke Zusammenhangskomponente.
\end{enumerate}
%
\end{minipage}}
\begin{lem}
Jeder Weg, der zwei Knoten aus derselben Komponente verbindet, enthält
nur Knoten aus dieser Komponente.
\end{lem}

\begin{lem}
Alle Knoten einer Komponente sind im gleichen DFS-Baum enthalten.
\end{lem}

\begin{defn*}
Für einen Knoten $u$ bezeichne $\phi(u)$ den Knoten $v$ mit der
größten Terminierungszeit bei DFS$\left(D\right)$, der von $u$ aus
in $D$ erreichbar ist, das heißt:

$\phi\left(u\right)=\mathrm{argmax}{}_{v}\left\{ f\left[v\right]|u\underset{D}{\rightarrow}v\right\} $
\end{defn*}
\begin{prop}
Für $D=\left(V,A\right)$ sei DFS$\left(D\right)$ ausgeführt. Dann
ist für jeden Knoten $\phi\left(u\right)$ Vorgänger von $u$ im DFS-Wald.
\end{prop}

\begin{prop}
Nach DFS$\left(D\right)$ liegen zwei Knoten $u$ und $v$ genau dann
in der gleichen Komponente, wenn $\phi\left(u\right)=\phi\left(v\right)$.
\end{prop}

\begin{prop}
Der Algorithmus StrongComponents identifiziert die starken Zusammenhangskomponenten
eines Digraphen.
\end{prop}


\section{Optimale Bäume und Branchings}

\subsection{Minimale aufspannende Bäume}

Die Probleme, einen minimalen, aufspannenden Baum oder einen maximalen,
aufspannenden Wald zu finden lassen sich einfach ineinander transformieren.
Darum beschränken wir uns auf ersteres.

\noindent %
\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Minimaler-aufspannender-Baum-Problem}

\smallskip{}

Gegeben ist ein Graph $G=\left(V,E\right)$ mit Kantengewichten $c_{e}$
für $e\in E$. Zu bestimmen ist ein aufspannender Baum für G, dessen
Gesamtgewicht möglichst klein ist.

(Wir nehmen an, dass $G$ zusammenhängend ist, da das Problem sonst
einzeln pro Komponente lösbar wäre.)%
\end{minipage}}

\subsubsection{Ein allgemeiner MST-Algorithmus}

Dieser Algorithmus färbt Kanten nach festen Regeln blau und rot. Es
ist stets die Invariante \emph{,,Es gibt einen minimalen, aufspannenden
Baum, der alle blauen und keine rote Kante enthält.``} erfüllt.
\begin{description}
\item [{Regel~B}] Wähle einen Schnitt, der keine blaue Kante enthält.
Färbe eine seiner kürzesten Kanten blau.
\item [{Regel~R}] Wähle einen Kreis, der keine rote Kante enthält. Färbe
eine seiner längsten Kanten rot.
\end{description}
\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{MinimumSpanningTree}$\left(G,c\right):$
\begin{enumerate}
\item Zu Beginn seien alle Kanten ungefärbt.
\item Wende Regeln B und R an, bis alle Kanten gefärbt sind.
\item Die blauen Kanten bilden einen minimalen aufspannenden Baum.
\end{enumerate}
%
\end{minipage}}
\begin{prop}
Der Algorithmus färbt alle Kanten eines zusammenhängenden Graphen
und erhält dabei die Invarianz-Bedingung, d.h. er berechnet einen
minimalen aufspannenden Baum.
\end{prop}


\subsubsection{Der Algorithmus von Boruvka}

\label{Boruvka}%
\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Boruvka}$\left(G,c\right)$:
\begin{enumerate}
\item Initialisiere $n$ blaue Bäume bestehend aus je einem Knoten.
\item Solange mehr als ein blauer Baum vorhanden ist, wähle gleichzeitig
zu jedem blauen Baum die minimale inzidente Kante und färbe alle ausgewählten
Kanten blau.
\item Die blauen Kanten bilden einen minimalen Baum.
\end{enumerate}
%
\end{minipage}}

Der Algorithmus kann blaue Kreise erzeugen, wenn es im Graphen Kanten
gleichen Gewichts gibt.

\subsubsection{Der Algorithmus von Kruskal}

\label{Kruskal}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Kruskal}$\left(G,c\right)$:
\begin{enumerate}
\item Initialisiere $n$ blaue Bäume bestehend aus je einem Knoten.
\item Sortiere die Kanten von $G$ nach nichtabsteigenden Gewichten, so
dass $c_{e_{1}}\leq c_{e_{2}}\leq\ldots\leq c_{e_{m}}$.
\item Für $i=1,2,\ldots,m:$
\begin{enumerate}
\item Sind die Endknoten von $e_{i}$ im gleichen blauen Baum, färbe $e_{i}$
rot, andernfalls blau.
\end{enumerate}
\item Die blauen Kanten bilden einen minimalen Baum.
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(E\log V\right)$, wenn die Bäume per fast-union-find
verwaltet werden. Ein Heap ermöglicht Optimierung bezöglich der Sortierung,
da abgebrochen werden kann, wenn es $n-1$ blaue Kanten gibt.

\subsubsection{Der Algorithmus von Prim}

Der Algorithmus verwendet nur Regel B und benötigt einen Startknoten
$s$.

\label{Prim}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Prim}$\left(G,c,s\right)$:
\begin{enumerate}
\item Initialisiere $n$ blaue Bäume bestehend aus je einem Knoten.
\item Solange noch blaue Bäume aus einem Knoten existieren, färbe minimale
Kante im Schnitt induziert durch den Baum, der $s$ enthält, blau.
\item Die blauen Kanten bilden einen minimalen Baum.
\end{enumerate}
%
\end{minipage}}

Es folgt eine einfach Implementierung. $T$ ist der angehende Baum:

\label{Prim1}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Prim1}$\left(G,c,s\right)$:
\begin{enumerate}
\item Setze $V_{T}=\left\{ s\right\} $, $T=\emptyset$ und $i=0$.
\item Falls $i=n-1$, \emph{Stop}(,,T ist MST``).
\item Bestimme $u\in V_{T}$ und $v\in V\setminus V_{T}$ mit $c_{uv}=\min\left\{ c_{xy}|x\in V_{T},y\in V\setminus V_{T}\right\} $.
\item Setze $V_{T}=V_{T}\cup\left\{ v\right\} $ und $T=T\cup\left\{ uv\right\} $
und $i=i+1$. Gehe zu (2).
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(VE\right)$

Es gibt eine bessere Implementierung.$t\left[v\right]$ speichert
den nächsten Baumknoten, $d\left[v\right]$ die zugehörige Distanz.

\label{Prim2}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Prim2}$\left(G,c,s\right)$:
\begin{enumerate}
\item Setze $V_{T}=\left\{ s\right\} $, $T=\emptyset$ und $i=0$. Setze
$d\left[v\right]=c_{sv}$ und $t\left[v\right]=s$, falls $sv\in E$,
setze $d\left[v\right]=\infty$ und $t\left[v\right]=\bot$, falls
$sv\notin E$.
\item Falls $i=n-1$, \emph{Stop}(,,T ist MST``).
\item Bestimme $v\in V\setminus V_{T}$ mit $d\left[v\right]=\min\left\{ d\left[u\right]|u\in V\setminus V_{T}\right\} $.
\item Setze $V_{T}=V_{T}\cup\left\{ v\right\} $ und $T=T\cup\left\{ t\left[v\right]v\right\} $.
\item Für alle $w$ adjazent zu $v$:
\begin{enumerate}
\item Falls $w\in V\setminus V_{T}$ und $c_{vw}<d\left[w\right]$, dann
setze $d\left[w\right]=c_{vw}$ und $t\left[w\right]=v$.
\end{enumerate}
\item Setze $i=i+1$ und gehe zu (2).
\end{enumerate}
%
\end{minipage}} 

\begin{tabular}{ll}
Laufzeit (naiv): & $\mathcal{O}\left(V^{2}\right)$\tabularnewline
Laufzeit (Heap): & $\mathcal{O}\left(E\log V\right)$ (besser für dünnbesetzte Graphen)\tabularnewline
Laufzeit (Fib-Heap): & $\mathcal{O}\left(E+V\log V\right)$\tabularnewline
\end{tabular}

\subsubsection{Der Round-Robin-Algorithmus}

\label{RoundRobin}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{RoundRobin}$\left(G,c\right)$:
\begin{enumerate}
\item Initialisiere $n$ blaue Bäume bestehend aus je einem Knoten.
\item Solange weniger als $n-1$ blaue Kanten vorhanden sind, wähle einen
blauen Baum, bestimme die kürzeste Kante im durch diesen Baum induzierten
Schnitt und färbe sie blau.
\item Die blauen Kanten bilden einen minimalen Baum.
\end{enumerate}
%
\end{minipage}}

Eine $\mathcal{O}\left(E\log\log V\right)$-Implementation ist möglich,
wenn immer der kleinste Baum gewählt wird.

\subsubsection{Eine Anwendung aufspannender Bäume}

Sogenannte 1-Bäume sind eine untere Schranke für eine optimale TSM-Tour.

\label{OneTree}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{OneTree}$\left(G,c\right)$:
\begin{enumerate}
\item Bestimme für die Knoten $\left\{ 2,3,\ldots,n\right\} $einen MST
$T$. Sei $c_{T}$ die Länge des MST.
\item Seien $e_{1}$ und $e_{2}$ die zwei kürzesten Kanten an Knoten $1$.
\item $T\cup\left\{ e_{1},e_{2}\right\} $ist optimaler 1-Baum mit Wert
$c_{T}+c_{e_{1}}+c_{e_{2}}$.
\end{enumerate}
%
\end{minipage}}

\subsection{Maximale Branchings}

Neue Notationen: $s:A\rightarrow V$, $t:A\rightarrow V$ und $c:A\rightarrow\mathbb{R}$
sind Start- und Endknoten sowie Gewichte von Kanten.

\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Maximales-Branching-Problem}

Gegeben ist ein Digraph $D=\left(V,A\right)$ mit Kantengewichten
$c_{e}$, für $e\in A$. Zu bestimmen ist ein Branching für $D$,
dessen Gesamtgewicht möglichst groß ist.%
\end{minipage}}

\subsubsection{Der Branching-Algorithmus von Edmonds}
\begin{defn}
Sei $D=\left(V,A\right)$ ein Digraph mit Kantengewichten $c_{e}$,
für $e\in A$.
\begin{lyxlist}{00.00.0000}
\item [{a)}] Eine Kante $e\in A$ heißt \textbf{kritisch}, falls $c\left(e\right)>0$
und falls $c\left(e^{\prime}\right)\leq c\left(e\right)$, für alle
$e^{\prime}\in A$ mit $t\left(e^{\prime}\right)=t\left(e\right)$.
\item [{b)}] Ein Subgraph $H\subseteq A$ heißt \textbf{kritisch}, falls
er nur aus kritischen Kanten besteht, jeder Knoten Endknoten von höchstens
einer dieser Kanten ist, und falls er inklusionsmaximal bezüglich
dieser Eigenschaft ist.
\end{lyxlist}
\end{defn}

\begin{lem}
Ein azyklischer kritischer Graph $H$ ist ein maximaler Branching.
\end{lem}

\begin{lem}
Sei $H$ ein kritischer Graph. Dann ist jeder Knoten von $H$ in maximal
einem Kreis enthalten.
\end{lem}

\begin{lem}
Seien $B$ ein Branching und $u$, $v$, $w$ drei Knoten. Falls $u\underset{B}{\rightarrow}v$
und $w\underset{B}{\rightarrow}v$, dann gilt entweder $u\underset{B}{\rightarrow}w$
oder $w\underset{B}{\rightarrow}u$.
\end{lem}

\begin{defn*}
Sei $B$ ein Branching. Eine Kante $e\notin B$ heißt \textbf{zulässig}
(relativ zu B), falls die Menge $B^{\prime}=B\cup\left\{ e\right\} \setminus\left\{ f|f\in B\wedge t\left(f\right)=t\left(e\right)\right\} $
ebenfalls ein Branching ist.
\end{defn*}
\begin{lem}
Sei $B$ ein Branching und $e\in A\setminus B$. Dann ist $e$ genau
dann zulässig relativ zu $B$, wenn kein Weg von $t\left(e\right)$
nach $s\left(e\right)$ in $B$ existiert.
\end{lem}

\begin{lem}
Sei $B$ ein Branching und $C$ ein Kreis mit der Eigenschaft, dass
keine Kante aus $C\setminus B$ zulässig relativ zu $B$ ist. Dann
gilt $\left|C\setminus B\right|=1$. 
\end{lem}

\begin{prop}
Sei $H$ ein kritischer Graph. Dann existiert ein Branching $B$ mit
maximalem Gewicht, so dass für jeden Kreis $C\subseteq H$ gilt $\left|C\setminus B\right|=1$.
\end{prop}

Im Folgenden bezeichne $V_{i}=V\left(C_{i}\right)$ und $a_{i}$ die
kürzeste Kante in $C_{i}$.
\begin{cor}
Sei $D=\left(V,A\right)$ ein Digraph mit Kantengewichten und $H$
ein kritischer Graph mit Kreisen $C_{i},i=1,2,\ldots,k$. Es existiert
ein gewichtsmaximales Branching $B$ mit den Eigenschaften
\begin{lyxlist}{00.00.0000}
\item [{a)}] $\left|C_{i}\setminus B\right|=1$, für $i=1,2,\ldots,k$
\item [{b)}] Falls für jede Kante $e\in B\setminus C_{i}$ gilt, dass $t\left(e\right)\notin V_{i},$dann
folgt $C_{i}\setminus B=\left\{ a_{i}\right\} $.
\end{lyxlist}
\end{cor}

\label{Branching (Schrumpfen)}%
\noindent\fbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule}%
\textbf{Schrumpfen von kritischen Graphen}:

Sei $\widetilde{V}=V\setminus\bigcup_{i=1}^{k}V_{i}$. Für $v\in V_{i}$
sei $\widetilde{e}\left(v\right)$ die Kante aus $C_{i}$ mit $t\left(\widetilde{e}\left(v\right)\right)=v$,
d.h. die Kreiskante mit Endknoten $v$.

\[
\begin{aligned}\overline{A}= & \left\{ e\in A|\text{für kein }i\text{ gilt }s\left(e\right)\in V_{i}\text{ und }t\left(e\right)\in V_{i}\right\} \\
= & A\setminus\bigcup_{i=1}^{k}A\left(V\left(C_{i}\right)\right)\text{,}\\
\overline{V}= & \widetilde{V}\cup\left\{ w_{1},w_{2},\ldots,w_{k}\right\} \text{, wobei die \ensuremath{w_{i}} neue Symbole sind,}\\
\overline{s}\left(e\right)= & \begin{cases}
s\left(e\right)\text{,} & \text{falls \ensuremath{s\left(e\right)\in\widetilde{V}},}\\
w_{i} & \text{falls \ensuremath{s\left(e\right)\in V_{i}},}
\end{cases}\\
\overline{t}\left(e\right)= & \begin{cases}
t\left(e\right)\text{,} & \text{falls \ensuremath{t\left(e\right)\in\widetilde{V}},}\\
w_{i} & \text{falls \ensuremath{t\left(e\right)\in V_{i}},}
\end{cases}\\
\overline{c}\left(e\right)= & \begin{cases}
c\left(e\right)\text{,} & \text{falls \ensuremath{t\left(e\right)\in\widetilde{V}},}\\
c\left(e\right)-c\left(\widetilde{e}\left(t\left(e\right)\right)\right)+c\left(a_{i}\right) & \text{falls \ensuremath{t\left(e\right)\in V_{i}}.}
\end{cases}
\end{aligned}
\]

Es entsteht ein neues Problem $\overline{P}$ im Digraphen $\overline{D}=\left(\overline{V},\overline{A}\right)$
mit den neuen Inzidenzfunktionen $\overline{s}$, $\overline{t}$
und Gewichtsfunktion $\overline{c}$.%
\end{minipage}}
\begin{prop}
Es gibt eine bijektive Abbildung zwischen $\mathcal{B}$ (der Menge
der Branchings im Originalproblem) und der Menge der Branchings im
Problem $\overline{P}$. Es korrespondiert das Branching $B\in\mathcal{B}$
mit dem Branching $\overline{B}=B\cap\overline{A}$ in $\overline{P}$
und es gilt:

\[
c\left(B\right)-\overline{c}\left(\overline{B}\right)=\sum_{i=1}^{k}c\left(C_{i}\right)-\sum_{i=1}^{k}c\left(a_{i}\right)\text{.}
\]
\end{prop}

\label{Branching}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Branching}$\left(D,c\right)$:
\begin{enumerate}
\item Bestimme einen kritischen Graphen $H$ für $D$.
\item Ist $H$ azyklisch, dann \emph{Stop}(,,$H$ ist optimales Branching
für $D$``).
\item Schrumpfe die Kreise von $H$, um $\overline{D}$ und $\overline{c}$
zu erhalten.
\item Berechne durch den rekursiven Aufruf \emph{Branching}$\left(\overline{D},\overline{c}\right)$
ein optimales Branching $\overline{B}$ für $\overline{D}$.
\item Expandiere das Branching $\overline{B}$ zu einem optimalen Branching
$B$ für $D$.
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(A\log V\right)$ oder $\mathcal{O}\left(V^{2}\right)$.

\subsubsection{Arboreszenzen und das asymmetrische TSP}

$\rightarrow$analog zum symmetrischen Fall

\section{Kürzeste Wege}

\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Kürstester-$\left(s,t\right)$-Weg-Problem}

Gegeben sind ein Digraph $D=\left(V,A\right)$ mit Kantengewichten
$c_{e}$ für $e\in A$, und zwei Knoten $s,t\in V$. Zu bestimmen
ist ein $\left(s,t\right)$-Weg in $D$, dessen Gesamtlänge möglichst
klein ist.%
\end{minipage}}

\subsection{Eigenschaften kürzester Wege}
\begin{defn*}
Im folgenden ist $s\in V$ der Startknoten, dessen kürzeste Wege berechnet
werden sollen. $\delta\left(u,v\right)$ ist die Länge des kürzesten
$\left(u,v\right)$-Weges, bzw. $+\infty$ (oder $-\infty$) wenn
keiner existiert. $\pi\left[v\right]$ ist der Vorgängerknoten von
$v$ auf dem kürstesten $\left(s,v\right)$-Weg.
\end{defn*}
\begin{lem}
Sei $p=\left(v_{1}v_{2},v_{2}v_{3},\ldots,v_{k-1}v_{k},\right)$ ein
kürzester Weg von $v_{1}$ nach $v_{k}$. Dann ist für $1\leq i\leq j\leq k$
der Teilweg $\left(v_{i}v_{i+1},\ldots,v_{j-1}v_{j},\right)$ ein
kürzester Weg von $v_{i}$ nach $v_{j}$.
\end{lem}

\begin{lem}
Für jede Kante $\left(u,v\right)$ gilt $\delta\left(s,v\right)\leq\delta\left(s,u\right)+c_{uv}$.
\end{lem}

Die \textbf{Standardinitialisierung} für $d$ ist $d\left[s\right]=0$
und $d\left[v\right]=\infty,v\in V\setminus\left\{ s\right\} $ und
$\pi\left[v\right]=\bot,v\in V$. 

\label{Correct}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Correct}$\left(u,v\right)$:

Falls $d\left[v\right]>d\left[u\right]+c_{uv}$, dann setze $d\left[v\right]=d\left[u\right]+c_{uv}$
und $\pi\left[v\right]=u$.%
\end{minipage}}
\begin{lem}
Nach Initialisierung gilt $d\left[v\right]\geq\delta\left(s,v\right)$,
für alle $v\in V$. Dies gilt auch nach Ausführung einer beliebigen
Folge von Correct()-Aufrufen. Falls einmal $d\left[v\right]=\delta\left(s,v\right)$
gilt, so kann $d\left[v\right]$nicht mehr verändert werden.
\end{lem}

\begin{lem}
$D$ enthalte keine von $s$ aus erreichbaren negativen Kreise und
die Standardinitialisierung sei ausgeführt. Für jede Folge von Korrekturoperationen
bildet der durch $\pi$ bestimmte Digraph $D_{\pi}$ eine Arboreszenz
mit Wurzel $s$.
\end{lem}


\subsection{Der Algorithmus von Dijkstra}

Der Algorithmus berechnet alle kürzesten Wege von $s$, wenn $c_{uv}\geq0$,
für alle $\left(u,v\right)\in A$.

\label{Dijkstra}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Dijkstra}$\left(D,c,s\right)$:
\begin{enumerate}
\item Setze $d\left[v\right]=\infty$, für alle $v\in V\setminus\left\{ s\right\} $,
$d\left[s\right]=0$ und $\pi\left[v\right]=\bot$ für alle $v\in V$.
\item $S=\emptyset,Q=V$.
\item Solange $Q\neq\emptyset$:
\begin{enumerate}
\item Bestimme $u$ mit $d\left[u\right]=\min_{v}\left\{ d\left[v\right]|v\in Q\right\} $.
\item $S=S\cup\left\{ u\right\} ,Q=Q\setminus\left\{ u\right\} $
\item Für jede Kante $\left(u,v\right)\in A$ mit $v\in Q$ führe \emph{Correct}$\left(u,v\right)$
aus.
\end{enumerate}
\end{enumerate}
%
\end{minipage}}

\begin{tabular}{ll}
Laufzeit (naiv): & $\mathcal{O}\left(V^{2}\right)$\tabularnewline
Laufzeit (Heap): & $\mathcal{O}\left(A\log V\right)$ (besser für dünnbesetzte Graphen)\tabularnewline
Laufzeit (Fib-Heap): & $\mathcal{O}\left(A+V\log V\right)$\tabularnewline
\end{tabular}
\begin{prop}
Nach Ausführung des Algorithmus von Dijkstra gilt $d\left[v\right]=\delta\left(s,v\right)$
für alle $v\in V$.
\end{prop}


\subsection{Der Algorithmus von Bellman und Ford}

\label{BellmanFord}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{BellmanFord}$\left(D,c,s\right)$:
\begin{enumerate}
\item Initialisiere $d\left[v\right]=\infty$, für alle $v\in V\setminus s$,
$d\left[s\right]=0,\pi\left[v\right]=\bot$ für alle $v\in V$.
\item Führe die folgende Schleife $\left(\left|V\right|-1\right)$-mal aus:
\begin{enumerate}
\item Für alle $\left(u,v\right)\in A$ führe \emph{Correct}$\left(u,v\right)$
aus.
\end{enumerate}
\item Für alle $\left(u,v\right)\in A$:
\begin{enumerate}
\item Falls $d\left[v\right]>d\left[u\right]+c_{uv}$ dann \emph{Stop}(,,Graph
enthält negativen Kreis``).
\end{enumerate}
\item \emph{Stop}(,,Der Kürzeste-Wege-Baum wurde berechnet``).
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(VA\right)$
\begin{lem}
$D$ enthalte keinen von $s$ aus erreichbaren negativen Kreis. Dann
gilt bei Terminierung des Bellman-Ford-Algorithmus $d\left[v\right]=\delta\left(s,v\right)$
für alle Knoten in $v$, die von $s$ aus erreichbar sind.
\end{lem}

\begin{cor}
Es gibt einen Weg von $s$ nach $v$ genau dann, wenn der Bellman-Ford-Algorithmus
mit $d\left[v\right]<\infty$ terminiert.
\end{cor}

\begin{prop}
Der Bellman-Ford-Algorithmus arbeitet korrekt, das heißt entweder
er stellt fest, dass $D$ einen negativen Kreis enthält, oder er berechnet
die Arboreszenz der kürzesten Wege von $s$ zu allen erreichbaren
Knoten.
\end{prop}


\paragraph{Yen-Variante}

Ersetze (2.1) durch:
\begin{lyxlist}{00.00.0000}
\item [{(2.1)}] Für $i=1,\ldots,n$: \emph{Correct}$\left(v_{i},v_{k}\right)$
für alle $\left(v_{i},v_{k}\right)\in A$ mit $i<k$.
\item [{(2.2)}] Für $i=n,n-1,\ldots,1$: \emph{Correct}$\left(v_{i},v_{j}\right)$
für alle $\left(v_{i},v_{j}\right)\in A$ mit $i>j$.
\end{lyxlist}

\paragraph{Variante von d\textquoteright Esopo und Pape}

Bevorzugt Knoten, die sich verbessert haben. Exponentielle Worst-Case-Laufzeit,
aber oft effizienter für dünne Graphen.

Modifikation der Correct-Operation:

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Correct}$\left(u,v\right)$:

Falls $d\left[v\right]>d\left[u\right]+c_{uv}$, dann:
\begin{enumerate}
\item Setze $d\left[v\right]=d\left[u\right]+c_{uv}$ und $\pi\left[v\right]=u$.
\item Falls $v$ noch nicht in $Q$ war, setze $v$ an das Ende von $Q$.
\item Falls $v$ schon in $Q$ war, aber gegenwärtig nicht $Q$ ist, dann
setze $v$ an den Anfang von $Q$.
\end{enumerate}
%
\end{minipage}}

Terminiert, wenn $Q$ leer.

\paragraph{Verfahren von Nicholson}

Sucht kürzesten $\left(s,t\right)$-Weg gleichzeitig von $s$ und
$t$.

\paragraph{$A^{\ast}$-Verfahren}

Verwendet Schätzwerte $s\left(v,t\right)$ für die Entfernung zum
Zielknoten, priorisiert Knoten mit niedrigem $d\left[v\right]+s\left(v,t\right)$.
Terminiert, wenn $d\left[t\right]$ und $s\left(s,t\right)$ nag genug
beieinander.

\subsection{Kürzeste Wege in azyklischen Digraphen}

\label{DAGShortestPath}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{DAGShortestPath}$\left(D,c,s\right)$:
\begin{enumerate}
\item Sei $t\left[1\right],\ldots,t\left[n\right]$ eine topologische Sortierung
der Knoten von $D$.
\item Setze $d\left[v\right]=\infty$, für alle $v\in V\setminus\left\{ s\right\} $,
$\pi\left[v\right]=\bot$, für alle $v\in V$, und $d\left[s\right]=0$.
\item Für $i=1,2,\ldots,n$:
\begin{enumerate}
\item Setze $u=t\left[i\right]$.
\item Für alle $v\in V$ mit $\left(u,v\right)\in A$ führe \emph{Correct$\left(u,v\right)$
aus.}
\end{enumerate}
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(V+A\right)$

\subsubsection{Berechnung optimaler Lösungen des Knapsack-Problems}


\subsubsection{Eine Anwendung in der Tourenplanung}


\subsubsection{Längste Wege}

Dies ist nur in azyklischen Digraphen möglich, oder wenn alle Kantengewichte
negativ oder 0 sind.

Entweder man komplementiert alle Gewichte oder ändert die Initialisierung
von $d$ in $-\infty$ und dreht den Vergleich in der \emph{Correct}-Operation
um.

\subsection{Kürzeste Wege zwischen allen Knotenpaaren}

Eine Möglichkeit wäre das $\left|V\right|$-malige Anwenden von Dijkstra
oder Bellman-Ford, was in der $\left|V\right|$-fachen Komplexität
resultiert.

\subsubsection{Der Algorithmus von Floyd und Warshall}

$D$ habe ganzzahlige Gewichte und keine negativen Kreise.

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{AllPairsShortestPaths}$\left(D,c\right)$:
\begin{enumerate}
\item Setze $d\left[i,j\right]=+\infty$, für alle $i,j\in V$, und $d\left[i,i\right]=0$,
für alle $i\in V$.
\item Für alle $\left(i,j\right)\in A$, setze $d\left[i,j\right]=c_{ij}$.
\item Solange es Knoten $i,j,k\in V$ gibt, mit $d\left[i,j\right]>d\left[i,k\right]+d\left[k,j\right]$
setze $d\left[i,j\right]=d\left[i,k\right]+d\left[k,j\right]$.
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(\left|V\right|^{2}\left(2\left|V\right|C\right)\right)$
mit $C$ = $\max\left\{ \left|c_{ij}\right||\left(i,j\right)\in A\right\} $
-> nicht poly!

Eine Verbesserung ergibt sich wie folgt:

Wenn alle kürzesten Wege bekannt sind, die nur die ersten $k-1$ Knoten
als Zwischenknoten verwenden, lässt sich ein kürzester Weg, der den
$k$-ten Knoten (und möglicherweise seine Vorgänger) als Zwischenknoten
nutzt durch $d\left(i,k\right)+d\left(k,j\right)$ bestimmen.

Sei $D^{\left(k\right)}$ eine Matrix mit $d_{ij}^{\left(k\right)}$
als kürzester Weg zwischen $i$ und $j$, der nur die ersten $k$
Knoten als Zwischenknoten nutzt:

\label{FloydWarshall}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{FloydWarshall}$\left(C\right)$:
\begin{enumerate}
\item Initialisiere $D^{\left(0\right)}=C$, mit $c_{ij}=+\infty$ wenn
keine Kante $\left(i,j\right)$ existiert.
\item Für $k=1,2,\ldots,\left|V\right|$:
\begin{enumerate}
\item Für $i=1,2,\ldots,\left|V\right|$:
\begin{enumerate}
\item Für $j=1,2,\ldots,\left|V\right|$:\\
$d_{ij}^{\left(k\right)}=\min\left\{ d_{ij}^{\left(k-1\right)},d_{ik}^{\left(k-1\right)}+d_{kj}^{\left(k-1\right)}\right\} $
\end{enumerate}
\end{enumerate}
\item $D^{\left(\left|V\right|\right)}$ enthält die Längen der kürzesten
Wege.
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(V^{3}\right)$

\label{Johnson}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Johnson}$\left(D,c\right)$:
\begin{enumerate}
\item Bilde $D^{\prime}=\left(V^{\prime},A^{\prime}\right)$ mit $V^{\prime}=V\cup\left\{ s\right\} $,
$A^{\prime}=A\cup\left\{ \left(s,v\right)|v\in V\right\} $ und setze
$c_{sv}=0$, für alle $v\in V$.
\item Führe \emph{Bellman-Ford}$\left(D^{\prime},c,s\right)$ aus.
\item Enthält $D^{\prime}$ negative Kreise, \emph{Stop}(,,Algorithmus
nicht anwendbar``)
\item Setze für jeden Knoten $v\in V:h\left[v\right]=\delta\left(s,v\right)$.
\item Setze für jede Kante $\left(u,v\right)\in A:\overline{c}_{uv}=c_{uv}+h\left[u\right]-h\left[v\right]$.
\item Für jeden Knoten $u\in V$:
\begin{enumerate}
\item Führe Dijkstra$\left(D,\overline{c},u\right)$ aus. Sei $\overline{\delta}\left(u,v\right)$
die Kürzeste-Wege-Distanz von $u$ nach $v\in V\setminus\left\{ u\right\} $
(bzgl. $\overline{c}$).
\item Für jedes $v\in V\setminus\left\{ u\right\} $ ist die Länge des kürzesten
$\left(u,v\right)$-Weges $\overline{\delta}\left(u,v\right)+h\left[v\right]-h\left[u\right]$.
\end{enumerate}
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(VA\log V\right)$ oder $\mathcal{O}\left(VA+V^{2}\log V\right)$
je nach Dijkstra-Implementierung

\subsection{Varianten kürzester Wege}

\subsubsection{Bottleneck-Probleme}

In einem Graphen wird ein $\left(s,t\right)$-Weg gesucht, dessen
kürzeste Kante größtmögliche Länge hat.

\paragraph{Initialisierung}

$d\left[v\right]=-\infty$, für alle $v\in V\setminus\left\{ s\right\} $,
$d\left[s\right]=+\infty,\pi\left[v\right]=\bot$, für alle $v\in V$.

\paragraph{Korrektur}

Falls $d\left[v\right]<\min\left\{ d\left[u\right],c_{uv}\right\} $,
dann setze $d\left[v\right]=\min\left\{ d\left[u\right],c_{uv}\right\} $
und $\pi\left[v\right]=u$.

\subsubsection{Netzwerke mit Gewinnen und Verlusten}

Das \textbf{Arbitrage-Problem} funktioniert wie ein Kürzeste-Wege-Problem,
nur dass Kanten auf einem Weg multipliziert werden. Entweder Initialisierung
und Correct werden angepasst, oder alle Kantengewichte logarithmiert.

\subsection{Kreise mit bestem Kosten-Zeit-Verhältnis}

Gesucht ist $\mu^{\ast}=\min_{B\text{ Kreis in }D}\mu\left(B\right)$
mit $\mu\left(B\right)=\frac{\sum_{\left(i,j\right)\in B}c_{ij}}{\sum_{\left(i,j\right)\in B}\tau_{ij}}$.

$\mu$ ist ein Schätzwert für $\mu^{\ast}\in\left[-\left|V\right|C,+\left|V\right|C\right]$,
welcher per Intervallschachtelung verbessert wird. $\left(C=\max c_{ij}\right)$

Es wird ein Digraph $\overline{D}$ erstellt mit $l_{ij}=c_{ij}-\mu\tau_{ij}$
für alle $\left(i,j\right)\in A$.
\begin{itemize}
\item Enthält $\overline{D}$ einen negativen Kreis, ist $\mu$ zu groß.
\item Enthält $\overline{D}$ nur positive Kreise, ist $\mu$ zu klein.
\item Enthält $\overline{D}$ einen Kreis der Länge $0$, minimiert dieser
die Zielfunktion.
\end{itemize}
Das Verfahren kann auch abgebrochen werden, wenn die Intervallgrenzen
weniger als $\frac{1}{n^{2}T^{2}}$ auseinander liegen. $\left(T=\max\tau_{ij}\right)$

Laufzeit: $\mathcal{O}\left(VA\log\left(CVT\right)\right)$

\section{Das Zuordnungsproblem}

\subsection{Anwendungen und Grundlagen}

\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
Perfektes-Matching-Problem in bipartiten Graphen

Sei $K_{n,n}$ der vollständige bipartite Graph mit jeweils $n$ Knoten
in den zwei Teilmengen $V_{1}$ und $V_{2}$ mit $V_{1}\cup V_{2}=V$
und Kantengewichten $c_{ij}$ für $i\in V_{1}$ und $j\in V_{2}$.
Gesucht ist ein perfektes Matching $\left(\forall v\in V:\left|\delta\left(v\right)\right|=1\right)$
in $K_{n,n}$ mit minimalem Gesamtgewicht.%
\end{minipage}}

\medskip{}

Das Problem wird mit Hilfe linearer Programmierung gelöst werden.
Es lässt sich wie folgt als lineares Programm darstellen:

\[
\begin{aligned}\text{(AP)} & \begin{aligned} & \min & \sum_{i=1}^{n} & \sum_{j=1}^{n}c_{ij}x_{ij}\\
 &  & \sum_{j=1}^{n} & x_{ij}=1\text{, für }i=1,2,\ldots,n\\
 &  & \sum_{i=1}^{n} & x_{ij}=1\text{, für }j=1,2,\ldots,n\\
 &  &  & x_{ij}\in\left\{ 0,1\right\} \text{, für }i=1,2,\ldots,n\text{, }j=1,2,\ldots,n
\end{aligned}
\end{aligned}
\]

Das duale Programm dazu ist:

\[
\begin{aligned}\text{(AP}_{D}\text{)} & \begin{alignedat}{1}\max & \sum_{i=1}^{n}u_{i}+\sum_{j=1}^{n}v_{j}\\
 & u_{i}+v_{j}\leq c_{ij}\text{, für }1,2,\ldots,n\text{, }j=1,2,\ldots n.
\end{alignedat}
\end{aligned}
\]

\begin{prop*}
Schwacher Dualitätssatz (am Beispiel)

Wenn $x$ zulässig für (AP) ist und $\left(u,v\right)$ zulässig für
(AP$_{D}$) sind, gilt: 

\[
\sum_{i=1}^{n}\sum_{j=1}^{n}c_{ij}x_{ij}\geq\sum_{i=1}^{n}u_{i}+\sum_{j=1}^{n}v_{j}
\]
\end{prop*}
%
\begin{prop*}
Satz vom komplenetären Schlupf (am Bsp.)

Ein Paar von zulässigen Lösungen $x$ für (AP) und $\left(u,v\right)$
für (AP$_{D}$) sind genau dann optimal, wenn gilt

\[
u_{i}+v_{j}<c_{ij}\Rightarrow x_{ij}=0
\]

bzw.

\[
x_{ij}>0\Rightarrow u_{i}+v_{j}=c_{ij}
\]
\end{prop*}

\subsection{Die Ungarische Methode}

\label{HungarianMethod}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{HungarianMethod}$\left(n,C\right)$:
\begin{enumerate}
\item Bestimme eine dual zulässige Startlösung $\left(u^{0},v^{0}\right)$,
setze $i=0$.
\item Konstruiere zu $\left(u^{i},v^{i}\right)$ einen 0/1-Vektor $x^{i}$,
so dass die Bedingungen vom komplementären Schlupf erfüllt sind.
\item Beschreibt $x^{i}$ eine Zuordnung, \emph{Stop}(,,Zuordnung optimal``)
\item Berechne eine neue dual zulässige Lösung $\left(u^{i+1},v^{i+1}\right)$,
setze $i=i+1$, gehe zu (2).
\end{enumerate}
%
\end{minipage}}

(Dies ist die grobe Idee des Algorithmus)
\begin{defn}
Folgende Definitionen werden für die Methode benötigt:
\begin{lyxlist}{00.00.0000}
\item [{a)}] Für eine dual zulässige Lösung $\left(u,v\right)$ heißt die
Matrix $\overline{C}=\left(\overline{c}_{ij}\right)$ mit $\overline{c}_{ij}=c_{ij}-u_{i}-v_{j}$
die \textbf{reduzierte Matrix}.
\item [{b)}] Sei $\overline{C}$ eine reduzierte Matrix. eine Menge $N\subseteq\left\{ 1,\ldots,n\right\} \times\left\{ 1,\ldots,n\right\} $
heißt Menge von \textbf{unabhängigen Nullen}, falls
\begin{enumerate}
\item $\overline{c}_{ij}=0$, für alle $\left(i,j\right)\in N$,
\item $\left|\left\{ j|\left(i,j\right)\in N\right\} \right|\leq1$, für
alle $i=1,\ldots,n$,
\item $\left|\left\{ i|\left(i,j\right)\in N\right\} \right|\leq1$, für
alle $j=1,\ldots,n$.
\end{enumerate}
\item [{c)}] Eine \textbf{Überdeckung }einer reduzierten Matrix ist eine
Menge von Zeilen- und Spaltenindizes, so dass die zugehörigen Zeilen
und Spalten sämtliche Nullelemente von $\overline{C}$ enthalten.
\end{lyxlist}
\end{defn}

\begin{prop}
Sei $\overline{C}$ eine reduzierte Matrix. Die maximale Kardinalität
einer Menge von unabhängigen Nullen ist gleich der minimalen Kardinalität
einer Überdeckung.

(In einem bipartiten Graphen ist die maximale Kardinalität eines Matchings
gleich der minimalen Kardinalität einer Kantenüberdeckung mit Knoten.)
\end{prop}


\subsubsection{Bestimmung einer Startlösung}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Start}$\left(n,C\right)$:
\begin{enumerate}
\item Berechne Zeilenminima $u_{i}=\min\left\{ c_{ij}|j=1,\ldots,n\right\} $,
für alle $i=1,\ldots,n$.
\item Setze $\overline{c}_{ij}=c_{ij}-u_{i}$, für alle $i=1,\ldots,n$,
$j=1,\ldots,n$.
\item Berechne Spaltenminima $v_{j}=\min\left\{ c_{ij}|i=1,\ldots,n\right\} $,
für alle $j=1,\ldots,n$.
\item Setze $\overline{c}_{ij}=\overline{c}_{ij}-v_{j}$, für alle $i=1,\ldots,n$,
$j=1,\ldots,n$.
\end{enumerate}
%
\end{minipage}}

Wir gehen nun spaltenweise vor und zeichnen die Null mit dem niedrigsten
Zeilenindex als unabhängige Null aus.

\subsubsection{Bestimmung einer minimalen Überdeckung}

\textbf{}%
\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{MinimusCover}$\left(n,\overline{C}\right)$:
\begin{enumerate}
\item Alle Zeilen und Spalten von $\overline{C}$ seien unmarkiert und nicht
überprüft. Sind $n$ unabhängige Nullen vorhanden gehe zu (5).
\item Alle Zeilen ohne unabhängige Null erhalten die Markierung ,,($-$)``.
\item Sei $i$ eine markierte, noch nicht überprüfte Zeile.\\
Gibt es keine solche Zeile, so gehe zu (4).
\begin{enumerate}
\item Erkläre $i$ für überprüft.
\item Sei $j$ eine unmarkierte Spalte, die in Zeile $i$ eine Null enthält.\\
Gibt es keine solche Spalte, gehe zu (3).
\item Markiere $j$ mit ,,(i)``.
\item Besitzt $j$ schon eine unabhängige Null gehe zu (3.2).\\
Andernfalls kann durch Verfolgen der Markierungen ausgehend von $j$
eine alternierende Kette von abhängigen und unabhänigen Nullen konstruiert
werden. Ändere die Klassifizierung dieser Nullen und gehe zu (1).
\end{enumerate}
\item Sei $j$ eine markierte, noch nicht überprüfte Spalte.\\
Gibt es keine solche Spalte, so gehe zu (5).
\begin{enumerate}
\item Erkläre $j$ für überprüft.
\item Markiere die Zeile, in der die unabhängige Null von Spalte $j$ steht,
mit ,,(j)``.
\item Gehe zu (3).
\end{enumerate}
\item Die Maximalzahl unabhängiger Nullen ist berechnet. Die zugehörige
minimale Überdeckung ergibt sich durch Zeilen, die nicht markiert
sind und Spalten, die markiert sind.
\end{enumerate}
%
\end{minipage}}

\subsubsection{Korrektur der Duallösung}

$I$ bezeichnet die Indizes der Zeilen der minimalen Überdeckung,
$J$ die der Spalten.

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{DualUpdate}$\left(n,\overline{C},I,J\right)$:
\begin{enumerate}
\item Setze $\delta=\min\left\{ \overline{c}_{ij}|i\notin I\wedge j\notin J\right\} $.
\item Setze $\begin{aligned}u_{i}=\begin{cases}
u_{i}+\delta\text{,} & \text{für }i\notin I\text{,}\\
u_{i} & \text{sonst,}
\end{cases} & \;\;\;\; & v_{j}=\begin{cases}
v_{j}-\delta\text{,} & \text{für }j\notin J\text{,}\\
v_{j} & \text{sonst.}
\end{cases}\end{aligned}
$
\item Setze $\overline{c}_{ij}=\begin{cases}
\overline{c}_{ij}-\delta\text{,} & \text{für }i\notin I,j\notin J\text{,}\\
\overline{c}_{ij}+\delta\text{,} & \text{für }i\in I,j\in J\text{,}\\
\overline{c}_{ij}, & \text{sonst.}
\end{cases}$
\end{enumerate}
%
\end{minipage}}
\begin{prop}
Die Ungarische Methode löst Zuordnungsprobleme in der Zeit $\mathcal{O}\left(n^{3}\right)$.
\end{prop}


\subsection{Ein dualer Algorithmus}

Im Folgenden werden diese Notationen genutzt:
\begin{itemize}
\item $w_{ij}=c_{ij}-u_{i}-v_{j}$
\item $I=\left\{ 1,2,\ldots,n\right\} $ ist die Menge der Zeilenknoten
\item $J=\left\{ 1,2,\ldots,n\right\} $ ist die Menge der Spaltenknoten
\item $G\left(I,J\right)$ ist der vollständige, bipartite Graph mit Kantenmenge
$\left\{ \left(i,j\right)|i\in I,j\in J\right\} $.
\end{itemize}
\begin{defn}
Sei $F$ ein Subgraph von $G\left(I,J\right)$.
\begin{lyxlist}{00.00.0000}
\item [{a)}] $F$ heißt dual zulässig, falls es einen dual zulässigen Vektor
$\left(u,v\right)$ gibt, so dass $w_{ij}=0$, für alle $\left(i,j\right)\in F$.
\item [{b)}] $F$ heißt primal zulässig, falls es einen primal zulässigen
Vektor $x$ gibt, so dass $x_{ij}=0$, für alle $\left(i,j\right)\in F$.
\end{lyxlist}
\end{defn}

\begin{lem}
Ist $F$ ein primal und dual zulässiger Subgraph von $G\left(I,J\right)$,
dann sind die zugehörigen Vektoren $\left(u,v\right)$ und $x$ optimal
für (AP) bzw. (AP$_{D}$).
\end{lem}

\begin{defn*}
Sei $F$ ein Subgraph von $G\left(I,J\right)$. Ein Knoten hat \textbf{Valenz}
$d$ (bzgl. F), falls sein Knotengrad in F gleich $d$ ist.
\end{defn*}
\begin{defn}
Ein Subgraph $F$ von $G\left(I,J\right)$ heißt \textbf{Superwald}
mit einer Menge von Wurzeln aus $J$, falls gilt:
\end{defn}

\begin{itemize}
\item $F$ ist ein aufspannender Wald
\item Jede Komponente von $F$ enthält genau eine Wurzel
\item Jeder Knoten aus J, der keine Wurzel ist, hat Valenz 2.
\end{itemize}
\begin{defn*}
Ein Superwald $F$ lässt sich in den \textbf{Überschuss-Wald} $F^{S}$
und den \textbf{Defizit-Wald} $F^{D}$ partitionieren, mit

$F^{S}=\text{Vereinigung der Komponenten von \ensuremath{F}, deren Wurzeln Valenz \ensuremath{\geq2} haben,}$

$F^{D}=\text{Vereinigung der Komponenten von \ensuremath{F}, deren Wurzeln Valenz \ensuremath{0} oder \ensuremath{1} haben.}$
\end{defn*}
\begin{lem}
Ist $F$ dual zulässiger Superwald mit $F^{S}=\emptyset$, dann ist
der zugehörige Vektor $\left(u,v\right)$ eine Optimallösung von (AP$_{D}$)
und $F$ enthält eine optimale Zuordnung.

\label{AKP}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{\textit{AKP}}\textit{$\left(C\right)$:}
\begin{enumerate}
\item Bestimme einen dual zulässigen Superwald $F_{0}$ mit Dualvariablen
$\left(u^{0},v^{0}\right)$ und setze $i=0$.
\item Falls $F_{i}$ dual zulässig und $F_{i}^{S}$ leer ist, \emph{Stop}(,,$F_{i}$
enthält eine optimale Zuordnung``).
\item Iteration $i$:
\begin{enumerate}
\item Bestimme eine geeignete Kante $\left(g,h\right)$.
\item Konstruiere mit Hilfe von $\left(g,h\right)$ einen neuen Superwald
$F_{i+1}$.
\item Berechne neue Dualvariablen $\left(u^{i+1},v^{i+1}\right)$.
\item Setze $i=i+1$ und gehe zu (2).
\end{enumerate}
\end{enumerate}
%
\end{minipage}}
\end{lem}


\subsubsection{Bestimmung einer Startlösung}

Bestimme $u_{i}$ und $v_{j}$ als Zeilen- und Spaltenminima. Erstelle
Subgraph $F=\left\{ \left(i,j\right)|w_{ij}=0\right\} $. Entferne
Kanten und zeichne Knoten aus $J$ als Wurzeln aus, bis $F$ ein Subgraph
ist.

\subsubsection{Korrektur des Superwaldes}

Wähle die Kante $\left(g,h\right)$ mit kleinstem $w_{ij}$, die einen
$I$-Knoten im Überschuss-Wald und einen $J$-Knoten im Defizit-Wald
verbindet und füge sie dem Superwald hinzu:

\[
\delta=w_{gh}=\min\left\{ w_{ij}|i\in I\cap F_{m}^{S},j\in J\cap F_{m}^{D}\right\} 
\]

Die Superwald-Eigenschaft muss wiederhergestellt werden. Es können
4 Fälle auftreten.\\
In Fall 1 und 2 wird der Überschuss-Wald größer:

\begin{tabular}{|>{\centering}p{0.5\textwidth}|>{\centering}p{0.5\textwidth}|}
\hline 
\textbf{Fall 1:} $h$ ist eine Wurzel mit Valenz 1 & \textbf{Fall 2:} $h$ ist keine Wurzel (und hat Vater $k$)\tabularnewline
\hline 
\hline 
\includegraphics[scale=0.17]{diagramme/akp_case1} & \includegraphics[scale=0.17]{diagramme/akp_case2}\tabularnewline
\hline 
$\begin{aligned}F_{m}^{\ast}= & \text{ Komponente von \ensuremath{F_{m}}, die \ensuremath{h} enthält}\\
F_{m+1}^{D}= & F_{m}^{D}\setminus F_{m}^{\ast}\\
F_{m+1}^{S}= & F_{m}^{S}\cup F_{m}^{\ast}\cup\left\{ \left(g,h\right)\right\} 
\end{aligned}
$ & $\begin{aligned}F_{m}^{\ast}= & \text{ Komponente von \ensuremath{F_{m}^{D}\setminus\left\{ \left(k,h\right)\right\} }, die \ensuremath{h} enthält}\\
F_{m+1}^{D}= & F_{m}^{D}\setminus\left(F_{m}^{\ast}\cup\left\{ \left(k,h\right)\right\} \right)\\
F_{m+1}^{S}= & F_{m}^{S}\cup\left(F_{m}^{\ast}\cup\left\{ \left(g,h\right)\right\} \right)
\end{aligned}
$\tabularnewline
\hline 
\end{tabular}

In Fall 3 und 4 wird der Überschuss-Wald kleiner:

\begin{tabular}{|>{\centering}p{0.5\textwidth}|>{\centering}p{0.5\textwidth}|}
\hline 
\textbf{Fall 3:} $h$ ist isolierte Wurzel und die Wurzel $j$ der
Komponente von $g$ hat Valenz 2 & \textbf{Fall 4:} $h$ ist isolierte Wurzel und die Wurzel $j$ der
Komponente von $g$ hat Valenz >2\tabularnewline
\hline 
\hline 
\includegraphics[scale=0.17]{diagramme/akp_case3} & \includegraphics[scale=0.17]{diagramme/akp_case4}\tabularnewline
\hline 
$\begin{aligned}F_{m}^{\ast}= & \text{ Komponente von \ensuremath{F_{m}^{S}}, die \ensuremath{g} enthält}\\
F_{m+1}^{D}= & F_{m}^{D}\cup F_{m}^{\ast}\cup\left\{ \left(g,h\right)\right\} \\
F_{m+1}^{S}= & F_{m}^{S}\setminus F_{m}^{\ast}
\end{aligned}
$ & $\begin{aligned}F_{m}^{\ast}= & \text{ Komponente von \ensuremath{F_{m}^{S}\setminus\left\{ \left(j,i\right)\right\} }, die \ensuremath{g} enthält,}\\
 & \text{mit \ensuremath{i} als Sohn von \ensuremath{j} im Ast der \ensuremath{g} enthält}\\
F_{m+1}^{D}= & F_{m}^{D}\cup F_{m}^{\ast}\cup\left\{ \left(g,h\right)\right\} \\
F_{m+1}^{S}= & F_{m}^{S}\setminus\left(F_{m}^{\ast}\cup\left\{ \left(j,i\right)\right\} \right)
\end{aligned}
$\tabularnewline
\hline 
\end{tabular}

\subsubsection{Korrektur der Dualvariablen}

$F_{m}^{\ast}$ ist anschaulich die Komponente, die ,,umgehängt``
wurde.

Ist Fall 1 oder 2 eingetreten, gilt:

\[
u_{i}=\begin{cases}
u_{i}-\delta, & \text{falls }i\in F_{m}^{\ast}\\
u_{i} & \text{sonst,}
\end{cases}
\]

\[
v_{j}=\begin{cases}
v_{j}+\delta, & \text{falls }j\in F_{m}^{\ast}\\
v_{j} & \text{sonst.}
\end{cases}
\]

In Fall 3 und 4 sind $+$ und $-$ vertauscht.
\begin{lem}
Falls die Teilwälder $F_{m}^{D}$ und $F_{m}^{S}$ dual zulässig sind,
dann gilt $\delta_{m+1}\geq\delta_{m}$ und $\delta_{m+1}\geq$-$\delta_{m}$.
\end{lem}

\begin{lem}
Falls $F_{m}^{D}$ und $F_{m}^{S}$ dual zulässig sind, dann auch
$F_{m+1}^{D}$ und $F_{m+1}^{S}$.
\end{lem}

\begin{prop}
Der AKP-Algorithmus arbeitet korrekt und löst das Zuordnungsproblem
mit Zeitkomplexität $\mathcal{O}\left(n^{3}\right)$.
\end{prop}


\section{Maximale Flüsse und minimale Schnitte}
\begin{defn*}
Ein \textbf{Flussnetzwerk} ist ein Digraph $D=\left(V,A\right)$ mit
Kantenkapazitäten $c\left(u,v\right)\geq0$ für alle Kanten $\left(u,v\right)$,
einer \textbf{Quelle} $s\in V$ und einer \textbf{Senke} $t\in V$.
$D$ ist zusammenhängend und für jeden Knoten $v\in V$ existiert
ein $\left(s,v\right)$-Weg so wie ein $\left(v,t\right)$-Weg.
\end{defn*}
\begin{defn}
Ein \textbf{$\left(s,t\right)$-Fluss} in $D$ ist eine Funktion $f:V\times V\rightarrow\mathbb{R}$
mit den Eigenschaften

$\begin{aligned}f\left(u,v\right)\leq & c\left(u,v\right)\text{, für alle }u,v\in V & \text{(Kapazitätsbeschränkung)}\\
f\left(u,v\right)= & -f\left(u,v\right)\text{, für alle }u,v\in V & \text{(Antisymmetrie)}\\
\sum_{v\in V}f\left(u,v\right)= & 0\text{, für alle }u\in V\setminus\left\{ s,t\right\}  & \text{(Flusserhaltung)}
\end{aligned}
$

Die Zahl $f\left(u,v\right)$ heißt Netto-Fluss von $u$ nach $v$.
Der \textbf{Wert} von $f$ ist $\left|f\right|:=\sum_{v\in V}f\left(s,v\right)$.

\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Maximaler-$\left(s,t\right)$-Fluss-Problem}

\smallskip{}

Gegeben sind ein Digraph $D=\left(V,A\right)$ mit Kantenkapazitäten
und zwei Knoten $s,t\in V$. Zu bestimmen ist ein $\left(s,t\right)$-Fluss
maximalen Werts.%
\end{minipage}}

Für $\left(u,v\right)\notin A$ setzen wir $c\left(u,v\right)=0$.

Der \textbf{positive Nettofluss} in einen Knoten $v$ ist definiert
als 
\[
\sum_{\substack{u\in V\\
f\left(u,v\right)>0
}
}f\left(u,v\right)
\]

Der positive Nettofluss \emph{aus} einem Knoten ist analog.

Für Knotenmengen $X$ und $Y$ gilt die Kurzschreibweise

\[
f\left(X,Y\right)=\sum_{x\in X}\sum_{y\in Y}f\left(x,y\right)
\]
\end{defn}

\begin{lem}
Sei $D$ ein Netzwerk und $f$ ein Fluss.
\begin{lyxlist}{00.00.0000}
\item [{a)}] Für $X\subseteq V$ gilt $f\left(X,X\right)=0$.
\item [{b)}] Für $X,Y\subseteq V$ gilt $f\left(X,Y\right)=-f\left(Y,X\right)$.
\item [{c)}] Für $X,Y,Z\subseteq V$ mit $X\cap Y=\emptyset$ gilt $f\left(X\cup Y,Z\right)=f\left(X,Z\right)+f\left(Y,Z\right)$
und $f\left(Z,X\cup Y\right)=f\left(Z,X\right)+f\left(Z,Y\right)$.
\end{lyxlist}
\end{lem}


\subsection{Der Algorithmus von Ford und Fulkerson}
\begin{defn*}
Die \textbf{Restkapazität} ist definiert als $c_{f}\left(u,v\right)=c\left(u,v\right)-f\left(u,v\right)$.
Das \textbf{reduzierte Netzwerk} $D_{f}=\left(V,A_{f}\right)$ mit
$A_{f}=\left\{ \left(u,v\right)\in V\times V|c_{f}\left(u,v\right)>0\right\} $
enthält die möglichen, zusätzlichen Nettoflüsse.
\end{defn*}
\begin{lem}
Sei $D$ ein Netzwerk mit $\left(s,t\right)$-Fluss $f$. $D_{f}$
sei das zugehörige reduzierte Netzwerk und $f^{\prime}$ sei ein $\left(s,t\right)$-Fluss
in $D_{f}$. Dann ist $\overline{f}$ definiert durch $\overline{f}\left(u,v\right)=f\left(u,v\right)+f^{\prime}\left(u,v\right)$
ein $\left(s,t\right)$-Fluss in $D$ mit Wert $\left|f\right|+\left|f^{\prime}\right|$.
\end{lem}

\begin{defn*}
Ein einfacher $\left(s,t\right)$-Weg in $D_{f}$ heißt \textbf{augmentierender
Weg} $P$ mit \textbf{Restkapazität} $c_{f}\left(P\right)=\min\left\{ c_{f}\left(u,v\right)|\left(u,v\right)\in P\right\} $.
\end{defn*}
%
\begin{defn*}
Ein \textbf{$\left(s,t\right)$-Schnitt} $\left(S:T\right)$ ist eine
Partition von $V$ in $S$ und $T=V\setminus S$, wobei $s\in S$
und $t\in T.$ Der \textbf{Nettofluss über dem Schnitt} $\left(S:T\right)$
ist definiert als $f\left(S,T\right)$. Seine Kapazität ist $c\left(S:T\right)={\displaystyle \sum_{u\in S}\sum_{v\in T}c\left(u,v\right)}$.
\end{defn*}
\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Minimaler-$\left(s,t\right)$-Schnitt-Problem}

\smallskip{}

Gegeben sind ein Digraph $D=\left(V,A\right)$ mit Kantenkapazitäten
und zwei Knoten $s,t\in V$. Zu bestimmen ist ein $\left(s,t\right)$-Schnitt
minimaler Kapazität.%
\end{minipage}}
\begin{lem}
Seien $f$ ein $\left(s,t\right)$-Fluss $D$ und $\left(S:T\right)$
ein $\left(s,t\right)$-Schnitt. Dann gelten:
\begin{lyxlist}{00.00.0000}
\item [{a)}] $f\left(S,T\right)=\left|f\right|$.
\item [{b)}] $\left|f\right|\leq c\left(S:T\right)$.
\end{lyxlist}
\end{lem}

\begin{prop}
\textbf{(Max-Flow-Min-Cut-Theorem)}

Sei $f$ ein $\left(s,t\right)$-Fluss in $D$. Die folgenden Aussagen
sind äquivalent:
\begin{itemize}
\item $f$ ist maximaler Fluss.
\item Das reduzierte Netzwerk enthält keinen augmentierenden Weg.
\item Es gibt einen Schnitt $\left(S:T\right)$ mit $c\left(S:T\right)=\left|f\right|$.
\end{itemize}
\end{prop}

\label{FordFulkerson}%
\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{FordFulkerson}$\left(D,c,s,t\right)$:
\begin{enumerate}
\item Für alle $\left(u,v\right)\in A$ setze $f\left[u,v\right]=f\left[v,u\right]=0$.
\item Konstruiere das reduzierte Netzwerk $D_{f}$.
\item Falls kein augmentierender $\left(s,t\right)$-Weg existiert, \emph{Stop}(,,$f$
ist maximal``), andernfalls sei $P$ ein solcher Weg mit Restkapazität
$c_{f}\left(P\right)$.
\item Für jede Kante $\left(u,v\right)$ des Weges $P$ setze $f\left[u,v\right]=f\left[u,v\right]+c_{f}\left(P\right)$
und $f\left[v,u\right]=-f\left[u,v\right]$.
\item Gehe zu (2).
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(A\left|f^{\ast}\right|\right)$ -> nicht
poly!

Ein minimaler Schnitt wird gleich mitgeliefert. Eine Seite sind alle
Knoten, zu denen kein augmentierender Weg mehr gefunden werden kann.
\begin{cor}
Wenn alle Kapazitäten ganzzahlig sind, dann existiert ein ganzzahliger
maximaler Fluss.
\end{cor}

\begin{prop}
Sei $f$ ein $\left(s,t\right)$-Fluss in $D$. Dann gibt es eine
Familie von $\left(s,t\right)$-Wegen $\mathcal{P}$ und (gerichteten)
Kreisen $\mathcal{C}$ in $D$ mit Gewichten $w_{P},P\in\mathcal{P}$,
und $w_{C},C\in\mathcal{C}$, so dass
\[
f\left(u,v\right)=\sum_{P\in\mathcal{P}}\sum_{\left(u,v\right)\in P}w_{P}+\sum_{C\in\mathcal{C}}\sum_{\left(u,v\right)\in C}w_{C}
\]
\end{prop}


\subsection{Der Satz von Menger}

(Dieses Kapitel zeigt, wie toll man einige Dinge mit Flüssen beweisen
kann und \emph{ergibt} ohne die Beweise leider nicht viel Sinn.)
\begin{prop}
Seien $D=\left(V,A\right)$ ein gerichteter Graph und $s,t$ zwei
Knoten in $V$. Für $k\geq1$ gibt es $k$ kantendisjunkte $\left(s,t\right)$-Wege
genau dann, wenn es auch nach Entfernen von $k-1$ beliebigen Kanten
noch einen Weg von $s$ nach $t$ gibt.
\end{prop}

\begin{prop}
Seien $D=\left(V,A\right)$ ein Digraph und $s,t$ zwei nicht benachbarte
Knoten in $V$. Für $k\geq1$ gibt es $k$ intern knotendisjunkte
$\left(s,t\right)$-Wege genau dann, wenn es auch nach Entfernen von
$k-1$ beliebigen Knoten noch einen Weg von $s$ nach $t$ gibt.
\end{prop}


\subsection{Der Algorithmus von Edmonds und Karp}

\label{EdmondsKarp}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{EdmondsKarp}$\left(D,c,s,t\right)$:
\begin{enumerate}
\item Für alle $\left(u,v\right)\in A$ setze $f\left[u,v\right]=f\left[v,u\right]=0$.
\item Konstruiere das reduzierte Netzwerk $D_{f}$.
\item Falls kein augmentierender $\left(s,t\right)$-Weg existiert, \emph{Stop}(,,$f$
ist maximal``), andernfalls sei $P$ ein solcher Weg \emph{mit möglichst
wenigen Kanten} und Restkapazität $c_{f}\left(P\right)$.
\item Für jede Kante $\left(u,v\right)$ des Weges $P$ setze $f\left[u,v\right]=f\left[u,v\right]+c_{f}\left(P\right)$
und $f\left[v,u\right]=-f\left[u,v\right]$. Gehe zu (2).
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(VA^{2}\right)$

$\delta_{f}\left(u,v\right)$ ist die Kürzeste-Wege-Distanz von $u$
nach $v$ im reduzierten Netzwerk, gemessen in Anzahl der Kanten.
\begin{lem}
Die Edmonds-Karp-Variante werde auf das Netzwerk$D=\left(V,A\right)$
mit Quelle $s$ und Senke $t$ angewendet.

Dann nehmen für jeden Knoten $v\in V\setminus\left\{ s,t\right\} $
die Distanzen $\delta_{f}\left(s,v\right)$ bei jeder Augmentierung
nicht ab.
\end{lem}

\begin{prop}
Die Edmonds-Karp-Variante führt $\mathcal{O}\left(VA\right)$ Augmentierungen
durch.
\end{prop}


\subsection{Die Skalierungsvariante von Ahuja und Orlin}

\label{ScalingMaxFlow}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{ScalingMaxFlow}$\left(D,c,s,t\right)$:
\begin{enumerate}
\item Setze $C=\max\left\{ c\left(u,v\right)|\left(u,v\right)\in A\right\} $.
\item Beginne mit dem $\left(s,t\right)$-Fluss $f\equiv0$.
\item Setze $K=2^{\left\lfloor \log_{2}C\right\rfloor }$.
\item Solange $K\geq1$:
\begin{enumerate}
\item So lange es einen augmentierenden Weg mit Restkapazität $\geq k$
gibt, augmentiere $f$ mit Hilfe dieses Weges.
\item Setzte$K=K/2$.
\end{enumerate}
\item Der Fluss $f$ ist ein maximaler Fluss.
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(A^{2}\log C\right)$, kann zu $\mathcal{O}\left(VA\log C\right)$
verbessert werden.
\begin{lem}
Vor der Ausführung von Schritt (4.1) ist die Kapazität eines minimalen
Schnitts im reduzierten Netzwerk höchstens $2\cdot K\cdot\left|A\right|$.
\end{lem}

\begin{lem}
Für festes $K$ erfolgen $\mathcal{O}\left(A\right)$ Augmentierungen
in Schritt (4.1).
\end{lem}

\begin{prop}
Der Algorithmus ScalingMaxFlow hat die Zeitkomplexität $\mathcal{O}\left(A^{2}\log C\right)$.
\end{prop}


\subsection{Der Preflow-Push-Algorithmus}
\begin{defn}
Ein Präfluss in einem Netzwerk $D$ ist eine Funktion $f:V\times V\rightarrow\mathbb{R}$
mit den Eigenschaften
\begin{itemize}
\item $f\left(u,v\right)\leq c\left(u,v\right)$, für alle $u,v\in V$,
\item $f\left(u,v\right)=-f\left(u,v\right)$, für alle $u,v\in V$,
\item $f\left(V,u\right)\geq0$, für alle $u\in V\setminus\left\{ s\right\} $.
\end{itemize}
Der \textbf{Überschuss} von Knoten $u$ ist $e\left(u\right)=f\left(V,u\right)$.

Ein Knoten $u\in V\setminus\left\{ s,t\right\} $ heißt \textbf{aktiv},
falls $e\left(u\right)>0$.
\end{defn}

(Ein Präfluss ist also ein Fluss, der statt der Flusserhaltung ,,$\text{Flow-In}=\text{Flow-Out}$``
nur die Bedingung ,,$\text{Flow-In}\geq\text{Flow-Out}$`` erfüllen
muss.)
\begin{defn}
Sei $D$ ein Netzwerk und $f$ ein Präfluss. Eine Funktion $h:V\rightarrow\mathbb{N}_{0}$
heißt \textbf{Höhenfunktion}, falls
\begin{itemize}
\item $h\left(s\right)=\left|V\right|$,
\item $h\left(t\right)=0$,
\item $h\left(u\right)\leq h\left(v\right)+1$ für jeder Kante $\left(u,v\right),u\neq s$,
aus dem reduzierten Netzwerk $D_{f}$.
\end{itemize}
\end{defn}

\begin{lem}
Sei $D$ ein Netzwerk, $f$ ein Präfluss und $h$ eine Höhenfunktion.
Falls für zwei Knoten $u,v\in V$ $h\left(u\right)>h\left(v\right)$
gilt, dann ist$\left(u,v\right)$ keine Kante des reduzierten Netzwerks.

\label{PrefowPush}
\end{lem}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Push}$\left(u,v\right)$:
\begin{enumerate}
\item Falls $u$ aktiv ist, $h\left[u\right]=h\left[v\right]+1$und $c_{f}\left(u,v\right)>0$,
dann:
\begin{enumerate}
\item $\Delta=\min\left\{ e\left[u\right],c_{f}\left(u,v\right)\right\} $.
\item $f\left[u,v\right]=f\left[u,v\right]+\Delta$, $f\left[v,u\right]=-f\left[u,v\right]$,
$e\left[u\right]=e\left[u\right]-\Delta$, $e\left[v\right]=e\left[v\right]+\Delta$.
\end{enumerate}
\end{enumerate}
%
\end{minipage}}

Eine Push-Operation ist \textbf{saturierend}, wenn danach $c_{f}\left(u,v\right)=0$
gilt, sonst \textbf{nicht saturierend}.

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Lift}$\left(u\right)$:
\begin{enumerate}
\item Falls $u$ aktiv und es keine Kante $\left(u,v\right)\in A_{f}$ gibt
mit $h\left[u\right]>h\left[v\right]$, dann:
\begin{enumerate}
\item $h\left[u\right]=1+\min\left\{ h\left[v\right]|\left(u,v\right)\in A_{f}\right\} $
\end{enumerate}
\end{enumerate}
%
\end{minipage}}

\medskip{}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{PreflowPush}$\left(D,c,s,t\right)$:
\begin{enumerate}
\item Für alle $v\in V$ setze $h\left[v\right]=0$ und $e\left[v\right]=0$.
\item Für jede Kante $\left(u,v\right)\in A$ setze $f\left[u,v\right]=0$
und $f\left[v,u\right]=0$.
\item Setze $h\left[s\right]=\left|V\right|$.
\item Für jeden Knoten $v$ mit $\left(s,v\right)\in A$ setze $f\left[s,v\right]=c\left(s,v\right)$,
$f\left[v,s\right]=-c\left(s,v\right)$ und $e\left[v\right]=c\left(s,v\right)$.
\item Solange eine anwendbare Push- oder Lift-Operation existiert, führe
eine solche aus.
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(V^{2}A\right)$
\begin{lem}
Sei $D=\left(V,A\right)$ ein Netzwerk mit Quelle $s$ und Senke $t$,
$f$ ein Präfluss und $h$ eine Höhenfunktion. Wenn $u$ ein aktiver
Knoten ist, dann ist Lift$\left(u\right)$ oder Push$\left(u,v\right)$
für ein $v\in V$ anwendbar.
\end{lem}

\begin{lem}
Während der Ausführung von Preflow-Push nehmen die Höhen der Knoten
nicht ab. Ist für einen Knoten $u$ Lift$\left(u\right)$ anwendbar,
dann steigt die Höhe von $u$ um mindestens 1.
\end{lem}

\begin{lem}
Die Funktion $h$ behält während der Ausführung der Algorithmus die
Eigenschaften einer Höhenfunktion.
\end{lem}

\begin{lem}
Es gibt keinen Weg von $s$ nach $t$ im reduzierten Netzwerk.
\end{lem}

\begin{prop}
Nach Terminierung des Algorithmus ist ein maximaler $\left(s,t\right)$-Fluss
bestimmt.
\end{prop}

\begin{lem}
Sei $f$ ein Präfluss in $D=\left(V,A\right)$. Es gilt: Für jeden
aktiven Knoten $u$ gibt es einen (einfachen) Weg von $u$ nach $s$
im reduzierten Netzwerk $D_{f}$.
\end{lem}

\begin{lem}
Im Verlauf des Algorithmus gilt immer $h\left(u\right)\leq2\cdot\left|V\right|-1$,
für alle $u\in V$.
\end{lem}

\begin{cor}
Für jeden Knoten wird höchstens $\left(2\cdot\left|V\right|-1\right)$-mal
eine Lift-Operation durchgeführt. Die Gesamtzahl aller Lift-Operationen
ist höchstens $\left(2\cdot\left|V\right|-1\right)\left(\left|V\right|-2\right)<2\cdot\left|V\right|^{2}$.
\end{cor}

\begin{lem}
Die Zahl der saturierenden Push-Operationen ist höchstens $2\cdot\left|V\right|\cdot\left|A\right|$.
\end{lem}

\begin{lem}
Die Zahl der nichtsaturierenden Push-Operationen ist höchstens $4\left|V\right|^{2}\cdot\left(\left|V\right|+\left|A\right|\right)$.
\end{lem}

\begin{prop}
Die Zahl der Basis-Operationen bei der Ausführung des Preflow-Push-Algorithmus
beträgt$\mathcal{O}\left(V^{2}A\right)$.
\end{prop}

\begin{cor}
Der Preflow-Push-Algorithmus hat die Zeitkomplexität $\mathcal{O}\left(V^{2}A\right)$.
\end{cor}


\paragraph{FIFO-Preflow-Push}

\label{FIFO-PFP}

Hier werden Knoten in einer Queue abgearbeitet, die mit den Nachbarn
von L initialisiert werden. Das abarbeiten funktioniert mit der \emph{Examine}$\left(u\right)$-Operation:

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Examine}$\left(u\right)$:
\begin{enumerate}
\item Falls $u$ aktiv ist, dann:
\begin{enumerate}
\item Solange möglich, führe Operationen \emph{Push}$\left(u,v\right)$
aus. Wird $v$ dadurch zu einem Überschussknoten, füge $v$ am Ende
von $L$ ein.
\item Ist \emph{Lift}$\left(u\right)$ anwendbar, führe die Operation aus
und setze $u$ ans Ende von $L$, andernfalls entferne $u$ aus $L$.
\end{enumerate}
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(V^{3}\right)$ 

\paragraph{Highest-Label-Preflow-Push}

Bevorzuge Knoten mit dem höchsten $h$-Wert. $\text{Laufzeit: }\mathcal{O}\left(V^{2}\sqrt{A}\right)$

\subsection{Untere Schranken und Knotenkapazitäten}

\subsubsection{Untere Schranken}

Wenn ein \textbf{Mindestfluss} gesucht ist, könnte es die Bedingung
$l\left(u,v\right)\leq f\left(u,v\right)\leq c\left(u,v\right)$ geben.
Dazu transformieren wir das Problem in $D=\left(V,A\right)$ wie folgt:

\[
\begin{aligned}D^{\ast}= & \left(V^{\ast},A^{\ast}\right)\\
V^{\ast}= & \,V\cup\left\{ s^{\ast},t^{\ast}\right\} \\
A^{\ast}= & \,A\cup\left\{ \left(s^{\ast},v\right)|v\in V\right\} \cup\left\{ \left(v,t^{\ast}\right)|v\in V\right\} \cup\left\{ \left(t,s\right)\right\} \\
c^{\ast}\left(t,s\right)= & \,\infty\\
c^{\ast}\left(u,v\right)= & \,c\left(u,v\right)-l\left(u,v\right)\text{, für }\left(u,v\right)\in A\\
c^{\ast}\left(s^{\ast},u\right)= & \,\sum_{\left(v,u\right)\in A}l\left(v,u\right)\text{, für }u\in V\\
c^{\ast}\left(u,t^{\ast}\right)= & \,\sum_{\left(u,v\right)\in A}l\left(u,v\right)\text{, für }u\in V
\end{aligned}
\]

In $D$ existiert ein zulässiger Fluss genau dann, wenn der maximale
$\left(s^{\ast},t^{\ast}\right)$-Fluss in $D^{\ast}$ den Wert $f^{\ast}=\sum_{\left(u,v\right)\in A}l\left(u,v\right)$
hat. Es gilt $f\left(u,v\right)=f^{\ast}\left(u,v\right)+l\left(u,v\right)$
ist ein zulässiger Fluss. Er kann als Startfluss für die oben genannten
Max-Flow-Algorithmen genutzt werden.

\subsubsection{Knotenkapazitäten}

Alle Knoten werden in zwei Knoten geteilt, die mit einer Kante verbunden
werden, die die Knotenkapatzität als Kapazität hat.

\subsection{Anwendungen des Max-Flow-Min-Cut-Theorems}

Hier könnten einige Anwendungen stehen, tun sie aber nicht.
\begin{prop}
Es gilt das \textbf{Min-Flow-Max-Cut-Theorem}

\[
\min_{\left(s,t\right)\text{-Fluss }f}\left|f\right|=\max_{\left(s,t\right)\text{-Schnitt }\left(S:T\right)}\sum_{u\in S,v\in T}l\left(u,v\right)-\sum_{u\in S,v\in T}c\left(v,u\right).
\]
\end{prop}


\section{Schnitte in ungerichteten Graphen}

\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Minimaler-Schnitt-Problem}

\smallskip{}

Gegeben ist ein zusammenhängender ungerichteter Graph $G=\left(V,E\right)$
mit positiven Kantengewichten $c_{e},e\in E$. Zu bestimmen ist eine
Knotenmenge $W\subseteq V,\emptyset\neq W\neq V$, so dass $c\left(\delta\left(W\right)\right)$
minimal ist.%
\end{minipage}}

\subsection{Der Algorithmus von Nagamochi und Ibaraki}
\begin{defn*}
Der Graph $G_{vw}$ entsteht durch \textbf{Identifikation} der beiden
Knoten $v$ und $w$, was bedeutet, dass sie durch einen neuen Knoten
$x$ ersetzt werden.
\end{defn*}
\begin{lem}
Die Schnitte in $G_{vw}$ korrespondieren zu den Schnitten von $G$,
die $v$ und $w$ nicht trennen.
\end{lem}

\begin{lem}
Seien $p,q,r\in V$. Es gilt $f\left(G:p,q\right)\geq\min\left\{ f\left(G:p,r\right),f\left(G:q,r\right)\right\} $.
\end{lem}

\begin{defn*}
Sei $v_{1},v_{2},\ldots,v_{n}$ eine Anordnung der Knoten von $G$
und sei $V_{i}=\left\{ v_{1},\ldots,v_{i}\right\} ,1\leq i\leq n$.
Die Anordnung heißt \textbf{legal}, falls $c\left(\delta\left(V_{i-1}\right)\cap\delta\left(v_{i}\right)\right)\geq c\left(\delta\left(V_{i-1}\right)\cap\delta\left(v_{j}\right)\right)$,
für alle $2\leq i\leq j\leq n$.

Man startet also mit irgendeinem Knoten und wählt als nächsten Knoten
einen aus, dessen Summe der Kapazitäten der Kanten zu bereits gewählten
Knoten maximal ist.
\end{defn*}
\begin{prop}
Wenn $v_{1},v_{2},\ldots,v_{n}$ eine legale Ordnung für $G$ ist,
dann ist $\delta\left(v_{n}\right)$ ein minimaler $\left(v_{n},v_{n-1}\right)$-Schnitt
in $G$.
\end{prop}

\label{NagamochiIbaraki}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{\textit{NagamochiIbaraki}}\textit{$\left(G,c\right)$:}
\begin{enumerate}
\item Setze $U=+\infty$, $C$ undefiniert, $k=n=\left|V\right|$, $G^{k}=G$.
\item Solange $k\geq2$:
\begin{enumerate}
\item Bestimme eine legale Ordnung $v_{1},\ldots,v_{k}$ von $G^{k}$.
\item Falls $c\left(\delta\left(v_{k}\right)\right)<U$, setze $U=c\left(\delta\left(v_{k}\right)\right)$
und $C=\delta\left(v_{k}\right)$.
\item Identifiziere die Knoten $v_{k-1}$ und $v_{k}$.
\item Setze $G^{k-1}=G_{v_{k-1}v_{k}}^{k}$ und $k=k-1$.
\end{enumerate}
\item $U$ ist Kapazität eines minimalen Schnitts in $G$ und ein zugehöriger
Schnitt lässt sich aus $C$ konstruieren.
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(V^{3}\right)$ oder $\mathcal{O}\left(V^{2}+VE\log V\right)$

\subsection{Der Algorithmus von Karger}

Dies ist ein \textbf{randomisierter} Algorithmus, er liefert also
mit einer gewissen Chance ein falsches Ergebnis.

\label{Karger}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{\textit{Karger}}\textit{$\left(G,c\right)$:}
\begin{enumerate}
\item Solange $G$ mehr als zwei Knoten enthält:
\begin{enumerate}
\item Wähle eine Kante $f$ von $G$ mit Wahrscheinlichkeit $c_{f}/{\displaystyle \sum_{e\in E}}c_{e}$.
\item Ersetze $G$ durch $G_{vw}$, wobei $f=vw$.
\end{enumerate}
\item Gib den eindeutigen Schnitt von $G$ aus.
\end{enumerate}
%
\end{minipage}}
\begin{prop}
Sei $B\subseteq E$ ein minimaler Schnitt von $G$. Dann liefert der
Algorithmus von Karger das Ergebnis $B$ mit einer Wahrscheinlichkeit
von mindestens $\frac{2}{n\left(n-1\right)}$.
\end{prop}

\begin{cor}
Sei $B$ minimaler Schnitt von $G$ und $k$ eine positive ganze Zahl.
Die Wahrscheinlichkeit, dass der Algorithmus von Karger bei $k\cdot n^{2}$
Aufrufen nicht mindestens einmal $B$ als Ausgabe liefert, ist höchstens
$e^{-2k}$.
\end{cor}


\subsection{Minimale Schnitte zwischen allen Knotenpaaren}

\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Alle-minimaler-Schnitte-Problem}

\smallskip{}

Gegeben ist ein Graph $G=\left(V,E\right)$ mit positiven Kantengewichten
und eine Knotenmenge $K\subseteq V$ (\textbf{Terminalknoten}). Zu
bestimmen sind alle minimalen $\left(u,v\right)$-Schnitte für $u,v\in K$.%
\end{minipage}}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
Hier könnte ihr Algorithmus stehen!%
\end{minipage}}

\section{Flüsse mit minimalen Kosten}

Betrachtet wird hier der Digraph $D=\left(V,A\right)$ mit \textbf{Kapazitäten}
$c_{uv}$, \textbf{Kosten} $w_{uv}$, und einer Zahl $b_{u}$.

Knoten $u$ mit $b_{u}>0$ nennen wir \textbf{Quelle} mit \textbf{Vorrat}/\textbf{Angebot}
$b_{u}$, bei $b_{u}<0$ nennen wir sie \textbf{Senke} mit \textbf{Nachfrage}
$b_{u}$, bei $b_{u}=0$ heißen sie \textbf{Durchflussknoten} und
müssen die Flusserhaltung erfüllen. 

\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Minimale-Kosten-Fluss-Problem}

\smallskip{}

Gegeben sind ein gerichteter Graph $D=\left(V,A\right)$ mit Kantenkapazitäten
und -kosten sowie vorgegebenen Knotenbilanzen. Es ist ein Fluss gesucht,
der alle Kapazitäten erfüllt, an den Knoten die Flussbilanzen realisiert
und unter allen diesen Flussen minimale Kosten hat.%
\end{minipage}}

Als lineares Programm formuliert:

\begin{align*}
\min\sum_{\left(u,v\right)\in A}w_{uv}f_{uv}\\
\sum_{v:\left(u,v\right)\in A}f_{uv}-\sum_{v:\left(v,u\right)\in A}f_{vu}=b_{u} & \text{, für alle }u\in V\\
0\leq f_{uv}\leq c_{uv} & \text{, für alle }\left(u,v\right)\in A
\end{align*}

Annahmen:\\
Alle Daten sind ganzzahlig, es gibt so viel Angebot wie Nachfrage,
es existiert ein zulässiger Fluss, alle Kosten und Kapazitäten sind
nicht-negativ, es gibt keine antiparallelen Kanten (nur aus Notationsgründen).

\medskip{}

Ein zulässiger Fluss lässt sich durch zusätzliche Knoten $s^{\ast}$
und $t^{\ast}$ und Kanten mit Kapazität von Angebot bzw. Nachfrage
nachweisen.

\subsection{Das klassische Transportproblem}

\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{(Unkapazitiertes) Transportproblem}

\smallskip{}

Ein Produkt wird in $m$ Anbieterorten produziert und in $n$ Nachfrageorten
benötigt. Am Anbieterort $i$ liegt ein Lagervorrat $a_{i}$ vor,
am Nachfrageort $j$ besteht der Bedarf $b_{j}$ . (Es gelte $\sum a_{i}$
= $\sum b_{j}$ .) Der Transport einer Einheit des Produkts vom Ort
$i$ zum Ort $j$ kostet $w_{ij}$ . Zu bestimmen ist ein Transportplan,
der alle Nachfragen erfüllt und minimale Kosten hat.%
\end{minipage}}

Als lineares Programm formuliert:

\begin{align*}
\min\sum_{i=1}^{m}\sum_{j=1}^{n}w_{ij}x_{ij}\\
\sum_{j=1}^{n}x_{ij}=a_{i} & i=1,\ldots,m\\
\sum_{i=1}^{m}x_{ij}=b_{i} & j=1,\ldots,n\\
x_{ij}\geq0 & i=1,\ldots,m,j=1,\ldots,n
\end{align*}


\subsubsection{Die Nordwestecken-Regel}

...liefert eine Startlösung.

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{NW}$\left(a,b\right)$:
\begin{enumerate}
\item Setze $i=j=1$ und $x_{11}=\min\left\{ a_{1},b_{1}\right\} $.
\item Solange $i<m$ oder $j<n$:
\begin{enumerate}
\item Setze $a_{i}=a_{i}-x_{ij}$ und $b_{j}=b_{j}-x_{ij}$.
\item Falls $a_{i}=0$, dann $i=i+1$, sonst $j=j+1$.
\item Setze $x_{ij}=\min\left\{ a_{i},b_{j}\right\} $.
\end{enumerate}
\end{enumerate}
%
\end{minipage}}

\subsubsection{Die Stepping-Stone-Methode}
\begin{prop}
Eine Teilmenge $E$ der Spalten von $T$ ist genau dann linear unabhängig,
wenn die zugehörige Kantenmenge in $K_{mn}$ keinen Kreis enthält.
\end{prop}

\begin{prop}
$E$ ist eine Teilmenge von $m+n-1$ linear unabhängigen Spalten von
$T$ genau dann, wenn der zugehörige Teilgraph von $K_{mn}$ ein aufspannender
Baum ist.
\end{prop}

\noindent\ovalbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 0.8pt}%
Der Algorithmus sollte einfach auswendig gelernt werden. Probieren,
studieren und so...%
\end{minipage}}

\subsubsection{Das kapazitierte Transportproblem}

Es existieren nun Kantenkapazitäten $0\leq x_{ij}\leq c_{ij}$. Man
fügt die Extraknoten $m+1$ und $n+1$ ein. Es gilt:

\begin{align*}
a_{m+1}=b_{n+1}= & \sum_{i=1}^{m}a_{i}\\
w_{i,n+1}=w_{m+1,j}= & M,\;i=1,\ldots,m,\;j=1,\ldots,n\\
w_{m+1,n+1}= & 0\\
c_{i,n+1}= & a_{i},\;i=1,\ldots,m\\
c_{m+1,j}= & b_{j},\;j=1,\ldots,n\\
c_{m+1,n+1}= & \sum_{i=1}^{m}a_{i}
\end{align*}

Triviale Startlösung: Alle liefern an $n+1$, alle kriegen von $m+1$.\\
Das Originaleproblem hat eine Lösung, wenn das transformierte Problem
eine Lösung hat, die die neuen Knoten nicht mit alten Knoten verbindet.

\subsubsection{Varianten und Erweiterungen}

<keine>

\subsection{Optimalitätsbedingungen}
\begin{defn*}
Auch hier gibt es ein \textbf{reduziertes Netzwerk} $D_{f}=\left(V,A_{f}\right)$
mit Restkapazitäten $r_{uv}$ zum Fluss $f$. Für eine Kante $\left(u,v\right)\in A$
gilt:

\begin{align*}
f_{uv}<c_{uv}\Rightarrow & \left(u,v\right)\in A_{f}\text{, mit Kosten \ensuremath{+w_{uv}} und }r_{uv}=c_{uv}-f_{uv}\\
f_{uv}>0\Rightarrow & \left(v,u\right)\in A_{f}\text{, mit Kosten \ensuremath{-w_{uv}} und }r_{uv}=f_{uv}
\end{align*}
\end{defn*}
\begin{prop}
\textbf{(Negativer-Kreis-Bedingung)} Ein zulässiger Fluss $f^{\ast}$
ist genau dann optimal, wenn das reduzierte Netzwerk $D_{f^{\ast}}$
keinen Kreis enthält, so dass die Summe der Kosten seiner Kanten negativ
ist.
\end{prop}

\begin{prop}
\textbf{(Reduzierte-Kosten-Bedingung)} Ein zulässiger Fluss $f^{\ast}$ist
genau dann optimal, wenn es einen Vektor $\pi$ gibt, so dass $w_{uv}^{\pi}\geq0$,
für alle $\left(u,v\right)\in A_{f^{\ast}}$.
\end{prop}


\subsection{Negaive-Kreise-Verfahren}

\label{CycleCanceling}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{CycleCanceling}$\left(D,c,w,b\right)$:
\begin{enumerate}
\item Bestimme einen zulässigen Fluss $f$.
\item Generiere das reduzierte Netzwerk $D_{f}$.
\item Enthält $D_{f}$ keinen negativen Kreis, dann \emph{Stop}(,,$f$
is kostenminimal``). Andernfalls sein $C$ ein negativer Kreis.
\item Bestimme die Restkapazität $\Delta$ von $C$ und setze $f_{uv}=f_{uv}+\Delta$
für alle $\left(u,v\right)\in C$. Gehe zu (2).
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(V^{2}AUW\right)$ mit $U$ und $W$ 
\begin{prop}
Sind alle Daten $c_{uv}$, $\left(u,v\right)\in A$, und $b_{u}$,
$u\in V$, ganzzahlig, dann existiert ein kostenminimaler Fluss mit
ganzzahligen Werten.
\end{prop}


\subsection{Kürzerste-Wege-Verfahren}
\begin{defn*}
Für einen \textbf{Pseudofluss} $f$ gilt $0\leq f_{uv}\leq c_{uv}$
für alle $\left(u,v\right)\in A$. $f=0$ \textbf{ist} ein Pseudofluss.

Für $v\in V$ ist die Knotenbilanz $e\left(v\right)=b_{v}\sum_{\left(u,v\right)\in A}f_{uv}-\sum_{\left(v,u\right)\in A}f_{vu}$.

Wir nennen Knoten mit $e\left(v\right)>0$ \textbf{Überschussknoten},
mit $e\left(v\right)<0$ \textbf{Defizitknoten}, mit $e\left(v\right)=0$
\textbf{balanciert}.
\end{defn*}
\begin{lem}
Seien $f$ ein Pseudofluss und $\pi$ ein Vektor von Knotenpotentialen,
so dass die Optimalitätsbedingungen $w_{uv}^{\pi}=\overline{w}_{uv}-\pi_{u}+\pi_{v}\geq0$,
für alle $\left(u,v\right)\in A$, erfüllt sind. Für jeden Knoten
$v\in V$ sei $\delta\left(s,v\right)$ die Länge eines kürzesten
Weges in $D_{f}$ (bezüglich der Kantenlänge $w^{\pi}$) von einem
ausgezeichneten Knoten $s$ zu $v$.
\begin{lyxlist}{00.00.0000}
\item [{a)}] Der Pseudofluss $f$ erfüllt auch die Optimaitätsbedingungen
mit den Knotenpotentialen $\pi^{\prime}$ definiert durch $\pi_{v}^{\prime}=\pi_{v}-\delta\left(s,v\right)$,
für alle $v\in V$.
\item [{b)}] Die reduzierten Kosten $w_{uv}^{\pi^{\prime}}$ sind Null
für alle Kanten $\left(u,v\right)$, die auf einem kürzesten Weg von
$s$ zu einem anderen Knoten liegen.
\end{lyxlist}
\end{lem}

\begin{lem}
Sei $f$ ein Pseudofluss, der die Reduzierte-Kosten-Bedingung erfüllt.
Der Pseudofluss $f^{\prime}$ werde durch Augmentierung entlang eines
kürzesten Weges (von $s$ nach $l$ in $D_{f}$ bezpglich der Kantenlängen
$w^{\pi}$) erhalten. Dann erfüllt $f^{\prime}$ die Reduzierte-Kosten-Bedingung
bzgl. $\pi^{\prime}$.
\end{lem}

\label{SuccShortestPath}%
\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{SuccessiveShortestPaths$\left(D,c,w,b\right)$}:
\begin{enumerate}
\item Setze $f=0$, $\pi=0$, und $e\left(u\right)=b_{u}$, für alle $u\in V$.
\item Solange noch Überschussknoten existieren:
\begin{enumerate}
\item Wähle einen Überschussknoten $s$ und einen Defizitknoten $t$.
\item Bestimme die Kürzeste-Wege-Distanzen $\delta\left(s,i\right)$ von
$s$ zu allen anderen Knoten $i$ in $D_{f}$ bezüglich der Kantenlängen
$w^{\pi}$. Sei $P$ der kürzeste Weg von $s$ nach $t$.
\item Setze $\pi_{u}=\pi_{u}-\delta\left(s,u\right)$, für alle $u\in V$.
\item Augmentiere $f$ entlang $P$ um den Betrag $\min\left\{ c_{f}\left(P\right),e\left(s\right)-e\left(t\right)\right\} $,
wobei $c_{f}\left(P\right)$ die Restkapazität des Weges $P$ ist.
\item Bestimme die neuen reduzierten Kosten und das neue reduzierte Netzwerk.
\end{enumerate}
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(BV^{2}\right)$ oder $\mathcal{O}\left(BA\log V\right)$
mit $B$ als Summe über alle Angebote.

\medskip{}

\label{SuccShortestPath2}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{SuccessiveShortestPaths2$\left(D,c,w,b\right)$}:
\begin{enumerate}
\item Setze $f=0$, $\pi=0$, und $e\left(u\right)=b_{u}$, für alle $u\in V$.
\item Solange ein Überschussknoten existiert:
\begin{enumerate}
\item Wähle einen Überschussknoten $s$.
\item Führe den Dijkstra-Algorithmus mit Startknoten $s$ aus und stoppe
ihn, sobald ein Defizitknoten permanent markiert wird. Wird kein Defizitknoten
erreicht, \emph{Stop}(,,Problem unlösbar``).
\item Sei $t$ der erste permanent markierte Defizitknoten.
\item Setze $\pi_{u}=\begin{cases}
\pi_{u}-\delta\left(s,u\right) & u\text{ ist permanent markiert worden,}\\
\pi_{u}-\delta\left(s,t\right) & \text{sonst}.
\end{cases}$
\item Augmentiere $f$ auf dem Weg von $s$ nach $t$ um den maximal möglichen
Betrag.
\item Bestimme die neuen reduzierten Kosten und das neue reduzierte Netzwerk.
\end{enumerate}
\end{enumerate}
%
\end{minipage}}

Dieser Algorithmus funktioniert auch ohne die Annahme, dass alle Kürzeste-Wege-Distanzen
existieren.

\subsection{Der primale Simplex-Algorithmus}

Omitted
\begin{prop}
\textemdash{}
\end{prop}


\subsection{Skalierung der Kapazitäten}
\begin{defn*}
In einer $\Delta$-Skalierungs-Phase erfolgen jeweils Augmentierungen
um mindestens den Betrag $\Delta$. Das $\Delta$-reduzierte Netzwerk
enthält nur Kanten mit mindestens Restkapazität $\Delta$ und Quellen
(Senken) mit mindestens Überschuss (Defizit) $\Delta$.
\end{defn*}
\label{CapacityScaling}

Es gilt $U=\max\left\{ \max\left\{ c_{uv}|\left(u,v\right)\in A\right\} ,\max\left\{ b_{u}|b_{u}>0\right\} ,\max\left\{ -b_{u}|b_{u}<0\right\} \right\} $.

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{CapacityScaling}$\left(D,c,w,b\right)$:
\begin{enumerate}
\item Setze $f=0$, $\pi=0$, $\Delta=2^{\left\lfloor \log_{2}U\right\rfloor }$.
\item Solange $\Delta\geq1:$
\begin{enumerate}
\item Für alle Kanten $\left(u,v\right)\in A_{f}$ mit $r_{uv}\geq\Delta$
und $w_{uv}^{\pi}<0$:
\begin{enumerate}
\item Setze $f_{uv}=f_{uv}+r_{uv}$, $e\left(u\right)=e\left(u\right)-r_{uv}$
und $e\left(v\right)=e\left(v\right)+r_{uv}$.
\item Setze $A_{f}=A_{f}\setminus\left\{ \left(u,v\right)\right\} \cup\left\{ \left(v,u\right)\right\} $
mit $r_{vu}=f_{uv}$
\end{enumerate}
\item Setze $S\left(\Delta\right)=\left\{ v|e\left(v\right)\geq\Delta\right\} $
und $T\left(\Delta\right)=\left\{ v|e\left(v\right)\leq-\Delta\right\} $
\item Solange $S\left(\Delta\right)=\emptyset$ und $T\left(\Delta\right)=\emptyset$:
\begin{enumerate}
\item Wähle $s\in S\left(\Delta\right)$ und $t\in T\left(\Delta\right)$.
\item Berechne Kürzeste-Wege-Distanzen $\delta\left(s,v\right)$, für alle
$v\in V$. Sei $P$ der kürzeste $\left(s,t\right)$-Weg.
\item Setze $\pi_{v}=\pi_{v}-\delta\left(s,v\right)$, für alle $v\in V$.
\item Augmentiere entlang $P$ um $\min\left\{ c_{f}\left(P\right),e\left(s\right),-e\left(t\right)\right\} $.
\item Ändere $S\left(\Delta\right)$, $T\left(\Delta\right)$ und $D_{f}$
entsprechend.
\end{enumerate}
\item Setze $\Delta=\Delta/2$.
\end{enumerate}
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(AV^{2}\log U\right)$ oder $\mathcal{O}\left(A^{2}\log V\log U\right)$
mit Dijkstra. 
\begin{prop}
Die Laufzeit von \emph{CapacityScaling} ist richtig.
\end{prop}


\subsection{Minimale-Mittlere-Kreise-Verfahren}

........
\end{document}
