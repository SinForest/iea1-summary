%% LyX 2.2.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[ngerman]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setlength{\parindent}{0bp}
\usepackage{array}
\usepackage{fancybox}
\usepackage{calc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}[section]
  \theoremstyle{definition}
  \newtheorem{defn}[thm]{\protect\definitionname}
 \theoremstyle{definition}
 \newtheorem*{defn*}{\protect\definitionname}
\newenvironment{lyxlist}[1]
{\begin{list}{}
{\settowidth{\labelwidth}{#1}
 \setlength{\leftmargin}{\labelwidth}
 \addtolength{\leftmargin}{\labelsep}
 \renewcommand{\makelabel}[1]{##1\hfil}}}
{\end{list}}
  \theoremstyle{plain}
  \newtheorem{lem}[thm]{\protect\lemmaname}
  \theoremstyle{plain}
  \newtheorem{prop}[thm]{\protect\propositionname}
  \theoremstyle{plain}
  \newtheorem{cor}[thm]{\protect\corollaryname}
  \theoremstyle{plain}
  \newtheorem*{prop*}{\protect\propositionname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage{pstricks}
\renewcommand{\labelenumi}{(\arabic{enumi})}
\renewcommand{\labelenumii}{(\arabic{enumi}.\arabic{enumii})}
\renewcommand{\labelenumiii}{(\arabic{enumi}.\arabic{enumii}.\arabic{enumiii})}
\renewcommand{\labelenumiv}{(\arabic{enumi}.\arabic{enumii}.\arabic{enumiii}.\arabic{enumiv})}

\makeatother

\usepackage{babel}
  \providecommand{\corollaryname}{Korollar}
  \providecommand{\definitionname}{Definition}
  \providecommand{\lemmaname}{Lemma}
  \providecommand{\propositionname}{Satz}
\providecommand{\theoremname}{Theorem}

\begin{document}

\title{\noindent Effiziente Algorithmen 1 - Zusammenfassung}

\author{\noindent Patrick Dammann}

\date{\noindent 21.05.2017}
\maketitle

\section{Probleme und Algorithmen}

\noindent %
\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Lineares kombinatorisches Optimierungsproblem}

\smallskip{}

Gegeben sind eine endliche Menge $E$, ein System von Teilmengen $\mathcal{I}\subseteq2^{E}$
(zulässige Lösungen) und eine Funktion $c:E\rightarrow\mathbb{R}$.
Es ist eine Menge $I^{\ast}\in\mathcal{I}$ zu bestimmen, so dass
${\displaystyle c(I^{\ast})=\sum_{e\in I^{\ast}}c(e)}$ minimal bzw.
maximal ist.%
\end{minipage}}

\medskip{}

\noindent %
\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Euklidisches Traveling-Salesman-Problem}

\smallskip{}

Gegeben sind $n$ Punkte in der Euklidischen Ebene. Zu bestimmen ist
eine geschlossene Tour, die jeden Punkt genau einmal besucht und möglichst
kurz ist.

$E=$ Menge der Kanten

$\mathcal{I}=$ Alle Mengen von Kanten, die eine Tour bilden%
\end{minipage}}

\medskip{}

\noindent %
\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Euklidisches Matching-Problem}

\smallskip{}

Gegeben sind $n$ Punkte in der Euklidischen Ebene ($n$ gerade).
Zu bestimmen sind $\frac{n}{2}$ Linien, so dass jeder Punkt Endpunkt
genau einer Linie ist und die Summe der Linienlängen so klein wie
möglich ist.

$E=$ Menge der Kanten

$\mathcal{I}=$ Alle Mengen von Kanten mit der Eigenschaft, dass jeder
Knoten zu genau einer der Kanten gehört.%
\end{minipage}}
\begin{description}
\item [{Einheitskosten-Modell}] Es werden nur die Schritte des Algorithmus
gezählt, die Zahlengrößen bleiben unberücksichtigt.
\item [{Bit-Modell}] Die Laufzeit für eine arithmetische Operation ist
$M$, wobei $M$ die größte Kodierungslänge einer an dieser Operation
beteiligten Zahl ist.
\end{description}
\begin{defn}
\noindent Die Laufzeitfunktion $f_{A}:\mathbb{N}\rightarrow\mathcal{\mathbb{N}}$
ist in $\mathcal{O}(g)$ für eine Funktion $g:\mathbb{N}\rightarrow\mathcal{\mathbb{N}}$
falls es eine Konstante $c>0$ und $n_{o}\in\mathbb{N}$ gibt, so
dass $f_{A}\leq c\cdot g(n)$ für alle $n\geq n_{o}$.
\end{defn}

\begin{defn}
Ein Algorithmus heißt \textbf{effizient} bzw. \textbf{polynomialer
Algorithmus}, wenn seine Laufzeit in $\mathcal{O}\left(n^{k}\right)$
liegt.

Ein Problem, das mit einem polynomialen Algorithmus gelöst werden
kann, heißt \textbf{polynomiales Problem}.
\end{defn}

\pagebreak{}
\begin{defn*}
Ein \textbf{Graph} $G$ ist ein Tupel $G=(V,E)$\footnote{In der Vorlesung werden primär endliche, einfache, schleifenfreie
Graphen behandelt, die der Einfachheit halber eine Notation ohne Inzendenzfunktion
nutzen können. In diesem Skript wird (sofern nicht anders angegeben)
von solchen Graphen ausgegangen.} bestehend aus einer nicht-leeren Knotenmenge $V$ und einer Kantenmenge
$E$.
\end{defn*}
\begin{itemize}
\item Ein Graph heißt \textbf{endlich}, wenn $V$ und $E$ endlich sind.
\item Wenn $e=\left\{ u,v\right\} \in E$ und $u,v\in V$, dann sind $u$
und $v$ \textbf{Nachbarn} bzw. \textbf{adjazen}t, sind \textbf{Endknoten}
von $e$ und werden von $e$ \textbf{verbunden}.
\item Eine Kante $e=\{u,u\}\in E$ heißt \textbf{Schleife}.
\item Kanten mit $E\ni e=\{u,v\}=f\in E$ heißen \textbf{parallel} oder
\textbf{mehrfach}.
\item Ein Graph ohne Mehrfachkanten heißt \textbf{einfach}.
\item Für $W\subseteq V$ bekommt die Menge aller Knoten in $V\setminus W$
mit Nachbarn in $W$ die Bezeichnung $\Gamma(W)$.
\item Kurzform von $\Gamma\left(\left\{ v\right\} \right)$ ist $\Gamma\left(v\right)$.
\item Die Menge $\delta\left(W\right)$ aller Kanten mit je einem Endknoten
in $W$ und $V\setminus W$ heißt \textbf{Schnitt}.
\item Kurzform von $\delta\left(\left\{ v\right\} \right)$ ist $\delta\left(v\right)$.
\item Der \textbf{Grad} eines Knoten $v$ ist die Anzahl seiner Nachbarn,
bzw. $\left|\delta\left(v\right)\right|$.
\item Ein \textbf{(s,t)-Schnitt} ist ein Schnitt $\delta\left(V\right)$
mit $s\in W$ und $t\in V\setminus W$ und gleichzeitig ein (t,s)-Schnitt.
\item Mit $W\subseteq V$ ist $E\left(W\right)$ die Menge aller Kanten
mit beiden Endknoten in $W$.
\item Mit $F\subseteq E$ ist $V\left(F\right)$ die Menge aller Knoten,
die Endknoten von mind. einer Kante in $F$ sind.
\item Sind $G=\left(V,E\right)$ und $H=\left(W,F\right)$ Graphen und $W\subseteq V$
und $F\subseteq E$, so heißt H \textbf{Untergraph} von G.
\item Mit $W\subseteq V$ ist $G-W$ der Graph $G$ ohne die Knoten in $W$
und ohne alle Kanten an $W$.
\item $G\left[W\right]=G-\left(V\setminus W\right)$ ist der \textbf{von
$W$ induzierte Untergraph}.
\item Mit $F\subseteq E$ ist $G-F=\left(V,E\setminus F\right)$.
\item Kurzform von $G-\left\{ x\right\} $ ist $G-x$ für $x\in E$ oder
$x\in V$.
\item Ein einfacher Graph heißt \textbf{vollständig}, wenn jede mögliche
Kante zwischen seinen Knoten existiert.
\item Der vollstängige Graph mit $n$ Knoten wird mit $K_{n}=\left(V_{n},E_{n}\right)$
bezeichnet.
\item Das \textbf{Komplement} des Graphen $G=\left(V,E\right)$ ist $\bar{G}=(V,E_{n}\setminus E)$.
\item Ein Graph heißt \textbf{bipartit}, wenn er sich in zwei disjunkte
Teilmengen $V_{1},V_{2}$ mit $V_{1}\cup V_{2}=V$ teilen lässt, ohne
dass es Kanten $\left\{ u,v\right\} $ mit $u,v\in V_{1}\vee u,v\in V_{2}$
gibt.
\end{itemize}
\begin{defn*}
Ein \textbf{Digraph} $G$ ist ein Tupel $D=(V,A)$ bestehend aus einer
nicht-leeren Knotenmenge $V$ und einer Kantenmenge $A$.
\end{defn*}
\begin{itemize}
\item Wenn $a=\left(u,v\right)\in A$ und $u,v\in V$, dann ist $u$ \textbf{Anfangsknoten}
und $v$ \textbf{Endknoten }von $a$. Hier heißt $u$ \textbf{Vorgänger}
von $v$ und $v$ \textbf{Nachfolger} von $u$.
\item Die Kanten $\left(u,v\right)$ und $\left(v,u\right)$ heißen \textbf{antiparallel}.
\item Mit $W\subseteq V$ ist $A\left(W\right)$ die Menge aller Kanten
mit Anfangs- und Endknoten in $W$.
\item Mit $B\subseteq A$ ist $V\left(A\right)$ die Menge aller Knoten,
die Anfangs- oder Endknoten von mind. einer Kante in $B$ sind.
\item $G=\left(V,E\right)$ ist der unterliegende Graph von $D=\left(V,A\right)$,
wenn $E$ genau die Kanten $\left\{ u,v\right\} $ enthält, für die
$\left(u,v\right)$ oder $\left(v,u\right)$ in $A$ liegen.
\item Ein einfacher Digraph heißt \textbf{vollständig}, wenn jede mögliche
Kante (in beide Richtungen) zwischen seinen Knoten existiert.
\item Der vollstängige Digraph mit $n$ Knoten wird mit $D_{n}=\left(V_{n},A_{n}\right)$
bezeichnet.
\item Für $W\subseteq V,W\neq V\neq\emptyset$ enthält $\delta^{+}\left(W\right)=\left\{ \left(i,j\right)\in A\,\vert\,i\in W,j\notin W\right\} $
alle Kanten, die $W$ verlassen, $\delta^{-}\left(W\right)=\delta^{+}\left(V\setminus W\right)$
alle Kanten, die in $W$ hinein führen und $\delta\left(W\right)=\delta^{+}\left(W\right)\cup\delta^{-}\left(W\right)$
beide. Diese Mengen heißen \textbf{Schnitt}. Es gelten die Kurzformen
für einzelne Knoten.
\item Für $s\in W$ und $t\notin W$ heißt $\delta^{+}\left(W\right)$ auch
\textbf{$\left(s,t\right)$-Schnitt}.
\item Die Kardinalitäten der Schnitte heißen \textbf{Außengrad} $\left(\left|\delta^{+}\left(v\right)\right|\right)$,
\textbf{Innengrad} $\left(\left|\delta^{-}\left(v\right)\right|\right)$
und \textbf{Grad} $\left(\left|\delta\left(v\right)\right|\right)$.
\item $\delta^{+}\left(W\right)$ heißt \textbf{gerichteter Schnitt}, wenn
$\delta^{-}\left(W\right)=\emptyset$.
\end{itemize}
\begin{defn*}
Eine endliche Folge $W=\left(v_{0},e_{1},v_{1},e_{2},v_{2},\ldots,e_{k},v_{k}\right)$
heißt \textbf{Kette} oder $\left[v_{0},v_{k}\right]$-Kette der Länge
$k$, wenn jede Kante $e_{i}$ die Knoten $v_{i-1}$ und $v_{i}$
in einem (Di-)Graphen indiziert und \textbf{gerichtete Kette} oder
$\left(v_{0},v_{k}\right)$-Kette, wenn alle Kanten in der Form $e_{i}=\left(v_{i-1},v_{i}\right)$
sind. $v_{0}$ und $v_{k}$ heißen \textbf{Anfangs- und Endknoten}.
\end{defn*}
\begin{itemize}
\item Gibt es in einem (Di-)Graphen keine parallelen Kanten, ist eine (gerichtete)
Kette durch ihre Knoten eindeutig identifiziert.
\item Ein \textbf{(gerichteter) Weg} oder \textbf{(gerichteter) Pfad} ist
eine (gerichtete) Kette, in der alle Knoten verschieden sind.
\item Die Notation $u\underset{D}{\rightarrow}v$ bedeutet, dass es einen
$\left(u,v\right)$-Weg in D gibt.
\item Man spricht auch von $\left(u,v\right)$-Wegen bzw. $\left(u,v\right)$-Pfaden.
\item Die Knoten $s$ und $t$ eines Graphen heißen \textbf{zusammenhängend},
wenn ein $\left(s,t\right)$-Weg existiert.
\item Ein \textbf{zusammenhängender Graph} enthält nur Knoten, die paarweise
zusammenhängend sind.
\item Ein Digraph heißt \textbf{stark zusammenhängend}, wenn es zu jedem
Knotenpaar $s,t$ einen $\left(s,t\right)$-Weg und einen $\left(t,s\right)$-Weg
gibt.
\item \textbf{Kompontenten} eines Graphen sind die (bezüglich Kanteninklusion)
maximalen zusammenhängenden Untergraphen.
\item \textbf{Starke Kompontenten} eines Diraphen sind die (bezüglich Kanteninklusion)
maximalen stark zusammenhängenden Unterdigraphen.
\item Ein Graph heißt \textbf{$k$-fach zusammenhängend}, wenn jedes Paar
Knoten $s,t$ durch mindestens $k$ $\left(s,t\right)$-Wege verbunden
ist, die keine inneren Knoten gemeinsam haben.
\item Ein Digraph heißt \textbf{$k$-fach stark zusammenhängend}, wenn jedes
Paar Knoten $s,t$ durch mindestens $k$ $\left(s,t\right)$-Wege
und $\left(t,s\right)$-Wege verbunden ist, die keine inneren Knoten
gemeinsam haben.
\item Eine \textbf{geschlossene Kette} hat mehr als $0$ Kanten und den
gleichen Anfangs- und Endknoten.
\item Ein \textbf{Kreis} ist eine geschlossene Kette mit paarweise verschiedenen
inneren Knoten. Seine \textbf{Länge} ist die Anzahl seiner Kanten.
\item Ein \textbf{Eulerpfad} ist eine Kette, die jede Kante eines (Di-)Graphen
einmal enthält.
\item Eine \textbf{Eulertour} ist ein geschlossener Eulerpfad.
\item Ein \textbf{Eulergraph} ist ein Graph, der eine Eulertour enthält.
\item Ein \textbf{Hamiltonkreis} (oder \textbf{Hamiltontour}) ist ein Kreis
der Länge $\left|V\right|$.
\item Ein \textbf{hamiltonischer} Graph enthält einen Hamiltonkreis.
\item Ein \textbf{Hamiltonweg} ist ein (gerichteter) Weg der Länge $\left|V\right|-1$.
\item Ein \textbf{Wald} ist eine Kantenmenge in einem Graphen, die keinen
Kreis enthält.
\item Ein \textbf{Baum} ist ein zusammenhängender Wald.
\item Ein \textbf{aufspannender} Baum enthält alle Knoten des Graphen.
\item Ein \textbf{azyklischer} Digraph enthält keine gerichteten Kreise.
\item Ein \textbf{Branching} in einem Digraphen ist eine azyklische Kantenmenge,
sodass jeder Knoten maximal eine Eingangskante besitzt.
\item Eine \textbf{Arboreszenz} ist ein zusammenhängendes Branching.
\item Eine \textbf{aufspannende Arboreszenz} enthält alle Knoten ihres Digraphen.
\item \textbf{Gewichte} (auch ``Kosten'', ``Distanzen'', ``Kapazitäten'',
usw.) werden durch Funktionen der Form $c:E\rightarrow\mathbb{R}$
bzw. $c:A\rightarrow\mathbb{R}$ mit Kanten assoziiert.
\end{itemize}

\section{Grundlegende Graphenalgorithmen}

\subsection{Repräsentationen von Graphen}
\begin{description}
\item [{Adjazenzliste}] Jeder Knoten hat eine Liste seiner Nachbarn gespeichert.
Speichersparend für dünne Graphen. Hinzufügen und Entfernen von Knoten
und Kanten sehr einfach. Existenz von Kanten prüfen teuer (einen Knoten
durchlaufen). Speicheraufwand: $\mathfrak{\mathcal{O}}(V+E)$
\item [{Adjazenzmatrix}] $\left|V\right|\times\left|V\right|$-Matrix,
die an der Stelle $(u,v)$ eine $1$ hat, wenn die Kante $\left(u,v\right)$
bzw. $\left\{ u,v\right\} $ existiert. Existenz von Kanten prüfen
in $\mathcal{O}(1)$. Nachbarn durchlaufen unanhängig von ihrer Anzahl
in $\mathcal{O}(V)$. Speicheraufwand: $\mathcal{O}\left(V^{2}\right)$
\item [{Inzidenzmatrix}] $\left|V\right|\times\left|E\right|$-Matrix,
die an der Stelle $(v,e)$ eine $1$ hat, wenn der Knoten $v$ Endknoten
der Kante $e$ ist. Erlaubt Untersuchung des Graphen mit diversen,
algebraischen Methoden. \emph{{[}Kein Beispiel{]}}
\end{description}
\begin{tabular}{>{\centering}m{0.3\textwidth}>{\centering}m{0.3\textwidth}>{\centering}m{0.3\textwidth}}
\includegraphics[scale=0.15]{diagramme/adjazenz} & $\begin{bmatrix}1 & \rightarrow2 & \rightarrow5\\
2 & \rightarrow1 & \rightarrow3 & \rightarrow4 & \rightarrow5\\
3 & \rightarrow2 & \rightarrow4\\
4 & \rightarrow2 & \rightarrow3 & \rightarrow5\\
5 & \rightarrow1 & \rightarrow2 & \rightarrow4
\end{bmatrix}$ & $\left[\begin{array}{c|ccccc}
 & 1 & 2 & 3 & 4 & 5\\
\hline 1 & 0 & 1 & 0 & 0 & 1\\
2 & 1 & 0 & 1 & 1 & 1\\
3 & 0 & 1 & 0 & 1 & 0\\
4 & 0 & 1 & 1 & 0 & 1\\
5 & 1 & 1 & 0 & 1 & 0
\end{array}\right]$\tabularnewline
 &  & \tabularnewline
\includegraphics[scale=0.15]{diagramme/adjazenz_dir} & $\begin{bmatrix}1 & \rightarrow2 & \rightarrow5\\
2 & \rightarrow4\\
3 & \rightarrow4\\
4\\
5 & \rightarrow2 & \rightarrow4
\end{bmatrix}$ & $\left[\begin{array}{c|ccccc}
\nearrow & 1 & 2 & 3 & 4 & 5\\
\hline 1 & 0 & 1 & 0 & 0 & 1\\
2 & 0 & 0 & 0 & 1 & 0\\
3 & 0 & 0 & 0 & 1 & 0\\
4 & 0 & 0 & 0 & 0 & 0\\
5 & 0 & 1 & 0 & 1 & 0
\end{array}\right]$\tabularnewline
\end{tabular}

\subsection{Durchsuchen von Graphen}

Das ``färben'' von Knoten ist eine Kurzschreibweise für folgende
Sachverhalte:
\begin{lyxlist}{00.00.0000}
\item [{weiß}] Der Knoten ist noch nicht erreicht. (Im Normalfall Grundzustand)
\item [{grau}] Der Knoten wurde erreicht, seine Nachbarn jedoch noch nicht
abgearbeitet.
\item [{schwarz}] Der Knoten wurde komplett bearbeitet.
\end{lyxlist}

\subsubsection{Breitensuche (BFS)}

Start bei Knoten $s$. $\pi\left[u\right]=v$ heißt $v$ ist direkter
Vorgänger von $u$. $Q$ ist eine Queue.

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{BFS}$\left(G,s\right)$:
\begin{enumerate}
\item Färbe $s$ grau, setze $d\left[s\right]=0$, $\pi\left[s\right]=\textrm{\ensuremath{\bot}}$
und initialisiere $Q$ mit $s$.
\item Färbe alle Knoten $v\in V\setminus\left\{ s\right\} $ weiß und setze
$d\left[v\right]=+\infty$ und $\pi\left[v\right]=\bot$.
\item Falls $Q$ leer, \emph{Stop}(``BFS beendet''), sonst sei $u$ erster
Knoten in $Q$.
\item Für alle $v$ aus Adjazenzliste von $u$:
\begin{enumerate}
\item Falls $v$ weiß ist, färbe $v$ grau, setze $d\left[v\right]=d\left[u\right]+1$,
$\pi\left[v\right]=u$ und füge $v$ ans Ende von $Q$ ein.
\end{enumerate}
\item Entferne $u$ aus $Q$, färbe $u$ schwarz und gehe zu $\left(3\right)$.
\end{enumerate}
%
\end{minipage}}

Laufzeit: linear in Bezug auf Adjazenzstruktur. Das heißt $\mathcal{O}\left(V+E\right)$
bei Adjazenzlisten und $\mathcal{O}\left(V^{2}\right)$ bei Adjazenzmatrizen.
\begin{defn*}
Für $v\in V$ sei $\delta\left(s,u\right)$ die Zahl der Kanten des
kürzesten $\left(s,u\right)$-Weges, bzw. $\infty$ wenn kein solcher
existiert.
\end{defn*}
\begin{lem}
Sei $G=\left(V,E\right)$ ein Graph und $s\in V$.
\begin{itemize}
\item Für jede Kante $uv\in E$ gilt: $\delta\left(s,v\right)\leq\delta\left(s,u\right)+1$.
\item Nach Terminierung von BFS$\left(G,s\right)$ gilt: $\forall v\in V:d\left[v\right]\geq\delta\left(s,v\right)$
\item Enthält $Q$ während BFS$\left(G,s\right)$ $v_{1},v_{2},\ldots,v_{r}$
gilt: $d\left[v_{r}\right]\leq d\left[v_{1}\right]+1$ und $d\left[v_{i}\right]\leq d\left[v_{i+1}\right],1\leq i<r$
\end{itemize}
\end{lem}

\begin{prop}
Sei $G=\left(V,E\right)$, $s\in V$ und BFS$\left(G,s\right)$ ausgeführt.
Dann ist jeder Knoten, der von $s$ aus erreichbar ist, schwarz gefärbt
und es gilt $d\left[v\right]=\delta\left(s,v\right)$.
\end{prop}


\subsubsection{Tiefensuche (DFS)}

Kein spezieller Startknoten. Die Zeit der Grau-Färbung wird in $d\left[v\right]$
gespeichtert, die Zeit der Schwarz-Färbung (Terminierungszeit) in
$t\left[v\right].$

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{DFS}$\left(D\right)$:
\begin{enumerate}
\item Färbe alle Knoten $u\in V$ weiß und setze $\pi\left[u\right]=\bot$.
\item Setze globale Zeit $t=0$.
\item Für jeden Knoten $u\in V$:
\begin{enumerate}
\item Falls $u$ weiß gefärbt ist, dann DFSVisit$\left(u\right)$.
\end{enumerate}
\end{enumerate}
\rule[1ex]{1\columnwidth}{1pt}

\textbf{DFSVisit}$\left(u\right)$:
\begin{enumerate}
\item Färbe $u$ grau, setze $t=t+1$ und $d[u]=t.$
\item Für alle $v$ aus Adjazenzliste von $u$:
\begin{enumerate}
\item Falls $v$ weiß ist, dann setze $\pi\left[v\right]=u$ und vollziehe
DFSVisit$\left(v\right)$.
\end{enumerate}
\item Färbe $u$ schwarz, setze $t=t+1$ und $f\left[u\right]=t$.
\end{enumerate}
%
\end{minipage}}

Laufzeit: linear in Bezug auf Adjazenzstruktur. Das heißt $\mathcal{O}\left(V+A\right)$
bei Adjazenzlisten und $\mathcal{O}\left(V^{2}\right)$ bei Adjazenzmatrizen.
\begin{defn*}
Der \textbf{DFS-Wald} des (Di-)Graphen $G=\left(V,E\right)$ ist ein
Digraph der Form $\left(V,\left\{ \left\{ \pi\left[v\right],v\right\} |v\in V,\pi\left[v\right]\neq\bot\right\} \right)$.
Er symbolisiert also den Weg durch den Graphen während einer DFS.

Alle Kanten $\left\{ u,v\right\} $ aus $E$, die nicht zum Wald gehören
sind:
\begin{description}
\item [{Vorwärtskanten}] Es gibt einen $\left(u,v\right)$-Weg im DFS-Wald
\item [{Rückwärtskanten}] Es gibt einen $(v,u)$-Weg im DFS-Wald
\item [{Kreuzungskanten}] Es gibt keinen der Wege im DFS-Wald
\end{description}
Für ungerichtete Graphen gibt es nur Rückwärtskanten.
\end{defn*}
\begin{prop}
Ein Knoten $v$ ist Nachfolger eines Knotens $u$ im DFS-Wald genau
dann, wenn gilt: Zu dem Zeitpunkt, zu dem $u$ grau gefärbt wird,
ist $v$ von $u$ aus auf einem Weg erreichbar, der nur aus weißen
Knoten besteht.
\end{prop}


\subsection{Topologisches Sortieren}

Die topologische Sortierung eines Digraphen ist eine Knotenreihenfolge,
in der alle Kanten nur zu später auftretenden Knoten führen.

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Topsort}$\left(D\right)$:
\begin{enumerate}
\item Initialisiere leere Liste $L=\emptyset$.
\item Führe DFS$\left(D\right)$ aus, mit Zusatz: Wenn ein Knoten $v$ schwarz
gefärbt wird, füge ihn am Anfang der Liste $L$ ein.
\item $L$ liefert topologische Sortierung.
\end{enumerate}
%
\end{minipage}}

Laufzeit: siehe DFS$\left(D\right)$
\begin{lem}
Ein Digraph $D$ ist genau dann kreisfrei, wenn DFS$\left(D\right)$
keine Ruckwärtskanten liefert.
\end{lem}

\begin{prop}
Ein azyklischer Digraph $D$ wird durch Topsort$\left(D\right)$ topologisch
sortiert.
\end{prop}


\subsection{Starke Zusammenhangskomponenten}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{StrongComponents}$\left(D\right)$:
\begin{enumerate}
\item Führe DFS$\left(D\right)$ aus, merke Terminierungszeiten $f\left[u\right]$
für alle $u\in V$.
\item Generiere $D^{\top}$.
\item Führe DFS$\left(D^{\top}\right)$ aus, wobei im Schritt $\left(3\right)$
die Knoten nach absteigenden Werten von $f\left[u\right]$ sortiert
werden.
\item Die Knoten jedes Baumes im DFS-Wald von $D^{\top}$ bestimmen eine
starke Zusammenhangskomponente.
\end{enumerate}
%
\end{minipage}}
\begin{lem}
Jeder Weg, der zwei Knoten aus derselben Komponente verbindet, enthält
nur Knoten aus dieser Komponente.
\end{lem}

\begin{lem}
Alle Knoten einer Komponente sind im gleichen DFS-Baum enthalten.
\end{lem}

\begin{defn*}
Für einen Knoten $u$ bezeichne $\phi(u)$ den Knoten $v$ mit der
größten Terminierungszeit bei DFS$\left(D\right)$, der von $u$ aus
in $D$ erreichbar ist, das heißt:

$\phi\left(u\right)=\mathrm{argmax}{}_{v}\left\{ f\left[v\right]|u\underset{D}{\rightarrow}v\right\} $
\end{defn*}
\begin{prop}
Für $D=\left(V,A\right)$ sei DFS$\left(D\right)$ ausgeführt. Dann
ist für jeden Knoten $\phi\left(u\right)$ Vorgänger von $u$ im DFS-Wald.
\end{prop}

\begin{prop}
Nach DFS$\left(D\right)$ liegen zwei Knoten $u$ und $v$ genau dann
in der gleichen Komponente, wenn $\phi\left(u\right)=\phi\left(v\right)$.
\end{prop}

\begin{prop}
Der Algorithmus StrongComponents identifiziert die starken Zusammenhangskomponenten
eines Digraphen.
\end{prop}


\section{Optimale Bäume und Branchings}

\subsection{Minimale aufspannende Bäume}

Die Probleme, einen minimalen, aufspannenden Baum oder einen maximalen,
aufspannenden Wald zu finden lassen sich einfach ineinander transformieren.
Darum beschränken wir uns auf ersteres.

\noindent %
\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Minimaler-aufspannender-Baum-Problem}

\smallskip{}

Gegeben ist ein Graph $G=\left(V,E\right)$ mit Kantengewichten $c_{e}$
für $e\in E$. Zu bestimmen ist ein aufspannender Baum für G, dessen
Gesamtgewicht möglichst klein ist.

(Wir nehmen an, dass $G$ zusammenhängend ist, da das Problem sonst
einzeln pro Komponente lösbar wäre.)%
\end{minipage}}

\subsubsection{Ein allgemeiner MST-Algorithmus}

Dieser Algorithmus färbt Kanten nach festen Regeln blau und rot. Es
ist stets die Invariante \emph{\glqq Es gibt einen minimalen, aufspannenden
Baum, der alle blauen und keine rote Kante enthält.``} erfüllt.
\begin{description}
\item [{Regel~B}] Wähle einen Schnitt, der keine blaue Kante enthält.
Färbe eine seiner kürzesten Kanten blau.
\item [{Regel~R}] Wähle einen Kreis, der keine rote Kante enthält. Färbe
eine seiner längsten Kanten rot.
\end{description}
\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{MinimumSpanningTree}$\left(G,c\right):$
\begin{enumerate}
\item Zu Beginn seien alle Kanten ungefärbt.
\item Wende Regeln B und R an, bis alle Kanten gefärbt sind.
\item Die blauen Kanten bilden einen minimalen aufspannenden Baum.
\end{enumerate}
%
\end{minipage}}
\begin{prop}
Der Algorithmus färbt alle Kanten eines zusammenhängenden Graphen
und erhält dabei die Invarianz-Bedingung, d.h. er berechnet einen
minimalen aufspannenden Baum.
\end{prop}


\subsubsection{Der Algorithmus von Boruvka}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Boruvka}$\left(G,c\right)$:
\begin{enumerate}
\item Initialisiere $n$ blaue Bäume bestehend aus je einem Knoten.
\item Solange mehr als ein blauer Baum vorhanden ist, wähle gleichzeitig
zu jedem blauen Baum die minimale inzidente Kante und färbe alle ausgewählten
Kanten blau.
\item Die blauen Kanten bilden einen minimalen Baum.
\end{enumerate}
%
\end{minipage}}

Der Algorithmus kann blaue Kreise erzeugen, wenn es im Graphen Kanten
gleichen Gewichts gibt.

\subsubsection{Der Algorithmus von Kruskal}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Kruskal}$\left(G,c\right)$:
\begin{enumerate}
\item Initialisiere $n$ blaue Bäume bestehend aus je einem Knoten.
\item Sortiere die Kanten von $G$ nach nichtabsteigenden Gewichten, so
dass $c_{e_{1}}\leq c_{e_{2}}\leq\ldots\leq c_{e_{m}}$.
\item Für $i=1,2,\ldots,m:$
\begin{enumerate}
\item Sind die Endknoten von $e_{i}$ im gleichen blauen Baum, färbe $e_{i}$
rot, andernfalls blau.
\end{enumerate}
\item Die blauen Kanten bilden einen minimalen Baum.
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(E\log V\right)$, wenn die Bäume per fast-union-find
verwaltet werden. Ein Heap ermöglicht Optimierung bezöglich der Sortierung,
da abgebrochen werden kann, wenn es $n-1$ blaue Kanten gibt.

\subsubsection{Der Algorithmus von Prim}

Der Algorithmus verwendet nur Regel R und benötigt einen Startknoten
$s$.

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Prim}$\left(G,c,s\right)$:
\begin{enumerate}
\item Initialisiere $n$ blaue Bäume bestehend aus je einem Knoten.
\item Solange noch blaue Bäume aus einem Knoten existieren, färbe minimale
Kante im Schnitt induziert durch den Baum, der $s$ enthält, blau.
\item Die blauen Kanten bilden einen minimalen Baum.
\end{enumerate}
%
\end{minipage}}

Es folgt eine einfach Implementierung. $T$ ist der angehende Baum:

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Prim1}$\left(G,c,s\right)$:
\begin{enumerate}
\item Setze $V_{T}=\left\{ s\right\} $, $T=\emptyset$ und $i=0$.
\item Falls $i=n-1$, \emph{Stop}(\glqq T ist MST``).
\item Bestimme $u\in V_{T}$ und $v\in V\setminus T_{T}$ mit $c_{uv}=\min\left\{ c_{xy}|x\in V_{T},y\in V\setminus V_{T}\right\} $.
\item Setze $V_{T}=V_{T}\cup\left\{ v\right\} $ und $T=T\cup\left\{ uv\right\} $
und $i=i+1$. Gehe zu (2).
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(VE\right)$

Es gibt eine bessere Implementierung.$t\left[v\right]$ speichert
den nächsten Baumknoten, $d\left[v\right]$ die zugehörige Distanz.

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Prim2}$\left(G,c,s\right)$:
\begin{enumerate}
\item Setze $V_{T}=\left\{ s\right\} $, $T=\emptyset$ und $i=0$. Setze
$d\left[v\right]=c_{sv}$ und $t\left[v\right]=s$, falls $sv\in E$,
setze $d\left[v\right]=\infty$ und $t\left[v\right]=\bot$, falls
$sv\notin E$.
\item Falls $i=n-1$, \emph{Stop}(\glqq T ist MST``).
\item Bestimme $v\in V\setminus T_{T}$ mit $d\left[v\right]=\min\left\{ d\left[u\right]|u\in V\setminus V_{T}\right\} $.
\item Setze $V_{T}=V_{T}\cup\left\{ v\right\} $ und $T=T\cup\left\{ t\left[v\right]v\right\} $.
\item Für alle $w$ adjazent zu $v$:
\begin{enumerate}
\item Falls $w\in V\setminus V_{T}$ und $c_{vw}<d\left[w\right]$, dann
setze $d\left[w\right]=c_{vw}$ und $t\left[w\right]=v$.
\end{enumerate}
\item Setze $i=i+1$ und gehe zu (2).
\end{enumerate}
%
\end{minipage}} 

\begin{tabular}{ll}
Laufzeit (naiv): & $\mathcal{O}\left(V^{2}\right)$\tabularnewline
Laufzeit (Heap): & $\mathcal{O}\left(E\log V\right)$ (besser für dünnbesetzte Graphen)\tabularnewline
Laufzeit (Fib-Heap): & $\mathcal{O}\left(E+V\log V\right)$\tabularnewline
\end{tabular}

\subsubsection{Der Round-Robin-Algorithmus}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{RoundRobin}$\left(G,c\right)$:
\begin{enumerate}
\item Initialisiere $n$ blaue Bäume bestehend aus je einem Knoten.
\item Solange weniger als $n-1$ blaue Kanten vorhanden sind, wähle einen
blauen Baum, bestimme die kürzeste Kante im durch diesen Baum induzierten
Schnitt und färbe sie blau.
\item Die blauen Kanten bilden einen minimalen Baum.
\end{enumerate}
%
\end{minipage}}

Eine $\mathcal{O}\left(E\log\log V\right)$-Implementation ist möglich,
wenn immer der kleinste Baum gewählt wird.

\subsubsection{Eine Anwendung aufspannender Bäume}

Sogenannte 1-Bäume sind eine untere Schranke für eine optimale TSM-Tour.

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{OneTree}$\left(G,c\right)$:
\begin{enumerate}
\item Bestimme für die Knoten $\left\{ 2,3,\ldots,n\right\} $einen MST
$T$. Sei $c_{T}$ die Länge des MST.
\item Seien $e_{1}$ und $e_{2}$ die zwei kürzesten Kanten an Knoten $1$.
\item $T\cup\left\{ e_{1},e_{2}\right\} $ist optimaler 1-Baum mit Wert
$c_{T}+c_{e_{1}}+c_{e_{2}}$.
\end{enumerate}
%
\end{minipage}}

\subsection{Maximale Branchings}

Neue Notationen: $s:A\rightarrow V$, $t:A\rightarrow V$ und $c:A\rightarrow\mathbb{R}$
sind Start- und Endknoten sowie Gewichte von Kanten.

\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Maximales-Branching-Problem}

Gegeben ist ein Digraph $D=\left(V,A\right)$ mit Kantengewichten
$c_{e}$, für $e\in A$. Zu bestimmen ist ein Branching für $D$,
dessen Gesamtgewicht möglichst groß ist.%
\end{minipage}}

\subsubsection{Der Branching-Algorithmus von Edmonds}
\begin{defn}
Sei $D=\left(V,A\right)$ ein Digraph mit Kantengewichten $c_{e}$,
für $e\in A$.
\begin{lyxlist}{00.00.0000}
\item [{a)}] Eine Kante $e\in A$ heißt \textbf{kritisch}, falls $c\left(e\right)>0$
und falls $c\left(e^{\prime}\right)\leq c\left(e\right)$, für alle
$e^{\prime}\in A$ mit $t\left(e^{\prime}\right)=t\left(e\right)$.
\item [{b)}] Ein Subgraph $H\subseteq A$ heißt \textbf{kritisch}, falls
er nur aus kritischen Kanten besteht, jeder Knoten Endknoten von höchstens
einer dieser Kanten ist, und falls er inklusionsmaximal bezüglich
dieser Eigenschaft ist.
\end{lyxlist}
\end{defn}

\begin{lem}
Ein azyklischer kritischer Graph $H$ ist ein maximaler Branching.
\end{lem}

\begin{lem}
Sei $H$ ein kritischer Graph. Dann ist jeder Knoten von $H$ in maximal
einem Kreis enthalten.
\end{lem}

\begin{lem}
Seien $B$ ein Branching und $u$, $v$, $w$ drei Knoten. Falls $u\underset{B}{\rightarrow}v$
und $w\underset{B}{\rightarrow}v$, dann gilt entweder $u\underset{B}{\rightarrow}w$
oder $w\underset{B}{\rightarrow}u$.
\end{lem}

\begin{defn*}
Sei $B$ ein Branching. Eine Kante $e\notin B$ heißt \textbf{zulässig}
(relativ zu B), falls die Menge $B^{\prime}=B\cup\left\{ e\right\} \setminus\left\{ f|f\in B\wedge t\left(f\right)=t\left(e\right)\right\} $
ebenfalls ein Branching ist.
\end{defn*}
\begin{lem}
Sei $B$ ein Branching und $e\in A\setminus B$. Dann ist $e$ genau
dann zulässig relativ zu $B$, wenn kein Weg von $t\left(e\right)$
nach $s\left(e\right)$ in $B$ existiert.
\end{lem}

\begin{lem}
Sei $B$ ein Branching und $C$ ein Kreis mit der Eigenschaft, dass
keine Kante aus $C\setminus B$ zulässig relativ zu $B$ ist. Dann
gilt $\left|C\setminus B\right|=1$. 
\end{lem}

\begin{prop}
Sei $H$ ein kritischer Graph. Dann existiert ein Branching$B$ mit
maximalem Gewicht, so dass für jeden Kreis $C\subseteq H$ gilt $\left|C\setminus B\right|=1$.
\end{prop}

Im Folgenden bezeichne $V_{i}=V\left(C_{i}\right)$ und $a_{i}$ die
kürzeste Kante in $C_{i}$.
\begin{cor}
Sei $D=\left(V,A\right)$ ein Digraph mit Kantengewichten und $H$
ein kritischer Graph mit Kreisen $C_{i},i=1,2,\ldots,k$. Es existiert
ein gewichtsmaximales Branching $B$ mit den Eigenschaften
\begin{lyxlist}{00.00.0000}
\item [{a)}] $\left|C_{i}\setminus B\right|=1$, für $i=1,2,\ldots,k$
\item [{b)}] Falls für jede Kante $e\in B\setminus C_{i}$ gilt, dass $t\left(e\right)\notin V_{i},$dann
folgt $C_{i}\setminus B=\left\{ a_{i}\right\} $.
\end{lyxlist}
\end{cor}

\noindent\fbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule}%
\textbf{Schrumpfen von kritischen Graphen}:

Sei $\widetilde{V}=V\setminus\bigcup_{i=1}^{k}V_{i}$. Für $v\in V_{i}$
sei $\widetilde{e}\left(v\right)$ die Kante aus $C_{i}$ mit $t\left(\widetilde{e}\left(v\right)\right)=v$,
d.h. die Kreiskante mit Endknoten $v$.

\[
\begin{aligned}\overline{A}= & \left\{ e\in A|\text{für kein }i\text{ gilt }s\left(e\right)\in V_{i}\text{ und }t\left(e\right)\in V_{i}\right\} \\
= & A\setminus\bigcup_{i=1}^{k}A\left(V\left(C_{i}\right)\right)\text{,}\\
\overline{V}= & \widetilde{V}\cup\left\{ w_{1},w_{2},\ldots,w_{k}\right\} \text{, wobei die \ensuremath{w_{i}} neue Symbole sind,}\\
\overline{s}\left(e\right)= & \begin{cases}
s\left(e\right)\text{,} & \text{falls \ensuremath{s\left(e\right)\in\widetilde{V}},}\\
w_{i} & \text{falls \ensuremath{s\left(e\right)\in V_{i}},}
\end{cases}\\
\overline{t}\left(e\right)= & \begin{cases}
t\left(e\right)\text{,} & \text{falls \ensuremath{t\left(e\right)\in\widetilde{V}},}\\
w_{i} & \text{falls \ensuremath{t\left(e\right)\in V_{i}},}
\end{cases}\\
\overline{c}\left(e\right)= & \begin{cases}
c\left(e\right)\text{,} & \text{falls \ensuremath{t\left(e\right)\in\widetilde{V}},}\\
c\left(e\right)-c\left(\widetilde{e}\left(t\left(e\right)\right)\right)+c\left(a_{i}\right) & \text{falls \ensuremath{t\left(e\right)\in V_{i}}.}
\end{cases}
\end{aligned}
\]

Es entsteht ein neues Problem $\overline{P}$ im Digraphen $\overline{D}=\left(\overline{V},\overline{A}\right)$
mit den neuen Inzidenzfunktionen $\overline{s}$, $\overline{t}$
und Gewichtsfunktion $\overline{c}$.%
\end{minipage}}
\begin{prop}
Es gibt eine bijektive Abbildung zwischen $\mathcal{B}$ (der Menge
der Branchings im Originalproblem) und der Menge der Branchings im
Problem $\overline{P}$. Es korrespondiert das Branching $B\in\mathcal{B}$
mit dem Branching $\overline{B}=B\cap\overline{A}$ in $\overline{P}$
und es gilt:

\[
c\left(B\right)-\overline{c}\left(\overline{B}\right)=\sum_{i=1}^{k}c\left(C_{i}\right)-\sum_{i=1}^{k}c\left(a_{i}\right)\text{.}
\]
\end{prop}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Branching}$\left(D,c\right)$:
\begin{enumerate}
\item Bestimme einen kritischen Graphen $H$ für $D$.
\item Ist $H$ azyklisch, dann \emph{Stop}(\glqq $H$ ist optimales Branching
für $D$``).
\item Schrumpfe die Kreise von $H$, um $\overline{D}$ und $\overline{c}$
zu erhalten.
\item Berechne durch den rekursiven Aufruf \emph{Branching}$\left(\overline{D},\overline{c}\right)$
ein optimales Branching $\overline{B}$ für $\overline{D}$.
\item Expandiere das Branching $\overline{B}$ zu einem optimalen Branching
$B$ für $D$.
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(A\log V\right)$ oder $\mathcal{O}\left(V^{2}\right)$.

\subsubsection{Arboreszenzen und das asymmetrische TSP}

$\rightarrow$analog zum symmetrischen Fall

\section{Kürzeste Wege}

\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Kürstester-$\left(s,t\right)$-Weg-Problem}

Gegeben sind ein Digraph $D=\left(V,A\right)$ mit Kantengewichten
$c_{e}$ für $e\in A$, und zwei Knoten $s,t\in V$. Zu bestimmen
ist ein $\left(s,t\right)$-Weg in $D$, dessen Gesamtlänge möglichst
klein ist.%
\end{minipage}}

\subsection{Eigenschaften kürzester Wege}
\begin{defn*}
Im folgenden ist $s\in V$ der Startknoten, dessen kürzeste Wege berechnet
werden sollen. $\delta\left(u,v\right)$ ist die Länge des kürzesten
$\left(u,v\right)$-Weges, bzw. $+\infty$ (oder $-\infty$) wenn
keiner existiert. $\pi\left[v\right]$ ist der Vorgängerknoten von
$v$ auf dem kürstesten $\left(s,v\right)$-Weg.
\end{defn*}
\begin{lem}
Sei $p=\left(v_{1}v_{2},v_{2}v_{3},\ldots,v_{k-1}v_{k},\right)$ ein
kürzester Weg von $v_{1}$ nach $v_{k}$. Dann ist für $1\leq i\leq j\leq k$
der Teilweg $\left(v_{i}v_{i+1},\ldots,v_{j-1}v_{j},\right)$ ein
kürzester Weg von $v_{i}$ nach $v_{j}$.
\end{lem}

\begin{lem}
Für jede Kante $\left(u,v\right)$ gilt $\delta\left(s,v\right)\leq\delta\left(s,u\right)+c_{uv}$.
\end{lem}

Die \textbf{Standardinitialisierung} für $d$ ist $d\left[s\right]=0$
und $d\left[v\right]=\infty,v\in V\setminus\left\{ s\right\} $ und
$\pi\left[v\right]=\bot,v\in V$. 

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Correct}$\left(u,v\right)$:

Falls $d\left[v\right]>d\left[u\right]+c_{uv}$, dann setze $d\left[v\right]=d\left[u\right]+c_{uv}$
und $\pi\left[v\right]=u$.%
\end{minipage}}
\begin{lem}
Nach Initialisierung gilt $d\left[v\right]\geq\delta\left(s,v\right)$,
für alle $v\in V$. Dies gilt auch nach Ausführung einer beliebigen
Folge von Correct()-Aufrufen. Falls einmal $d\left[v\right]=\delta\left(s,v\right)$
gilt, so kann $d\left[v\right]$nicht mehr verändert werden.
\end{lem}

\begin{lem}
$D$ enthalte keine von $s$ aus erreichbaren negativen Kreise und
die Standardinitialisierung sei ausgeführt. Für jede Folge von Korrekturoperationen
bildet der durch $\pi$ bestimmte Digraph $D_{\pi}$ eine Arboreszenz
mit Wurzel $s$.
\end{lem}


\subsection{Der Algorithmus von Dijkstra}

Der Algorithmus berechnet alle kürzesten Wege von $s$, wenn $c_{uv}\geq0$,
für alle $\left(u,v\right)\in A$.

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Dijkstra}$\left(D,c,s\right)$:
\begin{enumerate}
\item Setze $d\left[v\right]=\infty$, für alle $v\in V\setminus\left\{ s\right\} $,
$d\left[s\right]=0$ und $\pi\left[v\right]=\bot$ für alle $v\in V$.
\item $S=\emptyset,Q=V$.
\item Solange $Q\neq\emptyset$:
\begin{enumerate}
\item Bestimme $u$ mit $d\left[u\right]=\min_{v}\left\{ d\left[v\right]|v\in Q\right\} $.
\item $S=S\cup\left\{ u\right\} ,Q=Q\setminus\left\{ u\right\} $
\item Für jede Kante $\left(u,v\right)\in A$ mit $v\in Q$ führe \emph{Correct}$\left(u,v\right)$
aus.
\end{enumerate}
\end{enumerate}
%
\end{minipage}}

\begin{tabular}{ll}
Laufzeit (naiv): & $\mathcal{O}\left(V^{2}\right)$\tabularnewline
Laufzeit (Heap): & $\mathcal{O}\left(A\log V\right)$ (besser für dünnbesetzte Graphen)\tabularnewline
Laufzeit (Fib-Heap): & $\mathcal{O}\left(A+V\log V\right)$\tabularnewline
\end{tabular}
\begin{prop}
Nach Ausführung des Algorithmus von Dijkstra gilt $d\left[v\right]=\delta\left(s,v\right)$
für alle $v\in V$.
\end{prop}


\subsection{Der Algorithmus von Bellman und Ford}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{BellmanFord}$\left(D,c,s\right)$:
\begin{enumerate}
\item Initialisiere $d\left[v\right]=\infty$, für alle $v\in V\setminus s$,
$d\left[s\right]=0,\pi\left[v\right]=\bot$ für alle $v\in V$.
\item Führe die folgende Schleife $\left(\left|V\right|-1\right)$-mal aus:
\begin{enumerate}
\item Für alle $\left(u,v\right)\in A$ führe \emph{Correct}$\left(u,v\right)$
aus.
\end{enumerate}
\item Für alle $\left(u,v\right)\in A$:
\begin{enumerate}
\item Falls $d\left[v\right]>d\left[u\right]+c_{uv}$ dann \emph{Stop}(\glqq Graph
enthält negativen Kreis``).
\end{enumerate}
\item \emph{Stop}(\glqq Der Kürzeste-Wege-Baum wurde berechnet``).
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(VA\right)$
\begin{lem}
$D$ enthalte keinen von $s$ aus erreichbaren negativen Kreis. Dann
gilt bei Terminierung des Bellman-Ford-Algorithmus $d\left[v\right]=\delta\left(s,v\right)$
für alle Knoten in $v$, die von $s$ aus erreichbar sind.
\end{lem}

\begin{cor}
Es gibt einen Weg von $s$ nach $v$ genau dann, wenn der Bellman-Ford-Algorithmus
mit $d\left[v\right]<\infty$ terminiert.
\end{cor}

\begin{prop}
Der Bellman-Ford-Algorithmus arbeitet korrekt, das heißt entweder
er stellt fest, dass $D$ einen negativen Kreis enthält, oder er berechnet
die Arboreszenz der kürzesten Wege von $s$ zu allen erreichbaren
Knoten.
\end{prop}


\paragraph{Yen-Variante}

Ersetze (2.1) durch:
\begin{lyxlist}{00.00.0000}
\item [{(2.1)}] Für $i=1,\ldots,n$: \emph{Correct}$\left(v_{i},v_{k}\right)$
für alle $\left(v_{i},v_{k}\right)\in A$ mit $i<k$.
\item [{(2.2)}] Für $i=n,n-1,\ldots,1$: \emph{Correct}$\left(v_{i},v_{j}\right)$
für alle $\left(v_{i},v_{j}\right)\in A$ mit $i>j$.
\end{lyxlist}

\paragraph{Variante von d\textquoteright Esopo und Pape}

Bevorzugt Knoten, die sich verbessert haben. Exponentielle Worst-Case-Laufzeit,
aber oft effizienter für dünne Graphen.

Modifikation der Correct-Operation:

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Correct}$\left(u,v\right)$:

Falls $d\left[v\right]>d\left[u\right]+c_{uv}$, dann:
\begin{enumerate}
\item Setze $d\left[v\right]=d\left[u\right]+c_{uv}$ und $\pi\left[v\right]=u$.
\item Falls $v$ noch nicht in $Q$ war, setze $v$ an das Ende von $Q$.
\item Falls $v$ schon in $Q$ war, aber gegenwärtig nicht $Q$ ist, dann
setze $v$ an den Anfang von $Q$.
\end{enumerate}
%
\end{minipage}}

Terminiert, wenn $Q$ leer.

\paragraph{Verfahren von Nicholson}

Sucht kürzesten $\left(s,t\right)$-Weg gleichzeitig von $s$ und
$t$.

\paragraph{$A^{\ast}$-Verfahren}

Verwendet Schätzwerte $s\left(v,t\right)$ für die Entfernung zum
Zielknoten, priorisiert Knoten mit niedrigem $d\left[v\right]+s\left(v,t\right)$.
Terminiert, wenn $d\left[t\right]$ und $s\left(s,t\right)$ nag genug
beieinander.

\subsection{Kürzeste Wege in azyklischen Digraphen}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{DAGShortestPath}$\left(D,c,s\right)$:
\begin{enumerate}
\item Sei $t\left[1\right],\ldots,t\left[n\right]$ eine topologische Sortierung
der Knoten von $D$.
\item Setze $d\left[v\right]=\infty$, für alle $v\in V\setminus\left\{ s\right\} $,
$\pi\left[v\right]=\bot$, für alle $v\in V$, und $d\left[s\right]=0$.
\item Für $i=1,2,\ldots,n$:
\begin{enumerate}
\item Setze $u=t\left[i\right]$.
\item Für alle $v\in V$ mit $\left(u,v\right)\in A$ führe \emph{Correct$\left(u,v\right)$
aus.}
\end{enumerate}
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(V+A\right)$

\subsubsection{Berechnung optimaler Lösungen des Knapsack-Problems}


\subsubsection{Eine Anwendung in der Tourenplanung}


\subsubsection{Längste Wege}

Dies ist nur in azyklischen Digraphen möglich, oder wenn alle Kantengewichte
negativ oder 0 sind.

Entweder man komplementiert alle Gewichte oder ändert die Initialisierung
von $d$ in $-\infty$ und dreht den Vergleich in der \emph{Correct}-Operation
um.

\subsection{Kürzeste Wege zwischen allen Knotenpaaren}

Eine Möglichkeit wäre das $\left|V\right|$-malige Anwenden von Dijkstra
oder Bellman-Ford, was in der $\left|V\right|$-fachen Komplexität
resultiert.

\subsubsection{Der Algorithmus von Floyd und Warshall}

$D$ habe ganzzahlige Gewichte und keine negativen Kreise.

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{AllPairsShortestPaths}$\left(D,c\right)$:
\begin{enumerate}
\item Setze $d\left[i,j\right]=+\infty$, für alle $i,j\in V$, und $d\left[i,i\right]=0$,
für alle $i\in V$.
\item Für alle $\left(i,j\right)\in A$, setze $d\left[i,j\right]=c_{ij}$.
\item Solange es Knoten $i,j,k\in V$ gibt, mit $d\left[i,j\right]>d\left[i,k\right]+d\left[k,j\right]$
setze $d\left[i,j\right]=d\left[i,k\right]+d\left[k,j\right]$.
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(\left|V\right|^{2}\left(2\left|V\right|C\right)\right)$
mit $C$ = $\max\left\{ \left|c_{ij}\right||\left(i,j\right)\in A\right\} $
-> nicht poly!

Eine Verbesserung ergibt sich wie folgt:

Wenn alle kürzesten Wege bekannt sind, die nur die ersten $k-1$ Knoten
als Zwischenknoten verwenden, lässt sich ein kürzester Weg, der den
$k$-ten Knoten (und möglicherweise seine Vorgänger) als Zwischenknoten
nutzt durch $d\left(i,k\right)+d\left(k,j\right)$ bestimmen.

Sei $D^{\left(k\right)}$ eine Matrix mit $d_{ij}^{\left(k\right)}$
als kürzester Weg zwischen $i$ und $j$, der nur die ersten $k$
Knoten als Zwischenknoten nutzt:

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{FloydWarshall}$\left(C\right)$:
\begin{enumerate}
\item Initialisiere $D^{\left(0\right)}=C$, mit $c_{ij}=+\infty$ wenn
keine Kante $\left(i,j\right)$ existiert.
\item Für $k=1,2,\ldots,\left|V\right|$:
\begin{enumerate}
\item Für $i=1,2,\ldots,\left|V\right|$:
\begin{enumerate}
\item Für $j=1,2,\ldots,\left|V\right|$:\\
$d_{ij}^{\left(k\right)}=\min\left\{ d_{ij}^{\left(k-1\right)},d_{ik}^{\left(k-1\right)}+d_{kj}^{\left(k-1\right)}\right\} $
\end{enumerate}
\end{enumerate}
\item $D^{\left(\left|V\right|\right)}$ enthält die Längen der kürzesten
Wege.
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(V^{3}\right)$

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Johnson}$\left(D,c\right)$:
\begin{enumerate}
\item Bilde $D^{\prime}=\left(V^{\prime},A^{\prime}\right)$ mit $V^{\prime}=V\cup\left\{ s\right\} $,
$A^{\prime}=A\cup\left\{ \left(s,v\right)|v\in V\right\} $ und setze
$c_{sv}=0$, für alle $v\in V$.
\item Führe \emph{Bellman-Ford}$\left(D^{\prime},c,s\right)$ aus.
\item Enthält $D^{\prime}$ negative Kreise, \emph{Stop}(,,Algorithmus
nicht anwendbar``)
\item Setze für jeden Knoten $v\in V:h\left[v\right]=\delta\left(s,v\right)$.
\item Setze für jede Kante $\left(u,v\right)\in A:\overline{c}_{uv}=c_{uv}+h\left[u\right]-h\left[v\right]$.
\item Für jeden Knoten $u\in V$:
\begin{enumerate}
\item Führe Dijkstra$\left(D,\overline{c},u\right)$ aus. Sei $\overline{\delta}\left(u,v\right)$
die Kürzeste-Wege-Distanz von $u$ nach $v\in V\setminus\left\{ u\right\} $
(bzgl. $\overline{c}$).
\item Für jedes $v\in V\setminus\left\{ u\right\} $ ist die Länge des kürzesten
$\left(u,v\right)$-Weges $\overline{\delta}\left(u,v\right)+h\left[v\right]-h\left[u\right]$.
\end{enumerate}
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(VA\log V\right)$ oder $\mathcal{O}\left(VA+V^{2}\log V\right)$
je nach Dijkstra-Implementierung

\subsection{Varianten kürzester Wege}

\subsubsection{Bottleneck-Probleme}

In einem Graphen wird ein $\left(s,t\right)$-Weg gesucht, dessen
kürzeste Kante größtmögliche Länge hat.

\paragraph{Initialisierung}

$d\left[v\right]=-\infty$, für alle $v\in V\setminus\left\{ s\right\} $,
$d\left[s\right]=+\infty,\pi\left[v\right]=\bot$, für alle $v\in V$.

\paragraph{Korrektur}

Falls $d\left[v\right]<\min\left\{ d\left[u\right],c_{uv}\right\} $,
dann setze $d\left[v\right]=\min\left\{ d\left[u\right],c_{uv}\right\} $
und $\pi\left[v\right]=u$.

\subsubsection{Netzwerke mit Gewinnen und Verlusten}

Das \textbf{Arbitrage-Problem} funktioniert wie ein Kürzeste-Wege-Problem,
nur dass Kanten auf einem Weg multipliziert werden. Entweder Initialisierung
und Correct werden angepasst, oder alle Kantengewichte logarithmiert.

\subsection{Kreise mit bestem Kosten-Zeit-Verhältnis}

Gesucht ist $\mu^{\ast}=\min_{B\text{ Kreis in }D}\mu\left(B\right)$
mit $\mu\left(B\right)=\frac{\sum_{\left(i,j\right)\in B}c_{ij}}{\sum_{\left(i,j\right)\in B}\tau_{ij}}$.

$\mu$ ist ein Schätzwert für $\mu^{\ast}\in\left[-\left|V\right|C,+\left|V\right|C\right]$,
welcher per Intervallschachtelung verbessert wird. $\left(C=\max c_{ij}\right)$

Es wird ein Digraph $\overline{D}$ erstellt mit $l_{ij}=c_{ij}-\mu\tau_{ij}$
für alle $\left(i,j\right)\in A$.
\begin{itemize}
\item Enthält $\overline{D}$ einen negativen Kreis, ist $\mu$ zu groß.
\item Enthält $\overline{D}$ nur positive Kreise, ist $\mu$ zu klein.
\item Enthält $\overline{D}$ einen Kreis der Länge $0$, minimiert dieser
die Zielfunktion.
\end{itemize}
Das Verfahren kann auch abgebrochen werden, wenn die Intervallgrenzen
weniger als $\frac{1}{n^{2}T^{2}}$ auseinander liegen. $\left(T=\max\tau_{ij}\right)$

Laufzeit: $\mathcal{O}\left(VA\log\left(CVT\right)\right)$

\section{Das Zuordnungsproblem}

\subsection{Anwendungen und Grundlagen}

\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
Perfektes-Matching-Problem in bipartiten Graphen

Sei $K_{n,n}$ der vollständige bipartite Graph mit jeweils $n$ Knoten
in den zwei Teilmengen $V_{1}$ und $V_{2}$ mit $V_{1}\cup V_{2}=V$
und Kantengewichten $c_{ij}$ für $i\in V_{1}$ und $j\in V_{2}$.
Gesucht ist ein perfektes Matching $\left(\forall v\in V:\left|\delta\left(v\right)\right|=1\right)$
in $K_{n,n}$ mit minimalem Gesamtgewicht.%
\end{minipage}}

\medskip{}

Das Problem wird mit Hilfe linearer Programmierung gelöst werden.
Es lässt sich wie folgt als lineares Programm darstellen:

\[
\begin{aligned}\text{(AP)} & \begin{aligned} & \min & \sum_{i=1}^{n} & \sum_{j=1}^{n}c_{ij}x_{ij}\\
 &  & \sum_{j=1}^{n} & x_{ij}=1\text{, für }i=1,2,\ldots,n\\
 &  & \sum_{i=1}^{n} & x_{ij}=1\text{, für }j=1,2,\ldots,n\\
 &  &  & x_{ij}\in\left\{ 0,1\right\} \text{, für }i=1,2,\ldots,n\text{, }j=1,2,\ldots,n
\end{aligned}
\end{aligned}
\]

Das duale Programm dazu ist:

\[
\begin{aligned}\text{(AP}_{D}\text{)} & \begin{alignedat}{1}\max & \sum_{i=1}^{n}u_{i}+\sum_{j=1}^{n}v_{j}\\
 & u_{i}+v_{j}\leq c_{ij}\text{, für }1,2,\ldots,n\text{, }j=1,2,\ldots n.
\end{alignedat}
\end{aligned}
\]
\begin{prop*}
Schwacher Dualitätssatz (am Beispiel)

Wenn $x$ zulässig für (AP) ist und $\left(u,v\right)$ zulässig für
(AP$_{D}$) sind, gilt: 

\[
\sum_{i=1}^{n}\sum_{j=1}^{n}c_{ij}x_{ij}\geq\sum_{i=1}^{n}u_{i}+\sum_{j=1}^{n}v_{j}
\]
\end{prop*}
%
\begin{prop*}
Satz vom komplenetären Schlupf (am Bsp.)

Ein Paar von zulässigen Lösungen $x$ für (AP) und $\left(u,v\right)$
für (AP$_{D}$) sind genau dann optimal, wenn gilt

\[
u_{i}+v_{j}<c_{ij}\Rightarrow x_{ij}=0
\]

bzw.

\[
x_{ij}>0\Rightarrow u_{i}+v_{j}=c_{ij}
\]
\end{prop*}

\subsection{Die Ungarische Methode}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{HungarianMethod}$\left(n,C\right)$:
\begin{enumerate}
\item Bestimme eine dual zulässige Startlösung $\left(u^{0},v^{0}\right)$,
setze $i=0$.
\item Konstruiere zu $\left(u^{i},v^{i}\right)$ einen 0/1-Vektor $x^{i}$,
so dass die Bedingungen vom komplementären Schlupf erfüllt sind.
\item Beschreibt $x^{i}$ eine Zuordnung, \emph{Stop}(,,Zuordnung optimal``)
\item Berechne eine neue dual zulässige Lösung $\left(u^{i+1},v^{i+1}\right)$,
setze $i=i+1$, gehe zu (2).
\end{enumerate}
%
\end{minipage}}

(Dies ist die grobe Idee des Algorithmus)
\begin{defn}
Folgende Definitionen werden für die Methode benötigt:
\begin{lyxlist}{00.00.0000}
\item [{a)}] Für eine dual zulässige Lösung $\left(u,v\right)$ heißt die
Matrix $\overline{C}=\left(\overline{c}_{ij}\right)$ mit $\overline{c}_{ij}=c_{ij}-u_{i}-v_{j}$
die \textbf{reduzierte Matrix}.
\item [{b)}] Sei $\overline{C}$ eine reduzierte Matrix. eine Menge $N\subseteq\left\{ 1,\ldots,n\right\} \times\left\{ 1,\ldots,n\right\} $
heißt Menge von \textbf{unabhängigen Nullen}, falls
\begin{enumerate}
\item $\overline{c}_{ij}=0$, für alle $\left(i,j\right)\in N$,
\item $\left|\left\{ j|\left(i,j\right)\in N\right\} \right|\leq1$, für
alle $i=1,\ldots,n$,
\item $\left|\left\{ i|\left(i,j\right)\in N\right\} \right|\leq1$, für
alle $j=1,\ldots,n$.
\end{enumerate}
\item [{c)}] Eine \textbf{Überdeckung }einer reduzierten Matrix ist eine
Menge von Zeilen- und Spaltenindizes, so dass die zugehörigen Zeilen
und Spalten sämtliche Nullelemente von $\overline{C}$ enthalten.
\end{lyxlist}
\end{defn}

\begin{prop}
Sei $\overline{C}$ eine reduzierte Matrix. Die maximale Kardinalität
einer Menge von unabhängigen Nullen ist gleich der minimalen Kardinalität
einer Überdeckung.

(In einem bipartiten Graphen ist die maximale Kardinalität eines Matchings
gleich der minimalen Kardinalität einer Kantenüberdeckung mit Knoten.)
\end{prop}


\subsubsection{Bestimmung einer Startlösung}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{Start}$\left(n,C\right)$:
\begin{enumerate}
\item Berechne Zeilenminima $u_{i}=\min\left\{ c_{ij}|j=1,\ldots,n\right\} $,
für alle $i=1,\ldots,n$.
\item Setze $\overline{c}_{ij}=c_{ij}-u_{i}$, für alle $i=1,\ldots,n$,
$j=1,\ldots,n$.
\item Berechne Spaltenminima $v_{j}=\min\left\{ c_{ij}|i=1,\ldots,n\right\} $,
für alle $j=1,\ldots,n$.
\item Setze $\overline{c}_{ij}=\overline{c}_{ij}-v_{j}$, für alle $i=1,\ldots,n$,
$j=1,\ldots,n$.
\end{enumerate}
%
\end{minipage}}

Wir gehen nun spaltenweise vor und zeichnen die Null mit dem niedrigsten
Zeilenindex als unabhängige Null aus.

\subsubsection{Bestimmung einer minimalen Überdeckung}

\textbf{}%
\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{MinimusCover}$\left(n,\overline{C}\right)$:
\begin{enumerate}
\item Alle Zeilen und Spalten von $\overline{C}$ seien unmarkiert und nicht
überprüft. Sind $n$ unabhängige Nullen vorhanden gehe zu (5).
\item Alle Zeilen ohne unabhängige Null erhalten die Markierung ,,($-$)``.
\item Gibt es keine markierte, noch nicht überprüfte Zeile, so gehe zu (4).\\
Andernfalls sei $i$ eine solche Zeile.
\begin{enumerate}
\item Erkläre $i$ für überprüft.
\item Existiert keine unmarkierte Spalte, die in Zeile $i$ eine Null enthält,
gehe zu (3).\\
Andernfalls sei $j$ eine solche Spalte.
\item Markiere $j$ mit ,,(i)``.
\item Besitzt $j$ schon eine unabhängige Null gehe zu (3.2).\\
Andernfalls kann durch Verfolgen der Markierungen ausgehend von $j$
eine alternierende Kette von abhängigen und unabhänigen Nullen konstruiert
werden. Ändere die Klassifizierung dieser Nullen und gehe zu (1).
\end{enumerate}
\item Gibt es keine markierte, noch nicht überprüfte Spalte, so gehe zu
(5).\\
Andernfalls sei $j$ eine solche Spalte.
\begin{enumerate}
\item Erkläre $j$ für überprüft.
\item Markiere die Zeile, in der die unabhängige Null von Spalte $j$ steht,
mit ,,(j)``.
\item Gehe zu (3).
\end{enumerate}
\item Die Maximalzahl unabhängiger Nullen ist berechnet. Die zugehörige
minimale Überdeckung ergibt sich durch Zeilen, die nicht markiert
sind und Spalten, die markiert sind.
\end{enumerate}
%
\end{minipage}}

\subsubsection{Korrektur der Duallösung}

$I$ bezeichnet die Indizes der Zeilen der minimalen Überdeckung,
$J$ die der Spalten.

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{DualUpdate}$\left(n,\overline{C},I,J\right)$:
\begin{enumerate}
\item Setze $\delta=\min\left\{ \overline{c}_{ij}|i\notin I\wedge j\notin J\right\} $.
\item Setze $\begin{aligned}u_{i}=\begin{cases}
u_{i}+\delta\text{,} & \text{für }i\notin I\text{,}\\
u_{i} & \text{sonst,}
\end{cases} & \;\;\;\; & v_{j}=\begin{cases}
v_{j}-\delta\text{,} & \text{für }j\notin J\text{,}\\
v_{j} & \text{sonst.}
\end{cases}\end{aligned}
$
\item Setze $\overline{c}_{ij}=\begin{cases}
\overline{c}_{ij}-\delta\text{,} & \text{für }i\notin I,j\notin J\text{,}\\
\overline{c}_{ij}+\delta\text{,} & \text{für }i\in I,j\in J\text{,}\\
\overline{c}_{ij}, & \text{sonst.}
\end{cases}$
\end{enumerate}
%
\end{minipage}}
\begin{prop}
Die Ungarische Methode löst Zuordnungsprobleme in der Zeit $\mathcal{O}\left(n^{3}\right)$.
\end{prop}


\subsection{Ein dualer Algorithmus}

Im Folgenden werden diese Notationen genutzt:
\begin{itemize}
\item $w_{ij}=c_{ij}-u_{i}-v_{j}$
\item $I=\left\{ 1,2,\ldots,n\right\} $ ist die Menge der Zeilenknoten
\item $J=\left\{ 1,2,\ldots,n\right\} $ ist die Menge der Spaltenknoten
\item $G\left(I,J\right)$ ist der vollständige, bipartite Graph mit Kantenmenge
$\left\{ \left(i,j\right)|i\in I,j\in J\right\} $.
\end{itemize}
\begin{defn}
Sei $F$ ein Subgraph von $G\left(I,J\right)$.
\begin{lyxlist}{00.00.0000}
\item [{a)}] $F$ heißt dual zulässig, falls es einen dual zulässigen Vektor
$\left(u,v\right)$ gibt, so dass $w_{ij}=0$, für alle $\left(i,j\right)\in F$.
\item [{b)}] $F$ heißt primal zulässig, falls es einen primal zulässigen
Vektor $x$ gibt, so dass $x_{ij}=0$, für alle $\left(i,j\right)\in F$.
\end{lyxlist}
\end{defn}

\begin{lem}
Ist $F$ ein primal und dual zulässiger Subgraph von $G\left(I,J\right)$,
dann sind die zugehörigen Vektoren $\left(u,v\right)$ und $x$ optimal
für (AP) bzw. (AP$_{D}$).
\end{lem}

\begin{defn*}
Sei $F$ ein Subgraph von $G\left(I,J\right)$. Ein Knoten hat \textbf{Valenz}
$d$ (bzgl. F), falls sein Knotengrad in F gleich $d$ ist.
\end{defn*}
\begin{defn}
Ein Subgraph $F$ von $G\left(I,J\right)$ heißt \textbf{Superwald}
mit einer Menge von Wurzeln aus $J$, falls gilt:
\end{defn}

\begin{itemize}
\item $F$ ist ein aufspannender Wald
\item Jede Komponente von $F$ enthält genau eine Wurzel
\item Jeder Knoten aus J, der keine Wurzel ist, hat Valenz 2.
\end{itemize}
\begin{defn*}
Ein Superwald $F$ lässt sich in den \textbf{Überschuss-Wald} $F^{S}$
und den \textbf{Defizit-Wald} $F^{D}$ partitionieren, mit

$F^{S}=\text{Vereinigung der Komponenten von \ensuremath{F}, deren Wurzeln Valenz \ensuremath{\geq2} haben,}$

$F^{D}=\text{Vereinigung der Komponenten von \ensuremath{F}, deren Wurzeln Valenz \ensuremath{0} oder \ensuremath{1} haben.}$
\end{defn*}
\begin{lem}
Ist $F$ dual zulässiger Superwald mit $F^{S}=\emptyset$, dann ist
der zugehörige Vektor $\left(u,v\right)$ eine Optimallösung von (AP$_{D}$)
und $F$ enthält eine optimale Zuordnung.

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{\textit{AKP}}\textit{$\left(C\right)$:}
\begin{enumerate}
\item Bestimme einen dual zulässigen Superwald $F_{0}$ mit Dualvariablen
$\left(u^{0},v^{0}\right)$ und setze $i=0$.
\item Falls $F_{i}$ dual zulässig und $F_{i}^{S}$ leer ist, \emph{Stop}(,,$F_{i}$
enthält eine optimale Zuordnung``).
\item Iteration $i$:
\begin{enumerate}
\item Bestimme eine geeignete Kante $\left(g,h\right)$.
\item Konstruiere mit Hilfe von $\left(g,h\right)$ einen neuen Superwald
$F_{i+1}$.
\item Berechne neue Dualvariablen $\left(u^{i+1},v^{i+1}\right)$.
\item Setze $i=i+1$ und gehe zu (2).
\end{enumerate}
\end{enumerate}
%
\end{minipage}}
\end{lem}


\subsubsection{Bestimmung einer Startlösung}

Bestimme $u_{i}$ und $v_{j}$ als Zeilen- und Spaltenminima. Erstelle
Subgraph $F=\left\{ \left(i,j\right)|w_{ij}=0\right\} $. Entferne
Kanten und zeichne Knoten aus $J$ als Wurzeln aus, bis $F$ ein Subgraph
ist.

\subsubsection{Korrektur des Superwaldes}

Wähle die Kante $\left(g,h\right)$ mit kleinstem $w_{ij}$, die einen
$I$-Knoten im Überschuss-Wald und einen $J$-Knoten im Defizit-Wald
verbindet und füge sie dem Superwald hinzu:

\[
\delta=w_{gh}=\min\left\{ w_{ij}|i\in I\cap F_{m}^{S},j\in J\cap F_{m}^{D}\right\} 
\]

Die Superwald-Eigenschaft muss wiederhergestellt werden. Es können
4 Fälle auftreten.\\
In Fall 1 und 2 wird der Überschuss-Wald größer:

\begin{tabular}{|>{\centering}p{0.5\textwidth}|>{\centering}p{0.5\textwidth}|}
\hline 
\textbf{Fall 1:} $h$ ist eine Wurzel mit Valenz 1 & \textbf{Fall 2:} $h$ ist keine Wurzel (und hat Vater $k$)\tabularnewline
\hline 
\hline 
\includegraphics[scale=0.17]{diagramme/akp_case1} & \includegraphics[scale=0.17]{diagramme/akp_case2}\tabularnewline
\hline 
$\begin{aligned}F_{m}^{\ast}= & \text{ Komponente von \ensuremath{F_{m}}, die \ensuremath{h} enthält}\\
F_{m+1}^{D}= & F_{m}^{D}\setminus F_{m}^{\ast}\\
F_{m+1}^{S}= & F_{m}^{S}\cup F_{m}^{\ast}\cup\left\{ \left(g,h\right)\right\} 
\end{aligned}
$ & $\begin{aligned}F_{m}^{\ast}= & \text{ Komponente von \ensuremath{F_{m}^{D}\setminus\left\{ \left(k,h\right)\right\} }, die \ensuremath{h} enthält}\\
F_{m+1}^{D}= & F_{m}^{D}\setminus\left(F_{m}^{\ast}\cup\left\{ \left(k,h\right)\right\} \right)\\
F_{m+1}^{S}= & F_{m}^{S}\cup\left(F_{m}^{\ast}\cup\left\{ \left(g,h\right)\right\} \right)
\end{aligned}
$\tabularnewline
\hline 
\end{tabular}

In Fall 3 und 4 wird der Überschuss-Wald kleiner:

\begin{tabular}{|>{\centering}p{0.5\textwidth}|>{\centering}p{0.5\textwidth}|}
\hline 
\textbf{Fall 3:} $h$ ist isolierte Wurzel und die Wurzel $j$ der
Komponente von $g$ hat Valenz 2 & \textbf{Fall 4:} $h$ ist isolierte Wurzel und die Wurzel $j$ der
Komponente von $g$ hat Valenz >2\tabularnewline
\hline 
\hline 
\includegraphics[scale=0.17]{diagramme/akp_case3} & \includegraphics[scale=0.17]{diagramme/akp_case4}\tabularnewline
\hline 
$\begin{aligned}F_{m}^{\ast}= & \text{ Komponente von \ensuremath{F_{m}^{S}}, die \ensuremath{g} enthält}\\
F_{m+1}^{D}= & F_{m}^{D}\cup F_{m}^{\ast}\cup\left\{ \left(g,h\right)\right\} \\
F_{m+1}^{S}= & F_{m}^{S}\setminus F_{m}^{\ast}
\end{aligned}
$ & $\begin{aligned}F_{m}^{\ast}= & \text{ Komponente von \ensuremath{F_{m}^{S}\setminus\left\{ \left(j,i\right)\right\} }, die \ensuremath{g} enthält,}\\
 & \text{mit \ensuremath{i} als Sohn von \ensuremath{j} im Ast der \ensuremath{g} enthält}\\
F_{m+1}^{D}= & F_{m}^{D}\cup F_{m}^{\ast}\cup\left\{ \left(g,h\right)\right\} \\
F_{m+1}^{S}= & F_{m}^{S}\setminus\left(F_{m}^{\ast}\cup\left\{ \left(j,i\right)\right\} \right)
\end{aligned}
$\tabularnewline
\hline 
\end{tabular}

\subsubsection{Korrektur der Dualvariablen}

$F_{m}^{\ast}$ ist anschaulich die Komponente, die ,,umgehängt``
wurde.

Ist Fall 1 oder 2 eingetreten, gilt:

\[
u_{i}=\begin{cases}
u_{i}-\delta, & \text{falls }i\in F_{m}^{\ast}\\
u_{i} & \text{sonst,}
\end{cases}
\]

\[
v_{j}=\begin{cases}
v_{j}+\delta, & \text{falls }j\in F_{m}^{\ast}\\
v_{j} & \text{sonst.}
\end{cases}
\]

In Fall 3 und 4 sind $+$ und $-$ vertauscht.
\begin{lem}
Falls die Teilwälder $F_{m}^{D}$ und $F_{m}^{S}$ dual zulässig sind,
dann gilt $\delta_{m+1}\geq\delta_{m}$ und $\delta_{m+1}\geq$-$\delta_{m}$.
\end{lem}

\begin{lem}
Falls $F_{m}^{D}$ und $F_{m}^{S}$ dual zulässig sind, dann auch
$F_{m+1}^{D}$ und $F_{m+1}^{S}$.
\end{lem}

\begin{prop}
Der AKP-Algorithmus arbeitet korrekt und löst das Zuordnungsproblem
mit Zeitkomplexität $\mathcal{O}\left(n^{3}\right)$.
\end{prop}


\section{Maximale Flüsse und minimale Schnitte}
\begin{defn*}
Ein \textbf{Flussnetzwerk} ist ein Digraph $D=\left(V,A\right)$ mit
Kantenkapazitäten $c\left(u,v\right)\geq0$ für alle Kanten $\left(u,v\right)$,
einer \textbf{Quelle} $s\in V$ und einer \textbf{Senke} $t\in V$.
$D$ ist zusammenhängend und für jeden Knoten $v\in V$ existiert
ein $\left(s,v\right)$-Weg so wie ein $\left(v,t\right)$-Weg.
\end{defn*}
\begin{defn}
Ein \textbf{$\left(s,t\right)$-Fluss} in $D$ ist eine Funktion $f:V\times V\rightarrow\mathbb{R}$
mit den Eigenschaften

$\begin{aligned}f\left(u,v\right)\leq & c\left(u,v\right)\text{, für alle }u,v\in V & \text{(Kapazitätsbeschränkung)}\\
f\left(u,v\right)= & -f\left(u,v\right)\text{, für alle }u,v\in V & \text{(Antisymmetrie)}\\
\sum_{v\in V}f\left(u,v\right)= & 0\text{, für alle }u\in V\setminus\left\{ s,t\right\}  & \text{(Flusserhaltung)}
\end{aligned}
$

Die Zahl $f\left(u,v\right)$ heißt Netto-Fluss von $u$ nach $v$.
Der \textbf{Wert} von $f$ ist $\left|f\right|:=\sum_{v\in V}f\left(s,v\right)$.

\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Maximaler-$\left(s,t\right)$-Fluss-Problem}

\smallskip{}

Gegeben sind ein Digraph $D=\left(V,A\right)$ mit Kantenkapazitäten
und zwei Knoten $s,t\in V$. Zu bestimmen ist ein $\left(s,t\right)$-Fluss
maximalen Werts.%
\end{minipage}}

Für $\left(u,v\right)\notin A$ setzen wir $c\left(u,v\right)=0$.

Der \textbf{positive Nettofluss} in einen Knoten $v$ ist definiert
als 
\[
\sum_{\substack{u\in V\\
f\left(u,v\right)>0
}
}f\left(u,v\right)
\]

Der positive Nettofluss \emph{aus} einem Knoten ist analog.

Für Knotenmengen $X$ und $Y$ gilt die Kurzschreibweise

\[
f\left(X,Y\right)=\sum_{x\in X}\sum_{y\in Y}f\left(x,y\right)
\]
\end{defn}

\begin{lem}
Sei $D$ ein Netzwerk und $f$ ein Fluss.
\begin{lyxlist}{00.00.0000}
\item [{a)}] Für $X\subseteq V$ gilt $f\left(X,X\right)=0$.
\item [{b)}] Für $X,Y\subseteq V$ gilt $f\left(X,Y\right)=-f\left(Y,X\right)$.
\item [{c)}] Für $X,Y,Z\subseteq V$ mit $X\cap Y=\emptyset$ gilt $f\left(X\cup Y,Z\right)=f\left(X,Z\right)+f\left(Y,Z\right)$
und $f\left(Z,X\cup Y\right)=f\left(Z,X\right)+f\left(Z,Y\right)$.
\end{lyxlist}
\end{lem}


\subsection{Der Algorithmus von Ford und Fulkerson}
\begin{defn*}
Die \textbf{Restkapazität} ist definiert als $c_{f}\left(u,v\right)=c\left(u,v\right)-f\left(u,v\right)$.
Das \textbf{reduzierte Netzwerk} $D_{f}=\left(V,A_{f}\right)$ mit
$A_{f}=\left\{ \left(u,v\right)\in V\times V|c_{f}\left(u,v\right)>0\right\} $
enthält die möglichen, zusätzlichen Nettoflüsse.
\end{defn*}
\begin{lem}
Sei $D$ ein Netzwerk mit $\left(s,t\right)$-Fluss $f$. $D_{f}$
sei das zugehörige reduzierte Netzwerk und $f^{\prime}$ sei ein $\left(s,t\right)$-Fluss
in $D_{f}$. Dann ist $\overline{f}$ definiert durch $\overline{f}\left(u,v\right)=f\left(u,v\right)+f^{\prime}\left(u,v\right)$
ein $\left(s,t\right)$-Fluss in $D$ mit Wert $\left|f\right|+\left|f^{\prime}\right|$.
\end{lem}

\begin{defn*}
Ein einfacher $\left(s,t\right)$-Weg in $D_{f}$ heißt \textbf{augmentierender
Weg} $P$ mit \textbf{Restkapazität} $c_{f}\left(P\right)=\min\left\{ c_{f}\left(u,v\right)|\left(u,v\right)\in P\right\} $.
\end{defn*}
%
\begin{defn*}
Ein \textbf{$\left(s,t\right)$-Schnitt} $\left(S:T\right)$ ist eine
Partition von $V$ in $S$ und $T=V\setminus S$, wobei $s\in S$
und $t\in T.$ Der \textbf{Nettofluss über dem Schnitt} $\left(S:T\right)$
ist definiert als $f\left(S,T\right)$. Seine Kapazität ist $c\left(S:T\right)={\displaystyle \sum_{u\in S}\sum_{v\in T}c\left(u,v\right)}$.
\end{defn*}
\noindent\shadowbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule - \shadowsize}%
\textbf{Minimaler-$\left(s,t\right)$-Schnitt-Problem}

\smallskip{}

Gegeben sind ein Digraph $D=\left(V,A\right)$ mit Kantenkapazitäten
und zwei Knoten $s,t\in V$. Zu bestimmen ist ein $\left(s,t\right)$-Schnitt
minimaler Kapazität.%
\end{minipage}}
\begin{lem}
Seien $f$ ein $\left(s,t\right)$-Fluss $D$ und $\left(S:T\right)$
ein $\left(s,t\right)$-Schnitt. Dann gelten:
\begin{lyxlist}{00.00.0000}
\item [{a)}] $f\left(S,T\right)=\left|f\right|$.
\item [{b)}] $\left|f\right|\leq c\left(S:T\right)$.
\end{lyxlist}
\end{lem}

\begin{prop}
\textbf{(Max-Flow-Min-Cut-Theorem)}

Sei $f$ ein $\left(s,t\right)$-Fluss in $D$. Die folgenden Aussagen
sind äquivalent:
\begin{itemize}
\item $f$ ist maximaler Fluss.
\item Das reduzierte Netzwerk enthält keinen augmentierenden Weg.
\item Es gibt einen Schnitt $\left(S:T\right)$ mit $c\left(S:T\right)=\left|f\right|$.
\end{itemize}
\end{prop}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{FordFulkerson}$\left(D,c,s,t\right)$:
\begin{enumerate}
\item Für alle $\left(u,v\right)\in A$ setze $f\left[u,v\right]=f\left[v,u\right]=0$.
\item Konstruiere das reduzierte Netzwerk $D_{f}$.
\item Falls kein augmentierender $\left(s,t\right)$-Weg existiert, \emph{Stop}(,,$f$
ist maximal``), andernfalls sei $P$ ein solcher Weg mit Restkapazität
$c_{f}\left(P\right)$.
\item Für jede Kante $\left(u,v\right)$ des Weges $P$ setze $f\left[u,v\right]=f\left[u,v\right]+c_{f}\left(P\right)$
und $f\left[v,u\right]=-f\left[u,v\right]$.
\item Gehe zu (2).
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(A\left|f^{\ast}\right|\right)$ -> nicht
poly!

Ein minimaler Schnitt wird gleich mitgeliefert. Eine Seite sind alle
Knoten, zu denen kein augmentierender Weg mehr gefunden werden kann.
\begin{cor}
Wenn alle Kapazitäten ganzzahlig sind, dann existiert ein ganzzahliger
maximaler Fluss.
\end{cor}

\begin{prop}
Sei $f$ ein $\left(s,t\right)$-Fluss in $D$. Dann gibt es eine
Familie von $\left(s,t\right)$-Wegen $\mathcal{P}$ und (gerichteten)
Kreisen $\mathcal{C}$ in $D$ mit Gewichten $w_{P},P\in\mathcal{P}$,
und $w_{C},C\in\mathcal{C}$, so dass
\[
f\left(u,v\right)=\sum_{P\in\mathcal{P}}\sum_{\left(u,v\right)\in P}w_{P}+\sum_{C\in\mathcal{C}}\sum_{\left(u,v\right)\in C}w_{C}
\]
\end{prop}


\subsection{Der Satz von Menger}

(Dieses Kapitel zeigt, wie toll man einige Dinge mit Flüssen beweisen
kann und \emph{ergibt} ohne die Beweise leider nicht viel Sinn.)
\begin{prop}
Seien $D=\left(V,A\right)$ ein gerichteter Graph und $s,t$ zwei
Knoten in $V$. Für $k\geq1$ gibt es $k$ kantendisjunkte $\left(s,t\right)$-Wege
genau dann, wenn es auch nach Entfernen von $k-1$ beliebigen Kanten
noch einen Weg von $s$ nach $t$ gibt.
\end{prop}

\begin{prop}
Seien $D=\left(V,A\right)$ ein Digraph und $s,t$ zwei nicht benachbarte
Knoten in $V$. Für $k\geq1$ gibt es $k$ intern knotendisjunkte
$\left(s,t\right)$-Wege genau dann, wenn es auch nach Entfernen von
$k-1$ beliebigen Knoten noch einen Weg von $s$ nach $t$ gibt.
\end{prop}


\subsection{Der Algorithmus von Edmonds und Karp}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{EdmondsKarp}$\left(D,c,s,t\right)$:
\begin{enumerate}
\item Für alle $\left(u,v\right)\in A$ setze $f\left[u,v\right]=f\left[v,u\right]=0$.
\item Konstruiere das reduzierte Netzwerk $D_{f}$.
\item Falls kein augmentierender $\left(s,t\right)$-Weg existiert, \emph{Stop}(,,$f$
ist maximal``), andernfalls sei $P$ ein solcher Weg \emph{mit möglichst
wenigen Kanten} und Restkapazität $c_{f}\left(P\right)$.
\item Für jede Kante $\left(u,v\right)$ des Weges $P$ setze $f\left[u,v\right]=f\left[u,v\right]+c_{f}\left(P\right)$
und $f\left[v,u\right]=-f\left[u,v\right]$. Gehe zu (2).
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(VA\right)$

$\delta_{f}\left(u,v\right)$ ist die Kürzeste-Wege-Distanz von $u$
nach $v$ im reduzierten Netzwerk, gemessen in Anzahl der Kanten.
\begin{lem}
Die Edmonds-Karp-Variante werde auf das Netzwerk$D=\left(V,A\right)$
mit Quelle $s$ und Senke $t$ angewendet.

Dann nehmen für jeden Knoten $v\in V\setminus\left\{ s,t\right\} $
die Distanzen $\delta_{f}\left(s,v\right)$ bei jeder Augmentierung
nicht ab.
\end{lem}

\begin{prop}
Die Edmonds-Karp-Variante führt $\mathcal{O}\left(VA\right)$ Augmentierungen
durch.
\end{prop}


\subsection{Die Skalierungsvariante von Ahuja und Orlin}

\noindent\doublebox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 7.5\fboxrule - 1pt}%
\textbf{ScalingMaxFlow}$\left(D,c,s,t\right)$:
\begin{enumerate}
\item Setze $C=\max\left\{ c\left(u,v\right)|\left(u,v\right)\in A\right\} $.
\item Beginne mit dem $\left(s,t\right)$-Fluss $f\equiv0$.
\item Setze $K=2^{\left\lfloor \log_{2}C\right\rfloor }$.
\item Solange $K\geq1$:
\begin{enumerate}
\item So lange es einen augmentierenden Weg mit Restkapazität $\geq k$
gibt, augmentiere $f$ mit Hilfe dieses Weges.
\item Setzte$K=K/2$.
\end{enumerate}
\item Der Fluss $f$ ist ein maximaler Fluss.
\end{enumerate}
%
\end{minipage}}

Laufzeit: $\mathcal{O}\left(A^{2}\log C\right)$, kann zu $\mathcal{O}\left(VA\log C\right)$
verbessert werden.
\begin{lem}
Vor der Ausführung von Schritt (4.1) ist die Kapazität eines minimalen
Schnitts im reduzierten Netzwerk höchstens $2\cdot K\cdot\left|A\right|$.
\end{lem}

\begin{lem}
Für festes $K$ erfolgen $\mathcal{O}\left(A\right)$ Augmentierungen
in Schritt (4.1).
\end{lem}

\begin{prop}
Der Algorithmus ScalingMaxFlow hat die Zeitkomplexität $\mathcal{O}\left(A^{2}\log C\right)$.
\end{prop}


\end{document}
